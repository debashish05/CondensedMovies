loading features >>> [Total: 0.2s] (gnode012:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.7% of system memory 2.6 GB/131.4 GB
loading features >>> [Total: 3.4s] (gnode012:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.9% of system memory 6.8 GB/127.1 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 5.9% of system memory 6.9 GB/127.1 GB
loading features >>> [Total: 0.2s] (gnode012:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.0% of system memory 7.0 GB/127.0 GB
loading features >>> [Total: 0.2s] (gnode012:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.1% of system memory 7.2 GB/126.8 GB
loading features >>> [Total: 1.5s] (gnode012:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 7.5% of system memory 9.0 GB/124.9 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.6% of system memory 9.1 GB/124.9 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
train size: 24098 clips
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (scene): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=21, bias=True)
)
Trainable parameters: 50541651
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121312
Train Epoch: 1 [1408/24098 (6%)] Loss: 0.121205
Train Epoch: 1 [2816/24098 (12%)] Loss: 0.121207
Train Epoch: 1 [4224/24098 (18%)] Loss: 0.121234
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.121284
Train Epoch: 1 [7040/24098 (29%)] Loss: 0.121299
Train Epoch: 1 [8448/24098 (35%)] Loss: 0.121250
Train Epoch: 1 [9856/24098 (41%)] Loss: 0.121107
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.121352
Train Epoch: 1 [12672/24098 (53%)] Loss: 0.121477
Train Epoch: 1 [14080/24098 (58%)] Loss: 0.121273
Train Epoch: 1 [15488/24098 (64%)] Loss: 0.121245
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.121074
Train Epoch: 1 [18304/24098 (76%)] Loss: 0.121164
Train Epoch: 1 [19712/24098 (82%)] Loss: 0.121189
Train Epoch: 1 [21120/24098 (88%)] Loss: 0.121164
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.121086
Train Epoch: 1 [23936/24098 (99%)] Loss: 0.121249
[t2v_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.1, R@10 0.3, R@50 1.7MedR: 1640.5, MeanR: 1666.2
[v2t_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.0, R@10 0.0, R@50 1.5MedR: 1651.5, MeanR: 1653.9
    epoch          : 1
    loss           : 0.12124213966585341
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.12122725695371628
    val_t2v_metrics_R1: 0.02976190476190476
    val_t2v_metrics_R5: 0.11904761904761904
    val_t2v_metrics_R10: 0.3273809523809524
    val_t2v_metrics_R50: 1.6666666666666667
    val_t2v_metrics_MedR: 1640.5
    val_t2v_metrics_MeanR: 1666.1778273809523
    val_t2v_metrics_geometric_mean_R1-R5-R10: 0.10506989093232331
    val_v2t_metrics_R1: 0.0
    val_v2t_metrics_R5: 0.0
    val_v2t_metrics_R10: 0.0
    val_v2t_metrics_R50: 1.4880952380952381
    val_v2t_metrics_MedR: 1651.5
    val_v2t_metrics_MeanR: 1653.8592261904762
    val_v2t_metrics_geometric_mean_R1-R5-R10: 0.0
/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/scipy/stats/stats.py:275: RuntimeWarning: divide by zero encountered in log
  log_a = np.log(np.array(a, dtype=dtype))
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.121299
Train Epoch: 2 [1408/24098 (6%)] Loss: 0.110206
Train Epoch: 2 [2816/24098 (12%)] Loss: 0.081618
Train Epoch: 2 [4224/24098 (18%)] Loss: 0.071430
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.054725
Train Epoch: 2 [7040/24098 (29%)] Loss: 0.052942
Train Epoch: 2 [8448/24098 (35%)] Loss: 0.047898
Train Epoch: 2 [9856/24098 (41%)] Loss: 0.042970
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.046080
Train Epoch: 2 [12672/24098 (53%)] Loss: 0.041088
Train Epoch: 2 [14080/24098 (58%)] Loss: 0.035835
Train Epoch: 2 [15488/24098 (64%)] Loss: 0.034046
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.030861
Train Epoch: 2 [18304/24098 (76%)] Loss: 0.032492
Train Epoch: 2 [19712/24098 (82%)] Loss: 0.025771
Train Epoch: 2 [21120/24098 (88%)] Loss: 0.031210
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.026760
Train Epoch: 2 [23936/24098 (99%)] Loss: 0.028744
[t2v_metrics]MovieClips epoch 2, R@1: 2.1, R@5: 7.4, R@10 11.8, R@50 31.2MedR: 142, MeanR: 308.8
[v2t_metrics]MovieClips epoch 2, R@1: 2.6, R@5: 8.0, R@10 13.5, R@50 34.2MedR: 110, MeanR: 269.4
    epoch          : 2
    loss           : 0.049430998702528615
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.03145943954586983
    val_t2v_metrics_R1: 2.0833333333333335
    val_t2v_metrics_R5: 7.351190476190476
    val_t2v_metrics_R10: 11.785714285714286
    val_t2v_metrics_R50: 31.25
    val_t2v_metrics_MedR: 142.0
    val_t2v_metrics_MeanR: 308.7785714285714
    val_t2v_metrics_geometric_mean_R1-R5-R10: 5.6514182404885895
    val_v2t_metrics_R1: 2.5595238095238093
    val_v2t_metrics_R5: 8.035714285714286
    val_v2t_metrics_R10: 13.482142857142858
    val_v2t_metrics_R50: 34.166666666666664
    val_v2t_metrics_MedR: 110.0
    val_v2t_metrics_MeanR: 269.3699404761905
    val_v2t_metrics_geometric_mean_R1-R5-R10: 6.5209999230396924
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.026849
Train Epoch: 3 [1408/24098 (6%)] Loss: 0.023127
Train Epoch: 3 [2816/24098 (12%)] Loss: 0.019590
Train Epoch: 3 [4224/24098 (18%)] Loss: 0.020217
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.026003
Train Epoch: 3 [7040/24098 (29%)] Loss: 0.021680
Train Epoch: 3 [8448/24098 (35%)] Loss: 0.020018
Train Epoch: 3 [9856/24098 (41%)] Loss: 0.018968
Train Epoch: 3 [11264/24098 (47%)] Loss: 0.017233
Train Epoch: 3 [12672/24098 (53%)] Loss: 0.019810
Train Epoch: 3 [14080/24098 (58%)] Loss: 0.020618
Train Epoch: 3 [15488/24098 (64%)] Loss: 0.016220
Train Epoch: 3 [16896/24098 (70%)] Loss: 0.018829
Train Epoch: 3 [18304/24098 (76%)] Loss: 0.016699
Train Epoch: 3 [19712/24098 (82%)] Loss: 0.016427
Train Epoch: 3 [21120/24098 (88%)] Loss: 0.019320
Train Epoch: 3 [22528/24098 (93%)] Loss: 0.015824
Train Epoch: 3 [23936/24098 (99%)] Loss: 0.016182
[t2v_metrics]MovieClips epoch 3, R@1: 2.9, R@5: 10.8, R@10 17.3, R@50 40.0MedR: 83, MeanR: 221.8
[v2t_metrics]MovieClips epoch 3, R@1: 3.8, R@5: 13.5, R@10 20.0, R@50 45.7MedR: 63, MeanR: 187.7
    epoch          : 3
    loss           : 0.018979523035268935
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.024902936071157455
    val_t2v_metrics_R1: 2.9166666666666665
    val_t2v_metrics_R5: 10.773809523809524
    val_t2v_metrics_R10: 17.291666666666668
    val_t2v_metrics_R50: 40.029761904761905
    val_t2v_metrics_MedR: 83.0
    val_t2v_metrics_MeanR: 221.79494047619048
    val_t2v_metrics_geometric_mean_R1-R5-R10: 8.160140732688198
    val_v2t_metrics_R1: 3.8095238095238093
    val_v2t_metrics_R5: 13.482142857142858
    val_v2t_metrics_R10: 20.0
    val_v2t_metrics_R50: 45.714285714285715
    val_v2t_metrics_MedR: 63.0
    val_v2t_metrics_MeanR: 187.73125
    val_v2t_metrics_geometric_mean_R1-R5-R10: 10.089892461089972
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/24098 (0%)] Loss: 0.012360
Train Epoch: 4 [1408/24098 (6%)] Loss: 0.012761
Train Epoch: 4 [2816/24098 (12%)] Loss: 0.012042
Train Epoch: 4 [4224/24098 (18%)] Loss: 0.011818
Train Epoch: 4 [5632/24098 (23%)] Loss: 0.008913
Train Epoch: 4 [7040/24098 (29%)] Loss: 0.012148
Train Epoch: 4 [8448/24098 (35%)] Loss: 0.010659
Train Epoch: 4 [9856/24098 (41%)] Loss: 0.010618
Train Epoch: 4 [11264/24098 (47%)] Loss: 0.010153
Train Epoch: 4 [12672/24098 (53%)] Loss: 0.010382
Train Epoch: 4 [14080/24098 (58%)] Loss: 0.009860
Train Epoch: 4 [15488/24098 (64%)] Loss: 0.009400
Train Epoch: 4 [16896/24098 (70%)] Loss: 0.010917
Train Epoch: 4 [18304/24098 (76%)] Loss: 0.010102
Train Epoch: 4 [19712/24098 (82%)] Loss: 0.010500
Train Epoch: 4 [21120/24098 (88%)] Loss: 0.008343
Train Epoch: 4 [22528/24098 (93%)] Loss: 0.011016
Train Epoch: 4 [23936/24098 (99%)] Loss: 0.009047
[t2v_metrics]MovieClips epoch 4, R@1: 3.7, R@5: 13.8, R@10 21.4, R@50 46.2MedR: 60, MeanR: 183.2
[v2t_metrics]MovieClips epoch 4, R@1: 4.8, R@5: 16.2, R@10 24.1, R@50 52.6MedR: 45, MeanR: 156.0
    epoch          : 4
    loss           : 0.010844371030254969
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022748779505491257
    val_t2v_metrics_R1: 3.7202380952380953
    val_t2v_metrics_R5: 13.75
    val_t2v_metrics_R10: 21.428571428571427
    val_t2v_metrics_R50: 46.220238095238095
    val_t2v_metrics_MedR: 60.0
    val_t2v_metrics_MeanR: 183.1886904761905
    val_t2v_metrics_geometric_mean_R1-R5-R10: 10.31071741331737
    val_v2t_metrics_R1: 4.761904761904762
    val_v2t_metrics_R5: 16.220238095238095
    val_v2t_metrics_R10: 24.077380952380953
    val_v2t_metrics_R50: 52.589285714285715
    val_v2t_metrics_MedR: 45.0
    val_v2t_metrics_MeanR: 156.0455357142857
    val_v2t_metrics_geometric_mean_R1-R5-R10: 12.29746867005174
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch4.pth ...
Saving current best: model_best.pth ...
Train Epoch: 5 [0/24098 (0%)] Loss: 0.007040
Train Epoch: 5 [1408/24098 (6%)] Loss: 0.006936
Train Epoch: 5 [2816/24098 (12%)] Loss: 0.006583
Train Epoch: 5 [4224/24098 (18%)] Loss: 0.007076
Train Epoch: 5 [5632/24098 (23%)] Loss: 0.005938
Train Epoch: 5 [7040/24098 (29%)] Loss: 0.005529
Train Epoch: 5 [8448/24098 (35%)] Loss: 0.006118
Train Epoch: 5 [9856/24098 (41%)] Loss: 0.007359
Train Epoch: 5 [11264/24098 (47%)] Loss: 0.008448
Train Epoch: 5 [12672/24098 (53%)] Loss: 0.006330
Train Epoch: 5 [14080/24098 (58%)] Loss: 0.005578
Train Epoch: 5 [15488/24098 (64%)] Loss: 0.005242
Train Epoch: 5 [16896/24098 (70%)] Loss: 0.005249
Train Epoch: 5 [18304/24098 (76%)] Loss: 0.006040
Train Epoch: 5 [19712/24098 (82%)] Loss: 0.006329
Train Epoch: 5 [21120/24098 (88%)] Loss: 0.005038
Train Epoch: 5 [22528/24098 (93%)] Loss: 0.006137
Train Epoch: 5 [23936/24098 (99%)] Loss: 0.008335
[t2v_metrics]MovieClips epoch 5, R@1: 4.2, R@5: 16.1, R@10 23.8, R@50 51.4MedR: 48, MeanR: 163.0
[v2t_metrics]MovieClips epoch 5, R@1: 6.0, R@5: 19.3, R@10 27.1, R@50 55.7MedR: 38, MeanR: 139.7
    epoch          : 5
    loss           : 0.00650289380755374
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022031592205166817
    val_t2v_metrics_R1: 4.196428571428571
    val_t2v_metrics_R5: 16.13095238095238
    val_t2v_metrics_R10: 23.779761904761905
    val_t2v_metrics_R50: 51.398809523809526
    val_t2v_metrics_MedR: 48.0
    val_t2v_metrics_MeanR: 162.97976190476192
    val_t2v_metrics_geometric_mean_R1-R5-R10: 11.719680768072987
    val_v2t_metrics_R1: 5.982142857142857
    val_v2t_metrics_R5: 19.25595238095238
    val_v2t_metrics_R10: 27.142857142857142
    val_v2t_metrics_R50: 55.68452380952381
    val_v2t_metrics_MedR: 38.0
    val_v2t_metrics_MeanR: 139.70416666666668
    val_v2t_metrics_geometric_mean_R1-R5-R10: 14.622639775789079
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch5.pth ...
Saving current best: model_best.pth ...
Train Epoch: 6 [0/24098 (0%)] Loss: 0.005000
Train Epoch: 6 [1408/24098 (6%)] Loss: 0.004165
Train Epoch: 6 [2816/24098 (12%)] Loss: 0.003970
Train Epoch: 6 [4224/24098 (18%)] Loss: 0.004069
Train Epoch: 6 [5632/24098 (23%)] Loss: 0.004387
Train Epoch: 6 [7040/24098 (29%)] Loss: 0.004437
Train Epoch: 6 [8448/24098 (35%)] Loss: 0.004422
Train Epoch: 6 [9856/24098 (41%)] Loss: 0.003729
Train Epoch: 6 [11264/24098 (47%)] Loss: 0.004257
Train Epoch: 6 [12672/24098 (53%)] Loss: 0.003796
Train Epoch: 6 [14080/24098 (58%)] Loss: 0.004011
Train Epoch: 6 [15488/24098 (64%)] Loss: 0.004331
Train Epoch: 6 [16896/24098 (70%)] Loss: 0.004045
Train Epoch: 6 [18304/24098 (76%)] Loss: 0.004032
Train Epoch: 6 [19712/24098 (82%)] Loss: 0.003442
Train Epoch: 6 [21120/24098 (88%)] Loss: 0.003977
Train Epoch: 6 [22528/24098 (93%)] Loss: 0.003675
Train Epoch: 6 [23936/24098 (99%)] Loss: 0.003574
[t2v_metrics]MovieClips epoch 6, R@1: 5.3, R@5: 17.6, R@10 26.5, R@50 53.9MedR: 41.5, MeanR: 150.2
[v2t_metrics]MovieClips epoch 6, R@1: 6.9, R@5: 21.4, R@10 30.1, R@50 58.5MedR: 32, MeanR: 131.5
    epoch          : 6
    loss           : 0.004060119044321476
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.02180440165102482
    val_t2v_metrics_R1: 5.267857142857143
    val_t2v_metrics_R5: 17.589285714285715
    val_t2v_metrics_R10: 26.547619047619047
    val_t2v_metrics_R50: 53.92857142857143
    val_t2v_metrics_MedR: 41.5
    val_t2v_metrics_MeanR: 150.20059523809525
    val_t2v_metrics_geometric_mean_R1-R5-R10: 13.499030848725747
    val_v2t_metrics_R1: 6.904761904761905
    val_v2t_metrics_R5: 21.428571428571427
    val_v2t_metrics_R10: 30.089285714285715
    val_v2t_metrics_R50: 58.51190476190476
    val_v2t_metrics_MedR: 32.0
    val_v2t_metrics_MeanR: 131.46607142857144
    val_v2t_metrics_geometric_mean_R1-R5-R10: 16.450708298266424
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch6.pth ...
Saving current best: model_best.pth ...
Train Epoch: 7 [0/24098 (0%)] Loss: 0.002515
Train Epoch: 7 [1408/24098 (6%)] Loss: 0.002733
Train Epoch: 7 [2816/24098 (12%)] Loss: 0.002741
Train Epoch: 7 [4224/24098 (18%)] Loss: 0.002910
Train Epoch: 7 [5632/24098 (23%)] Loss: 0.002932
Train Epoch: 7 [7040/24098 (29%)] Loss: 0.002976
Train Epoch: 7 [8448/24098 (35%)] Loss: 0.002404
Train Epoch: 7 [9856/24098 (41%)] Loss: 0.002067
Train Epoch: 7 [11264/24098 (47%)] Loss: 0.002808
Train Epoch: 7 [12672/24098 (53%)] Loss: 0.002682
Train Epoch: 7 [14080/24098 (58%)] Loss: 0.002617
Train Epoch: 7 [15488/24098 (64%)] Loss: 0.002711
Train Epoch: 7 [16896/24098 (70%)] Loss: 0.002934
Train Epoch: 7 [18304/24098 (76%)] Loss: 0.002477
Train Epoch: 7 [19712/24098 (82%)] Loss: 0.002711
Train Epoch: 7 [21120/24098 (88%)] Loss: 0.002412
Train Epoch: 7 [22528/24098 (93%)] Loss: 0.002688
Train Epoch: 7 [23936/24098 (99%)] Loss: 0.002839
[t2v_metrics]MovieClips epoch 7, R@1: 5.8, R@5: 19.3, R@10 27.9, R@50 55.6MedR: 37, MeanR: 143.9
[v2t_metrics]MovieClips epoch 7, R@1: 8.0, R@5: 23.2, R@10 32.4, R@50 60.5MedR: 29, MeanR: 124.9
    epoch          : 7
    loss           : 0.0026505433673423436
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022008517757058144
    val_t2v_metrics_R1: 5.773809523809524
    val_t2v_metrics_R5: 19.345238095238095
    val_t2v_metrics_R10: 27.857142857142858
    val_t2v_metrics_R50: 55.625
    val_t2v_metrics_MedR: 37.0
    val_t2v_metrics_MeanR: 143.91875
    val_t2v_metrics_geometric_mean_R1-R5-R10: 14.599042326794118
    val_v2t_metrics_R1: 7.976190476190476
    val_v2t_metrics_R5: 23.154761904761905
    val_v2t_metrics_R10: 32.410714285714285
    val_v2t_metrics_R50: 60.50595238095238
    val_v2t_metrics_MedR: 29.0
    val_v2t_metrics_MeanR: 124.88571428571429
    val_v2t_metrics_geometric_mean_R1-R5-R10: 18.156890712432876
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch7.pth ...
Train Epoch: 8 [0/24098 (0%)] Loss: 0.002174
Train Epoch: 8 [1408/24098 (6%)] Loss: 0.001773
Train Epoch: 8 [2816/24098 (12%)] Loss: 0.001849
Train Epoch: 8 [4224/24098 (18%)] Loss: 0.002079
Train Epoch: 8 [5632/24098 (23%)] Loss: 0.002023
Train Epoch: 8 [7040/24098 (29%)] Loss: 0.001401
Train Epoch: 8 [8448/24098 (35%)] Loss: 0.002053
Train Epoch: 8 [9856/24098 (41%)] Loss: 0.001851
Train Epoch: 8 [11264/24098 (47%)] Loss: 0.001905
Train Epoch: 8 [12672/24098 (53%)] Loss: 0.001926
Train Epoch: 8 [14080/24098 (58%)] Loss: 0.002035
Train Epoch: 8 [15488/24098 (64%)] Loss: 0.001739
Train Epoch: 8 [16896/24098 (70%)] Loss: 0.001725
Train Epoch: 8 [18304/24098 (76%)] Loss: 0.001799
Train Epoch: 8 [19712/24098 (82%)] Loss: 0.002274
Train Epoch: 8 [21120/24098 (88%)] Loss: 0.001726
Train Epoch: 8 [22528/24098 (93%)] Loss: 0.001886
Train Epoch: 8 [23936/24098 (99%)] Loss: 0.001937
[t2v_metrics]MovieClips epoch 8, R@1: 6.1, R@5: 20.3, R@10 29.7, R@50 57.1MedR: 35, MeanR: 141.0
[v2t_metrics]MovieClips epoch 8, R@1: 8.8, R@5: 24.7, R@10 33.8, R@50 61.0MedR: 28, MeanR: 124.5
    epoch          : 8
    loss           : 0.00183947253528805
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022428354248404503
    val_t2v_metrics_R1: 6.130952380952381
    val_t2v_metrics_R5: 20.327380952380953
    val_t2v_metrics_R10: 29.672619047619047
    val_t2v_metrics_R50: 57.05357142857143
    val_t2v_metrics_MedR: 35.0
    val_t2v_metrics_MeanR: 140.98958333333334
    val_t2v_metrics_geometric_mean_R1-R5-R10: 15.463996761305975
    val_v2t_metrics_R1: 8.779761904761905
    val_v2t_metrics_R5: 24.672619047619047
    val_v2t_metrics_R10: 33.80952380952381
    val_v2t_metrics_R50: 61.041666666666664
    val_v2t_metrics_MedR: 28.0
    val_v2t_metrics_MeanR: 124.47619047619048
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.4198415415977
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch8.pth ...
Train Epoch: 9 [0/24098 (0%)] Loss: 0.001357
Train Epoch: 9 [1408/24098 (6%)] Loss: 0.001318
Train Epoch: 9 [2816/24098 (12%)] Loss: 0.001542
Train Epoch: 9 [4224/24098 (18%)] Loss: 0.001273
Train Epoch: 9 [5632/24098 (23%)] Loss: 0.001289
Train Epoch: 9 [7040/24098 (29%)] Loss: 0.001266
Train Epoch: 9 [8448/24098 (35%)] Loss: 0.001591
Train Epoch: 9 [9856/24098 (41%)] Loss: 0.001321
Train Epoch: 9 [11264/24098 (47%)] Loss: 0.001374
Train Epoch: 9 [12672/24098 (53%)] Loss: 0.001409
Train Epoch: 9 [14080/24098 (58%)] Loss: 0.001498
Train Epoch: 9 [15488/24098 (64%)] Loss: 0.001241
Train Epoch: 9 [16896/24098 (70%)] Loss: 0.001329
Train Epoch: 9 [18304/24098 (76%)] Loss: 0.001201
Train Epoch: 9 [19712/24098 (82%)] Loss: 0.001313
Train Epoch: 9 [21120/24098 (88%)] Loss: 0.001418
Train Epoch: 9 [22528/24098 (93%)] Loss: 0.001513
Train Epoch: 9 [23936/24098 (99%)] Loss: 0.001778
[t2v_metrics]MovieClips epoch 9, R@1: 6.8, R@5: 21.5, R@10 31.4, R@50 59.0MedR: 31.5, MeanR: 136.0
[v2t_metrics]MovieClips epoch 9, R@1: 9.1, R@5: 25.1, R@10 34.9, R@50 62.1MedR: 26, MeanR: 121.7
    epoch          : 9
    loss           : 0.0013324419762101517
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022653931751847267
    val_t2v_metrics_R1: 6.755952380952381
    val_t2v_metrics_R5: 21.547619047619047
    val_t2v_metrics_R10: 31.428571428571427
    val_t2v_metrics_R50: 59.017857142857146
    val_t2v_metrics_MedR: 31.5
    val_t2v_metrics_MeanR: 135.95238095238096
    val_t2v_metrics_geometric_mean_R1-R5-R10: 16.601098885202585
    val_v2t_metrics_R1: 9.107142857142858
    val_v2t_metrics_R5: 25.05952380952381
    val_v2t_metrics_R10: 34.851190476190474
    val_v2t_metrics_R50: 62.142857142857146
    val_v2t_metrics_MedR: 26.0
    val_v2t_metrics_MeanR: 121.69583333333334
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.96139369733836
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch9.pth ...
Train Epoch: 10 [0/24098 (0%)] Loss: 0.001112
Train Epoch: 10 [1408/24098 (6%)] Loss: 0.000980
Train Epoch: 10 [2816/24098 (12%)] Loss: 0.001447
Train Epoch: 10 [4224/24098 (18%)] Loss: 0.001063
Train Epoch: 10 [5632/24098 (23%)] Loss: 0.001061
Train Epoch: 10 [7040/24098 (29%)] Loss: 0.000995
Train Epoch: 10 [8448/24098 (35%)] Loss: 0.001193
Train Epoch: 10 [9856/24098 (41%)] Loss: 0.000940
Train Epoch: 10 [11264/24098 (47%)] Loss: 0.001024
Train Epoch: 10 [12672/24098 (53%)] Loss: 0.000975
Train Epoch: 10 [14080/24098 (58%)] Loss: 0.001124
Train Epoch: 10 [15488/24098 (64%)] Loss: 0.001029
Train Epoch: 10 [16896/24098 (70%)] Loss: 0.001133
Train Epoch: 10 [18304/24098 (76%)] Loss: 0.000937
Train Epoch: 10 [19712/24098 (82%)] Loss: 0.001032
Train Epoch: 10 [21120/24098 (88%)] Loss: 0.000820
Train Epoch: 10 [22528/24098 (93%)] Loss: 0.001237
Train Epoch: 10 [23936/24098 (99%)] Loss: 0.000955
[t2v_metrics]MovieClips epoch 10, R@1: 7.1, R@5: 22.6, R@10 32.4, R@50 60.4MedR: 29, MeanR: 134.3
[v2t_metrics]MovieClips epoch 10, R@1: 9.4, R@5: 26.0, R@10 35.7, R@50 62.8MedR: 25, MeanR: 120.4
    epoch          : 10
    loss           : 0.0010178958031314392
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.02311047725379467
    val_t2v_metrics_R1: 7.083333333333333
    val_t2v_metrics_R5: 22.589285714285715
    val_t2v_metrics_R10: 32.38095238095238
    val_t2v_metrics_R50: 60.357142857142854
    val_t2v_metrics_MedR: 29.0
    val_t2v_metrics_MeanR: 134.30833333333334
    val_t2v_metrics_geometric_mean_R1-R5-R10: 17.303870864324722
    val_v2t_metrics_R1: 9.375
    val_v2t_metrics_R5: 25.952380952380953
    val_v2t_metrics_R10: 35.654761904761905
    val_v2t_metrics_R50: 62.767857142857146
    val_v2t_metrics_MedR: 25.0
    val_v2t_metrics_MeanR: 120.40178571428571
    val_v2t_metrics_geometric_mean_R1-R5-R10: 20.54732742488159
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch10.pth ...
Train Epoch: 11 [0/24098 (0%)] Loss: 0.000824
Train Epoch: 11 [1408/24098 (6%)] Loss: 0.000716
Train Epoch: 11 [2816/24098 (12%)] Loss: 0.000758
Train Epoch: 11 [4224/24098 (18%)] Loss: 0.000757
Train Epoch: 11 [5632/24098 (23%)] Loss: 0.000743
Train Epoch: 11 [7040/24098 (29%)] Loss: 0.000810
Train Epoch: 11 [8448/24098 (35%)] Loss: 0.000787
Train Epoch: 11 [9856/24098 (41%)] Loss: 0.000960
Train Epoch: 11 [11264/24098 (47%)] Loss: 0.000824
Train Epoch: 11 [12672/24098 (53%)] Loss: 0.000914
Train Epoch: 11 [14080/24098 (58%)] Loss: 0.000789
Train Epoch: 11 [15488/24098 (64%)] Loss: 0.000916
Train Epoch: 11 [16896/24098 (70%)] Loss: 0.000705
Train Epoch: 11 [18304/24098 (76%)] Loss: 0.000807
Train Epoch: 11 [19712/24098 (82%)] Loss: 0.000939
Train Epoch: 11 [21120/24098 (88%)] Loss: 0.001142
Train Epoch: 11 [22528/24098 (93%)] Loss: 0.000805
Train Epoch: 11 [23936/24098 (99%)] Loss: 0.000879
[t2v_metrics]MovieClips epoch 11, R@1: 7.8, R@5: 23.5, R@10 33.2, R@50 60.6MedR: 27, MeanR: 132.1
[v2t_metrics]MovieClips epoch 11, R@1: 9.5, R@5: 27.0, R@10 36.5, R@50 62.9MedR: 24, MeanR: 119.7
    epoch          : 11
    loss           : 0.0008171097579949275
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.023487184196710587
    val_t2v_metrics_R1: 7.767857142857143
    val_t2v_metrics_R5: 23.511904761904763
    val_t2v_metrics_R10: 33.214285714285715
    val_t2v_metrics_R50: 60.595238095238095
    val_t2v_metrics_MedR: 27.0
    val_t2v_metrics_MeanR: 132.09017857142857
    val_t2v_metrics_geometric_mean_R1-R5-R10: 18.237752611008375
    val_v2t_metrics_R1: 9.523809523809524
    val_v2t_metrics_R5: 26.99404761904762
    val_v2t_metrics_R10: 36.48809523809524
    val_v2t_metrics_R50: 62.916666666666664
    val_v2t_metrics_MedR: 24.0
    val_v2t_metrics_MeanR: 119.74657738095237
    val_v2t_metrics_geometric_mean_R1-R5-R10: 21.090002657519715
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_164139/checkpoint-epoch11.pth ...
Train Epoch: 12 [0/24098 (0%)] Loss: 0.000678
Train Epoch: 12 [1408/24098 (6%)] Loss: 0.000704
Train Epoch: 12 [2816/24098 (12%)] Loss: 0.000753
Train Epoch: 12 [4224/24098 (18%)] Loss: 0.000743
Train Epoch: 12 [5632/24098 (23%)] Loss: 0.000623
Train Epoch: 12 [7040/24098 (29%)] Loss: 0.000743
Train Epoch: 12 [8448/24098 (35%)] Loss: 0.000583
Train Epoch: 12 [9856/24098 (41%)] Loss: 0.000820
Train Epoch: 12 [11264/24098 (47%)] Loss: 0.000734
Train Epoch: 12 [12672/24098 (53%)] Loss: 0.000641
Train Epoch: 12 [14080/24098 (58%)] Loss: 0.000655
Train Epoch: 12 [15488/24098 (64%)] Loss: 0.000593
Train Epoch: 12 [16896/24098 (70%)] Loss: 0.000746
Train Epoch: 12 [18304/24098 (76%)] Loss: 0.000712
Train Epoch: 12 [19712/24098 (82%)] Loss: 0.000793
Train Epoch: 12 [21120/24098 (88%)] Loss: 0.000605
Train Epoch: 12 [22528/24098 (93%)] Loss: 0.000614
Train Epoch: 12 [23936/24098 (99%)] Loss: 0.000676
[t2v_metrics]MovieClips epoch 12, R@1: 7.7, R@5: 24.0, R@10 33.8, R@50 61.5MedR: 26, MeanR: 132.3
[v2t_metrics]MovieClips epoch 12, R@1: 9.9, R@5: 27.2, R@10 37.4, R@50 63.5MedR: 23, MeanR: 119.3
    epoch          : 12
    loss           : 0.0006617007988983046
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.023927493020892143
    val_t2v_metrics_R1: 7.678571428571429
    val_t2v_metrics_R5: 23.988095238095237
    val_t2v_metrics_R10: 33.839285714285715
    val_t2v_metrics_R50: 61.48809523809524
    val_t2v_metrics_MedR: 26.0
    val_t2v_metrics_MeanR: 132.32559523809525
    val_t2v_metrics_geometric_mean_R1-R5-R10: 18.403444964536245
    val_v2t_metrics_R1: 9.880952380952381
    val_v2t_metrics_R5: 27.172619047619047
    val_v2t_metrics_R10: 37.38095238095238
    val_v2t_metrics_R50: 63.482142857142854
    val_v2t_metrics_MedR: 23.0
    val_v2t_metrics_MeanR: 119.31339285714286
    val_v2t_metrics_geometric_mean_R1-R5-R10: 21.570500533551375
Validation performance didn't improve for 5 epochs. Training stops.