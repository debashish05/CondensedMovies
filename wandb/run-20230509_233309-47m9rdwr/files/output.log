loading features >>> [Total: 1.2s] (gnode086:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.6% of system memory 2.5 GB/131.5 GB
loading features >>> [Total: 35.4s] (gnode086:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.7% of system memory 6.6 GB/127.4 GB
loading features >>> [Total: 0.8s] (gnode086:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 5.7% of system memory 6.6 GB/127.4 GB
loading features >>> [Total: 1.5s] (gnode086:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.8% of system memory 6.8 GB/127.2 GB
loading features >>> [Total: 1.4s] (gnode086:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.9% of system memory 7.0 GB/127.0 GB
loading features >>> [Total: 15.9s] (gnode086:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 7.4% of system memory 8.9 GB/125.1 GB
loading features >>> [Total: 0.7s] (gnode086:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.4% of system memory 9.0 GB/125.0 GB
loading features >>> [Total: 0.6s] (gnode086:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
train size: 24098 clips
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (scene): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=21, bias=True)
)
Trainable parameters: 50541651
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1459b296b170>
Traceback (most recent call last):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1465, in __del__
    def __del__(self):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 13489) is killed by signal: Killed.
Traceback (most recent call last):
  File "train.py", line 86, in <module>
    main(config)
  File "train.py", line 57, in main
    trainer.train()
  File "/home2/debashish.roy/CondensedMovies/base/base_trainer.py", line 68, in train
    result = self._train_epoch(epoch)
  File "/home2/debashish.roy/CondensedMovies/trainer/trainer.py", line 73, in _train_epoch
    output = self.model(minibatch)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/debashish.roy/CondensedMovies/model/model.py", line 80, in forward
    ftr=self.aggregation[expert](ftr[:,1,:,:], x[expert]['n_tokens'])
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home2/debashish.roy/CondensedMovies/model/net_vlad.py", line 63, in forward
    assignment = th.matmul(x, self.clusters)  # (BN x D) x (D x (K+G)) -> BN x (K+G)
KeyboardInterrupt