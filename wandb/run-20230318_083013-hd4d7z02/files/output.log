<parse_config.ConfigParser object at 0x14595db38d90>
loading features >>> [Total: 0.3s] (gnode030:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 1.9% of system memory 1.5 GB/132.5 GB
loading features >>> [Total: 8.7s] (gnode030:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.2% of system memory 5.9 GB/128.1 GB
loading features >>> [Total: 0.4s] (gnode030:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.2% of system memory 5.9 GB/128.1 GB
loading features >>> [Total: 0.5s] (gnode030:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.2% of system memory 6.0 GB/128.0 GB
loading features >>> [Total: 0.3s] (gnode030:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
train size: 24098 clips
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
>>> Currently using 5.3% of system memory 6.1 GB/127.9 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=4, bias=True)
)
Trainable parameters: 31877152
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121121
Train Epoch: 1 [512/24098 (2%)] Loss: 0.121229
Train Epoch: 1 [1024/24098 (4%)] Loss: 0.121410
Train Epoch: 1 [1536/24098 (6%)] Loss: 0.121335
Train Epoch: 1 [2048/24098 (8%)] Loss: 0.121054
Train Epoch: 1 [2560/24098 (11%)] Loss: 0.120975
Train Epoch: 1 [3072/24098 (13%)] Loss: 0.121387
Train Epoch: 1 [3584/24098 (15%)] Loss: 0.121254
Train Epoch: 1 [4096/24098 (17%)] Loss: 0.121764
Train Epoch: 1 [4608/24098 (19%)] Loss: 0.121274
Train Epoch: 1 [5120/24098 (21%)] Loss: 0.121026
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.121269
Train Epoch: 1 [6144/24098 (25%)] Loss: 0.121638
Train Epoch: 1 [6656/24098 (28%)] Loss: 0.121658
Train Epoch: 1 [7168/24098 (30%)] Loss: 0.120574
Train Epoch: 1 [7680/24098 (32%)] Loss: 0.121630
Train Epoch: 1 [8192/24098 (34%)] Loss: 0.121733
Train Epoch: 1 [8704/24098 (36%)] Loss: 0.121670
Train Epoch: 1 [9216/24098 (38%)] Loss: 0.120620
Train Epoch: 1 [9728/24098 (40%)] Loss: 0.121513
Train Epoch: 1 [10240/24098 (42%)] Loss: 0.121542
Train Epoch: 1 [10752/24098 (45%)] Loss: 0.121280
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.121143
Train Epoch: 1 [11776/24098 (49%)] Loss: 0.121337
Train Epoch: 1 [12288/24098 (51%)] Loss: 0.120728
Train Epoch: 1 [12800/24098 (53%)] Loss: 0.121451
Train Epoch: 1 [13312/24098 (55%)] Loss: 0.121697
Train Epoch: 1 [13824/24098 (57%)] Loss: 0.121468
Train Epoch: 1 [14336/24098 (59%)] Loss: 0.121584
Train Epoch: 1 [14848/24098 (62%)] Loss: 0.122046
Train Epoch: 1 [15360/24098 (64%)] Loss: 0.121635
Train Epoch: 1 [15872/24098 (66%)] Loss: 0.121558
Train Epoch: 1 [16384/24098 (68%)] Loss: 0.121377
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.121543
Train Epoch: 1 [17408/24098 (72%)] Loss: 0.121280
Train Epoch: 1 [17920/24098 (74%)] Loss: 0.121754
Train Epoch: 1 [18432/24098 (76%)] Loss: 0.121048
Train Epoch: 1 [18944/24098 (79%)] Loss: 0.121168
Train Epoch: 1 [19456/24098 (81%)] Loss: 0.121532
Train Epoch: 1 [19968/24098 (83%)] Loss: 0.121130
Train Epoch: 1 [20480/24098 (85%)] Loss: 0.121725
Train Epoch: 1 [20992/24098 (87%)] Loss: 0.121289
Train Epoch: 1 [21504/24098 (89%)] Loss: 0.121543
Train Epoch: 1 [22016/24098 (91%)] Loss: 0.120731
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.121269
Train Epoch: 1 [23040/24098 (96%)] Loss: 0.121447
Train Epoch: 1 [23552/24098 (98%)] Loss: 0.121065
Train Epoch: 1 [24064/24098 (100%)] Loss: 0.121300
[t2v_metrics]MovieClips epoch 1, R@1: 0.1, R@5: 0.2, R@10 0.4, R@50 1.7MedR: 1694, MeanR: 1686.3
[v2t_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.1, R@10 0.2, R@50 1.5MedR: 1686, MeanR: 1688.1
    epoch          : 1
    loss           : 0.12131962883693787
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.12136417627334595
    val_t2v_metrics_R1: 0.05952380952380952
    val_t2v_metrics_R5: 0.23809523809523808
    val_t2v_metrics_R10: 0.35714285714285715
    val_t2v_metrics_R50: 1.6964285714285714
    val_t2v_metrics_MedR: 1694.0
    val_t2v_metrics_MeanR: 1686.3175595238095
    val_t2v_metrics_geometric_mean_R1-R5-R10: 0.1716963774175486
    val_v2t_metrics_R1: 0.02976190476190476
    val_v2t_metrics_R5: 0.1488095238095238
    val_v2t_metrics_R10: 0.23809523809523808
    val_v2t_metrics_R50: 1.5178571428571428
    val_v2t_metrics_MedR: 1686.0
    val_v2t_metrics_MeanR: 1688.1096726190476
    val_v2t_metrics_geometric_mean_R1-R5-R10: 0.10178428254027956
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.121796
/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/ssd_scratch/cvit/debashish/CondensedMovies/trainer/trainer.py:136: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly():
Train Epoch: 2 [512/24098 (2%)] Loss: 0.064111
Train Epoch: 2 [1024/24098 (4%)] Loss: 0.049610
Train Epoch: 2 [1536/24098 (6%)] Loss: 0.045278
Train Epoch: 2 [2048/24098 (8%)] Loss: 0.038201
Train Epoch: 2 [2560/24098 (11%)] Loss: 0.042360
Train Epoch: 2 [3072/24098 (13%)] Loss: 0.044083
Train Epoch: 2 [3584/24098 (15%)] Loss: 0.046409
Train Epoch: 2 [4096/24098 (17%)] Loss: 0.030897
Train Epoch: 2 [4608/24098 (19%)] Loss: 0.039210
Train Epoch: 2 [5120/24098 (21%)] Loss: 0.037717
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.039090
Train Epoch: 2 [6144/24098 (25%)] Loss: 0.027836
Train Epoch: 2 [6656/24098 (28%)] Loss: 0.023021
Train Epoch: 2 [7168/24098 (30%)] Loss: 0.030888
Train Epoch: 2 [7680/24098 (32%)] Loss: 0.031202
Train Epoch: 2 [8192/24098 (34%)] Loss: 0.024758
Train Epoch: 2 [8704/24098 (36%)] Loss: 0.029309
Train Epoch: 2 [9216/24098 (38%)] Loss: 0.028121
Train Epoch: 2 [9728/24098 (40%)] Loss: 0.024112
Train Epoch: 2 [10240/24098 (42%)] Loss: 0.026008
Train Epoch: 2 [10752/24098 (45%)] Loss: 0.029649
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.021558
Train Epoch: 2 [11776/24098 (49%)] Loss: 0.021401
Train Epoch: 2 [12288/24098 (51%)] Loss: 0.024076
Train Epoch: 2 [12800/24098 (53%)] Loss: 0.021456
Train Epoch: 2 [13312/24098 (55%)] Loss: 0.021314
Train Epoch: 2 [13824/24098 (57%)] Loss: 0.023492
Train Epoch: 2 [14336/24098 (59%)] Loss: 0.025835
Train Epoch: 2 [14848/24098 (62%)] Loss: 0.021646
Train Epoch: 2 [15360/24098 (64%)] Loss: 0.019037
Train Epoch: 2 [15872/24098 (66%)] Loss: 0.016701
Train Epoch: 2 [16384/24098 (68%)] Loss: 0.021551
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.015712
Train Epoch: 2 [17408/24098 (72%)] Loss: 0.020769
Train Epoch: 2 [17920/24098 (74%)] Loss: 0.019292
Train Epoch: 2 [18432/24098 (76%)] Loss: 0.025460
Train Epoch: 2 [18944/24098 (79%)] Loss: 0.031565
Train Epoch: 2 [19456/24098 (81%)] Loss: 0.020194
Train Epoch: 2 [19968/24098 (83%)] Loss: 0.020889
Train Epoch: 2 [20480/24098 (85%)] Loss: 0.026565
Train Epoch: 2 [20992/24098 (87%)] Loss: 0.024939
Train Epoch: 2 [21504/24098 (89%)] Loss: 0.018236
Train Epoch: 2 [22016/24098 (91%)] Loss: 0.026455
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.016972
Train Epoch: 2 [23040/24098 (96%)] Loss: 0.021283
Train Epoch: 2 [23552/24098 (98%)] Loss: 0.017897
Train Epoch: 2 [24064/24098 (100%)] Loss: 0.017773
[t2v_metrics]MovieClips epoch 2, R@1: 3.8, R@5: 12.2, R@10 17.8, R@50 40.0MedR: 85.5, MeanR: 245.0
[v2t_metrics]MovieClips epoch 2, R@1: 4.7, R@5: 12.9, R@10 18.8, R@50 42.3MedR: 74, MeanR: 223.7
    epoch          : 2
    loss           : 0.029194543118383588
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022118540480732918
    val_t2v_metrics_R1: 3.8095238095238093
    val_t2v_metrics_R5: 12.172619047619047
    val_t2v_metrics_R10: 17.767857142857142
    val_t2v_metrics_R50: 40.0
    val_t2v_metrics_MedR: 85.5
    val_t2v_metrics_MeanR: 245.02619047619046
    val_t2v_metrics_geometric_mean_R1-R5-R10: 9.374826929341667
    val_v2t_metrics_R1: 4.6726190476190474
    val_v2t_metrics_R5: 12.916666666666666
    val_v2t_metrics_R10: 18.839285714285715
    val_v2t_metrics_R50: 42.291666666666664
    val_v2t_metrics_MedR: 74.0
    val_v2t_metrics_MeanR: 223.7328869047619
    val_v2t_metrics_geometric_mean_R1-R5-R10: 10.437386197616247
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.010866
Train Epoch: 3 [512/24098 (2%)] Loss: 0.010894
Train Epoch: 3 [1024/24098 (4%)] Loss: 0.010613
Train Epoch: 3 [1536/24098 (6%)] Loss: 0.006738
Train Epoch: 3 [2048/24098 (8%)] Loss: 0.011151
Train Epoch: 3 [2560/24098 (11%)] Loss: 0.008632
Train Epoch: 3 [3072/24098 (13%)] Loss: 0.010605
Train Epoch: 3 [3584/24098 (15%)] Loss: 0.007988
Train Epoch: 3 [4096/24098 (17%)] Loss: 0.009164
Train Epoch: 3 [4608/24098 (19%)] Loss: 0.008570
Train Epoch: 3 [5120/24098 (21%)] Loss: 0.008773
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.011149
Train Epoch: 3 [6144/24098 (25%)] Loss: 0.008616
Train Epoch: 3 [6656/24098 (28%)] Loss: 0.010318
Train Epoch: 3 [7168/24098 (30%)] Loss: 0.010051
Train Epoch: 3 [7680/24098 (32%)] Loss: 0.010748
Train Epoch: 3 [8192/24098 (34%)] Loss: 0.007372
Train Epoch: 3 [8704/24098 (36%)] Loss: 0.008389
Train Epoch: 3 [9216/24098 (38%)] Loss: 0.008062
Train Epoch: 3 [9728/24098 (40%)] Loss: 0.011392
Train Epoch: 3 [10240/24098 (42%)] Loss: 0.009339
Train Epoch: 3 [10752/24098 (45%)] Loss: 0.012704
Train Epoch: 3 [11264/24098 (47%)] Loss: 0.009843
Train Epoch: 3 [11776/24098 (49%)] Loss: 0.010240
Train Epoch: 3 [12288/24098 (51%)] Loss: 0.006008
Train Epoch: 3 [12800/24098 (53%)] Loss: 0.008410
Train Epoch: 3 [13312/24098 (55%)] Loss: 0.007070
Train Epoch: 3 [13824/24098 (57%)] Loss: 0.010333
Train Epoch: 3 [14336/24098 (59%)] Loss: 0.012912
Train Epoch: 3 [14848/24098 (62%)] Loss: 0.009088
Train Epoch: 3 [15360/24098 (64%)] Loss: 0.007601
Train Epoch: 3 [15872/24098 (66%)] Loss: 0.011424
Train Epoch: 3 [16384/24098 (68%)] Loss: 0.006735
Train Epoch: 3 [16896/24098 (70%)] Loss: 0.010390
Train Epoch: 3 [17408/24098 (72%)] Loss: 0.006071
Train Epoch: 3 [17920/24098 (74%)] Loss: 0.007735
Train Epoch: 3 [18432/24098 (76%)] Loss: 0.010661
Train Epoch: 3 [18944/24098 (79%)] Loss: 0.008928
Train Epoch: 3 [19456/24098 (81%)] Loss: 0.009531
Train Epoch: 3 [19968/24098 (83%)] Loss: 0.009594
Train Epoch: 3 [20480/24098 (85%)] Loss: 0.011046
Train Epoch: 3 [20992/24098 (87%)] Loss: 0.005936
Train Epoch: 3 [21504/24098 (89%)] Loss: 0.008824
Train Epoch: 3 [22016/24098 (91%)] Loss: 0.006637
Train Epoch: 3 [22528/24098 (93%)] Loss: 0.008364
Train Epoch: 3 [23040/24098 (96%)] Loss: 0.009621
Train Epoch: 3 [23552/24098 (98%)] Loss: 0.007667
Train Epoch: 3 [24064/24098 (100%)] Loss: 0.006156
[t2v_metrics]MovieClips epoch 3, R@1: 4.7, R@5: 14.6, R@10 22.2, R@50 45.4MedR: 65, MeanR: 212.0
[v2t_metrics]MovieClips epoch 3, R@1: 5.6, R@5: 16.2, R@10 23.1, R@50 46.4MedR: 60, MeanR: 201.3
    epoch          : 3
    loss           : 0.009025405472347054
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.020246103405952454
    val_t2v_metrics_R1: 4.7023809523809526
    val_t2v_metrics_R5: 14.642857142857142
    val_t2v_metrics_R10: 22.202380952380953
    val_t2v_metrics_R50: 45.357142857142854
    val_t2v_metrics_MedR: 65.0
    val_t2v_metrics_MeanR: 212.04791666666668
    val_t2v_metrics_geometric_mean_R1-R5-R10: 11.519873983456574
    val_v2t_metrics_R1: 5.625
    val_v2t_metrics_R5: 16.19047619047619
    val_v2t_metrics_R10: 23.095238095238095
    val_v2t_metrics_R50: 46.398809523809526
    val_v2t_metrics_MedR: 60.0
    val_v2t_metrics_MeanR: 201.2970238095238
    val_v2t_metrics_geometric_mean_R1-R5-R10: 12.81252908652399
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/24098 (0%)] Loss: 0.004581
Train Epoch: 4 [512/24098 (2%)] Loss: 0.003107
Train Epoch: 4 [1024/24098 (4%)] Loss: 0.002939
Train Epoch: 4 [1536/24098 (6%)] Loss: 0.003554
Train Epoch: 4 [2048/24098 (8%)] Loss: 0.002469
Train Epoch: 4 [2560/24098 (11%)] Loss: 0.002834
Train Epoch: 4 [3072/24098 (13%)] Loss: 0.002290
Train Epoch: 4 [3584/24098 (15%)] Loss: 0.003104
Train Epoch: 4 [4096/24098 (17%)] Loss: 0.003265
Train Epoch: 4 [4608/24098 (19%)] Loss: 0.002957
Train Epoch: 4 [5120/24098 (21%)] Loss: 0.004376
Train Epoch: 4 [5632/24098 (23%)] Loss: 0.003707
Train Epoch: 4 [6144/24098 (25%)] Loss: 0.002949
Train Epoch: 4 [6656/24098 (28%)] Loss: 0.002143
Train Epoch: 4 [7168/24098 (30%)] Loss: 0.003090
Train Epoch: 4 [7680/24098 (32%)] Loss: 0.002384
Train Epoch: 4 [8192/24098 (34%)] Loss: 0.002684
Train Epoch: 4 [8704/24098 (36%)] Loss: 0.002405
Train Epoch: 4 [9216/24098 (38%)] Loss: 0.003248
Train Epoch: 4 [9728/24098 (40%)] Loss: 0.003795
Train Epoch: 4 [10240/24098 (42%)] Loss: 0.002562
Train Epoch: 4 [10752/24098 (45%)] Loss: 0.003039
Train Epoch: 4 [11264/24098 (47%)] Loss: 0.003033
Train Epoch: 4 [11776/24098 (49%)] Loss: 0.002294
Train Epoch: 4 [12288/24098 (51%)] Loss: 0.002900
Train Epoch: 4 [12800/24098 (53%)] Loss: 0.003233
Train Epoch: 4 [13312/24098 (55%)] Loss: 0.003226
Train Epoch: 4 [13824/24098 (57%)] Loss: 0.003097
Train Epoch: 4 [14336/24098 (59%)] Loss: 0.002637
Train Epoch: 4 [14848/24098 (62%)] Loss: 0.002743
Train Epoch: 4 [15360/24098 (64%)] Loss: 0.003466
Train Epoch: 4 [15872/24098 (66%)] Loss: 0.003145
Train Epoch: 4 [16384/24098 (68%)] Loss: 0.002335
Train Epoch: 4 [16896/24098 (70%)] Loss: 0.004857
Train Epoch: 4 [17408/24098 (72%)] Loss: 0.003043
Train Epoch: 4 [17920/24098 (74%)] Loss: 0.002523
Train Epoch: 4 [18432/24098 (76%)] Loss: 0.002207
Train Epoch: 4 [18944/24098 (79%)] Loss: 0.003070
Train Epoch: 4 [19456/24098 (81%)] Loss: 0.002605
Train Epoch: 4 [19968/24098 (83%)] Loss: 0.003067
Train Epoch: 4 [20480/24098 (85%)] Loss: 0.002225
Train Epoch: 4 [20992/24098 (87%)] Loss: 0.002231
Train Epoch: 4 [21504/24098 (89%)] Loss: 0.004281
Train Epoch: 4 [22016/24098 (91%)] Loss: 0.002800
Train Epoch: 4 [22528/24098 (93%)] Loss: 0.002964
Train Epoch: 4 [23040/24098 (96%)] Loss: 0.003084
Train Epoch: 4 [23552/24098 (98%)] Loss: 0.001960
Train Epoch: 4 [24064/24098 (100%)] Loss: 0.003645
[t2v_metrics]MovieClips epoch 4, R@1: 6.8, R@5: 17.2, R@10 25.1, R@50 48.4MedR: 56, MeanR: 205.2
[v2t_metrics]MovieClips epoch 4, R@1: 7.0, R@5: 17.9, R@10 26.2, R@50 48.7MedR: 53.5, MeanR: 197.4
    epoch          : 4
    loss           : 0.0031277650840017225
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.02012140303850174
    val_t2v_metrics_R1: 6.785714285714286
    val_t2v_metrics_R5: 17.202380952380953
    val_t2v_metrics_R10: 25.089285714285715
    val_t2v_metrics_R50: 48.36309523809524
    val_t2v_metrics_MedR: 56.0
    val_t2v_metrics_MeanR: 205.22380952380954
    val_t2v_metrics_geometric_mean_R1-R5-R10: 14.30729315709891
    val_v2t_metrics_R1: 6.994047619047619
    val_v2t_metrics_R5: 17.946428571428573
    val_v2t_metrics_R10: 26.160714285714285
    val_v2t_metrics_R50: 48.660714285714285
    val_v2t_metrics_MedR: 53.5
    val_v2t_metrics_MeanR: 197.35565476190476
    val_v2t_metrics_geometric_mean_R1-R5-R10: 14.863419628785334
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch4.pth ...
Saving current best: model_best.pth ...
Train Epoch: 5 [0/24098 (0%)] Loss: 0.001152
Train Epoch: 5 [512/24098 (2%)] Loss: 0.001421
Train Epoch: 5 [1024/24098 (4%)] Loss: 0.001249
Train Epoch: 5 [1536/24098 (6%)] Loss: 0.001093
Train Epoch: 5 [2048/24098 (8%)] Loss: 0.001241
Train Epoch: 5 [2560/24098 (11%)] Loss: 0.001224
Train Epoch: 5 [3072/24098 (13%)] Loss: 0.001576
Train Epoch: 5 [3584/24098 (15%)] Loss: 0.001021
Train Epoch: 5 [4096/24098 (17%)] Loss: 0.001140
Train Epoch: 5 [4608/24098 (19%)] Loss: 0.001257
Train Epoch: 5 [5120/24098 (21%)] Loss: 0.001111
Train Epoch: 5 [5632/24098 (23%)] Loss: 0.001108
Train Epoch: 5 [6144/24098 (25%)] Loss: 0.000904
Train Epoch: 5 [6656/24098 (28%)] Loss: 0.001295
Train Epoch: 5 [7168/24098 (30%)] Loss: 0.000764
Train Epoch: 5 [7680/24098 (32%)] Loss: 0.001214
Train Epoch: 5 [8192/24098 (34%)] Loss: 0.001152
Train Epoch: 5 [8704/24098 (36%)] Loss: 0.001593
Train Epoch: 5 [9216/24098 (38%)] Loss: 0.001406
Train Epoch: 5 [9728/24098 (40%)] Loss: 0.001575
Train Epoch: 5 [10240/24098 (42%)] Loss: 0.001095
Train Epoch: 5 [10752/24098 (45%)] Loss: 0.001229
Train Epoch: 5 [11264/24098 (47%)] Loss: 0.001028
Train Epoch: 5 [11776/24098 (49%)] Loss: 0.001140
Train Epoch: 5 [12288/24098 (51%)] Loss: 0.001463
Train Epoch: 5 [12800/24098 (53%)] Loss: 0.001225
Train Epoch: 5 [13312/24098 (55%)] Loss: 0.001002
Train Epoch: 5 [13824/24098 (57%)] Loss: 0.001483
Train Epoch: 5 [14336/24098 (59%)] Loss: 0.001656
Train Epoch: 5 [14848/24098 (62%)] Loss: 0.000830
Train Epoch: 5 [15360/24098 (64%)] Loss: 0.001212
Train Epoch: 5 [15872/24098 (66%)] Loss: 0.001094
Train Epoch: 5 [16384/24098 (68%)] Loss: 0.000930
Train Epoch: 5 [16896/24098 (70%)] Loss: 0.001341
Train Epoch: 5 [17408/24098 (72%)] Loss: 0.001268
Train Epoch: 5 [17920/24098 (74%)] Loss: 0.001330
Train Epoch: 5 [18432/24098 (76%)] Loss: 0.000986
Train Epoch: 5 [18944/24098 (79%)] Loss: 0.000886
Train Epoch: 5 [19456/24098 (81%)] Loss: 0.001342
Train Epoch: 5 [19968/24098 (83%)] Loss: 0.001030
Train Epoch: 5 [20480/24098 (85%)] Loss: 0.001005
Train Epoch: 5 [20992/24098 (87%)] Loss: 0.000686
Train Epoch: 5 [21504/24098 (89%)] Loss: 0.001710
Train Epoch: 5 [22016/24098 (91%)] Loss: 0.001267
Train Epoch: 5 [22528/24098 (93%)] Loss: 0.001247
Train Epoch: 5 [23040/24098 (96%)] Loss: 0.001007
Train Epoch: 5 [23552/24098 (98%)] Loss: 0.001418
Train Epoch: 5 [24064/24098 (100%)] Loss: 0.001375
[t2v_metrics]MovieClips epoch 5, R@1: 6.5, R@5: 18.7, R@10 26.4, R@50 50.3MedR: 50, MeanR: 197.8
[v2t_metrics]MovieClips epoch 5, R@1: 7.8, R@5: 19.7, R@10 28.2, R@50 51.4MedR: 46, MeanR: 193.0
    epoch          : 5
    loss           : 0.0011810469620216351
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.020219581201672554
    val_t2v_metrics_R1: 6.488095238095238
    val_t2v_metrics_R5: 18.720238095238095
    val_t2v_metrics_R10: 26.428571428571427
    val_t2v_metrics_R50: 50.29761904761905
    val_t2v_metrics_MedR: 50.0
    val_t2v_metrics_MeanR: 197.80119047619047
    val_t2v_metrics_geometric_mean_R1-R5-R10: 14.751428917524892
    val_v2t_metrics_R1: 7.767857142857143
    val_v2t_metrics_R5: 19.672619047619047
    val_v2t_metrics_R10: 28.24404761904762
    val_v2t_metrics_R50: 51.398809523809526
    val_v2t_metrics_MedR: 46.0
    val_v2t_metrics_MeanR: 192.99107142857142
    val_v2t_metrics_geometric_mean_R1-R5-R10: 16.281588805569832
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch5.pth ...
Train Epoch: 6 [0/24098 (0%)] Loss: 0.000495
Train Epoch: 6 [512/24098 (2%)] Loss: 0.000630
Train Epoch: 6 [1024/24098 (4%)] Loss: 0.000548
Train Epoch: 6 [1536/24098 (6%)] Loss: 0.000691
Train Epoch: 6 [2048/24098 (8%)] Loss: 0.000613
Train Epoch: 6 [2560/24098 (11%)] Loss: 0.000669
Train Epoch: 6 [3072/24098 (13%)] Loss: 0.000681
Train Epoch: 6 [3584/24098 (15%)] Loss: 0.000476
Train Epoch: 6 [4096/24098 (17%)] Loss: 0.000613
Train Epoch: 6 [4608/24098 (19%)] Loss: 0.000625
Train Epoch: 6 [5120/24098 (21%)] Loss: 0.000482
Train Epoch: 6 [5632/24098 (23%)] Loss: 0.000703
Train Epoch: 6 [6144/24098 (25%)] Loss: 0.000476
Train Epoch: 6 [6656/24098 (28%)] Loss: 0.000627
Train Epoch: 6 [7168/24098 (30%)] Loss: 0.000586
Train Epoch: 6 [7680/24098 (32%)] Loss: 0.000588
Train Epoch: 6 [8192/24098 (34%)] Loss: 0.000395
Train Epoch: 6 [8704/24098 (36%)] Loss: 0.000573
Train Epoch: 6 [9216/24098 (38%)] Loss: 0.000403
Train Epoch: 6 [9728/24098 (40%)] Loss: 0.000510
Train Epoch: 6 [10240/24098 (42%)] Loss: 0.000695
Train Epoch: 6 [10752/24098 (45%)] Loss: 0.000582
Train Epoch: 6 [11264/24098 (47%)] Loss: 0.000573
Train Epoch: 6 [11776/24098 (49%)] Loss: 0.000667
Train Epoch: 6 [12288/24098 (51%)] Loss: 0.000490
Train Epoch: 6 [12800/24098 (53%)] Loss: 0.000626
Train Epoch: 6 [13312/24098 (55%)] Loss: 0.000423
Train Epoch: 6 [13824/24098 (57%)] Loss: 0.000482
Train Epoch: 6 [14336/24098 (59%)] Loss: 0.000349
Train Epoch: 6 [14848/24098 (62%)] Loss: 0.000455
Train Epoch: 6 [15360/24098 (64%)] Loss: 0.000595
Train Epoch: 6 [15872/24098 (66%)] Loss: 0.000617
Train Epoch: 6 [16384/24098 (68%)] Loss: 0.000477
Train Epoch: 6 [16896/24098 (70%)] Loss: 0.000508
Train Epoch: 6 [17408/24098 (72%)] Loss: 0.000594
Train Epoch: 6 [17920/24098 (74%)] Loss: 0.000698
Train Epoch: 6 [18432/24098 (76%)] Loss: 0.000530
Train Epoch: 6 [18944/24098 (79%)] Loss: 0.000555
Train Epoch: 6 [19456/24098 (81%)] Loss: 0.000939
Train Epoch: 6 [19968/24098 (83%)] Loss: 0.000614
Train Epoch: 6 [20480/24098 (85%)] Loss: 0.000692
Train Epoch: 6 [20992/24098 (87%)] Loss: 0.000596
Train Epoch: 6 [21504/24098 (89%)] Loss: 0.000605
Train Epoch: 6 [22016/24098 (91%)] Loss: 0.000447
Train Epoch: 6 [22528/24098 (93%)] Loss: 0.000589
Train Epoch: 6 [23040/24098 (96%)] Loss: 0.000747
Train Epoch: 6 [23552/24098 (98%)] Loss: 0.000858
Train Epoch: 6 [24064/24098 (100%)] Loss: 0.002505
[t2v_metrics]MovieClips epoch 6, R@1: 6.8, R@5: 19.0, R@10 27.4, R@50 51.4MedR: 47, MeanR: 202.0
[v2t_metrics]MovieClips epoch 6, R@1: 7.9, R@5: 19.1, R@10 27.2, R@50 50.9MedR: 47, MeanR: 203.3
    epoch          : 6
    loss           : 0.0005874129012844646
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.0213779304176569
    val_t2v_metrics_R1: 6.755952380952381
    val_t2v_metrics_R5: 19.047619047619047
    val_t2v_metrics_R10: 27.44047619047619
    val_t2v_metrics_R50: 51.36904761904762
    val_t2v_metrics_MedR: 47.0
    val_t2v_metrics_MeanR: 202.0482142857143
    val_t2v_metrics_geometric_mean_R1-R5-R10: 15.227886810308286
    val_v2t_metrics_R1: 7.857142857142857
    val_v2t_metrics_R5: 19.107142857142858
    val_v2t_metrics_R10: 27.172619047619047
    val_v2t_metrics_R50: 50.892857142857146
    val_v2t_metrics_MedR: 47.0
    val_v2t_metrics_MeanR: 203.28125
    val_v2t_metrics_geometric_mean_R1-R5-R10: 15.97830229780096
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch6.pth ...
Train Epoch: 7 [0/24098 (0%)] Loss: 0.000238
Train Epoch: 7 [512/24098 (2%)] Loss: 0.000407
Train Epoch: 7 [1024/24098 (4%)] Loss: 0.000574
Train Epoch: 7 [1536/24098 (6%)] Loss: 0.000421
Train Epoch: 7 [2048/24098 (8%)] Loss: 0.000705
Train Epoch: 7 [2560/24098 (11%)] Loss: 0.000646
Train Epoch: 7 [3072/24098 (13%)] Loss: 0.000509
Train Epoch: 7 [3584/24098 (15%)] Loss: 0.000398
Train Epoch: 7 [4096/24098 (17%)] Loss: 0.000435
Train Epoch: 7 [4608/24098 (19%)] Loss: 0.000401
Train Epoch: 7 [5120/24098 (21%)] Loss: 0.000256
Train Epoch: 7 [5632/24098 (23%)] Loss: 0.000403
Train Epoch: 7 [6144/24098 (25%)] Loss: 0.000377
Train Epoch: 7 [6656/24098 (28%)] Loss: 0.000347
Train Epoch: 7 [7168/24098 (30%)] Loss: 0.000301
Train Epoch: 7 [7680/24098 (32%)] Loss: 0.000375
Train Epoch: 7 [8192/24098 (34%)] Loss: 0.000309
Train Epoch: 7 [8704/24098 (36%)] Loss: 0.000181
Train Epoch: 7 [9216/24098 (38%)] Loss: 0.000276
Train Epoch: 7 [9728/24098 (40%)] Loss: 0.000537
Train Epoch: 7 [10240/24098 (42%)] Loss: 0.001403
Train Epoch: 7 [10752/24098 (45%)] Loss: 0.000310
Train Epoch: 7 [11264/24098 (47%)] Loss: 0.000369
Train Epoch: 7 [11776/24098 (49%)] Loss: 0.000587
Train Epoch: 7 [12288/24098 (51%)] Loss: 0.000374
Train Epoch: 7 [12800/24098 (53%)] Loss: 0.000234
Train Epoch: 7 [13312/24098 (55%)] Loss: 0.000576
Train Epoch: 7 [13824/24098 (57%)] Loss: 0.000629
Train Epoch: 7 [14336/24098 (59%)] Loss: 0.000394
Train Epoch: 7 [14848/24098 (62%)] Loss: 0.000318
Train Epoch: 7 [15360/24098 (64%)] Loss: 0.000580
Train Epoch: 7 [15872/24098 (66%)] Loss: 0.000417
Train Epoch: 7 [16384/24098 (68%)] Loss: 0.000464
Train Epoch: 7 [16896/24098 (70%)] Loss: 0.000417
Train Epoch: 7 [17408/24098 (72%)] Loss: 0.000247
Train Epoch: 7 [17920/24098 (74%)] Loss: 0.000364
Train Epoch: 7 [18432/24098 (76%)] Loss: 0.000360
Train Epoch: 7 [18944/24098 (79%)] Loss: 0.000521
Train Epoch: 7 [19456/24098 (81%)] Loss: 0.000328
Train Epoch: 7 [19968/24098 (83%)] Loss: 0.000756
Train Epoch: 7 [20480/24098 (85%)] Loss: 0.000395
Train Epoch: 7 [20992/24098 (87%)] Loss: 0.000472
Train Epoch: 7 [21504/24098 (89%)] Loss: 0.000213
Train Epoch: 7 [22016/24098 (91%)] Loss: 0.000237
Train Epoch: 7 [22528/24098 (93%)] Loss: 0.000407
Train Epoch: 7 [23040/24098 (96%)] Loss: 0.000322
Train Epoch: 7 [23552/24098 (98%)] Loss: 0.000378
Train Epoch: 7 [24064/24098 (100%)] Loss: 0.000228
[t2v_metrics]MovieClips epoch 7, R@1: 7.2, R@5: 19.3, R@10 28.0, R@50 51.6MedR: 46, MeanR: 202.4
[v2t_metrics]MovieClips epoch 7, R@1: 8.3, R@5: 20.5, R@10 29.1, R@50 52.1MedR: 45, MeanR: 198.8
    epoch          : 7
    loss           : 0.00037961123720094294
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.021571844816207886
    val_t2v_metrics_R1: 7.2023809523809526
    val_t2v_metrics_R5: 19.31547619047619
    val_t2v_metrics_R10: 27.976190476190474
    val_t2v_metrics_R50: 51.57738095238095
    val_t2v_metrics_MedR: 46.0
    val_t2v_metrics_MeanR: 202.39880952380952
    val_t2v_metrics_geometric_mean_R1-R5-R10: 15.72980581962749
    val_v2t_metrics_R1: 8.273809523809524
    val_v2t_metrics_R5: 20.535714285714285
    val_v2t_metrics_R10: 29.136904761904763
    val_v2t_metrics_R50: 52.142857142857146
    val_v2t_metrics_MedR: 45.0
    val_v2t_metrics_MeanR: 198.80416666666667
    val_v2t_metrics_geometric_mean_R1-R5-R10: 17.043269657477296
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch7.pth ...
Train Epoch: 8 [0/24098 (0%)] Loss: 0.000285
Train Epoch: 8 [512/24098 (2%)] Loss: 0.000182
Train Epoch: 8 [1024/24098 (4%)] Loss: 0.000251
Train Epoch: 8 [1536/24098 (6%)] Loss: 0.000276
Train Epoch: 8 [2048/24098 (8%)] Loss: 0.000354
Train Epoch: 8 [2560/24098 (11%)] Loss: 0.000222
Train Epoch: 8 [3072/24098 (13%)] Loss: 0.000201
Train Epoch: 8 [3584/24098 (15%)] Loss: 0.000432
Train Epoch: 8 [4096/24098 (17%)] Loss: 0.000219
Train Epoch: 8 [4608/24098 (19%)] Loss: 0.000190
Train Epoch: 8 [5120/24098 (21%)] Loss: 0.000198
Train Epoch: 8 [5632/24098 (23%)] Loss: 0.000415
Train Epoch: 8 [6144/24098 (25%)] Loss: 0.000288
Train Epoch: 8 [6656/24098 (28%)] Loss: 0.000214
Train Epoch: 8 [7168/24098 (30%)] Loss: 0.000234
Train Epoch: 8 [7680/24098 (32%)] Loss: 0.000183
Train Epoch: 8 [8192/24098 (34%)] Loss: 0.000267
Train Epoch: 8 [8704/24098 (36%)] Loss: 0.000170
Train Epoch: 8 [9216/24098 (38%)] Loss: 0.000217
Train Epoch: 8 [9728/24098 (40%)] Loss: 0.000240
Train Epoch: 8 [10240/24098 (42%)] Loss: 0.000237
Train Epoch: 8 [10752/24098 (45%)] Loss: 0.000418
Train Epoch: 8 [11264/24098 (47%)] Loss: 0.000172
Train Epoch: 8 [11776/24098 (49%)] Loss: 0.000247
Train Epoch: 8 [12288/24098 (51%)] Loss: 0.000187
Train Epoch: 8 [12800/24098 (53%)] Loss: 0.000250
Train Epoch: 8 [13312/24098 (55%)] Loss: 0.000227
Train Epoch: 8 [13824/24098 (57%)] Loss: 0.000442
Train Epoch: 8 [14336/24098 (59%)] Loss: 0.000430
Train Epoch: 8 [14848/24098 (62%)] Loss: 0.000218
Train Epoch: 8 [15360/24098 (64%)] Loss: 0.000357
Train Epoch: 8 [15872/24098 (66%)] Loss: 0.000241
Train Epoch: 8 [16384/24098 (68%)] Loss: 0.000139
Train Epoch: 8 [16896/24098 (70%)] Loss: 0.000219
Train Epoch: 8 [17408/24098 (72%)] Loss: 0.000263
Train Epoch: 8 [17920/24098 (74%)] Loss: 0.000407
Train Epoch: 8 [18432/24098 (76%)] Loss: 0.000635
Train Epoch: 8 [18944/24098 (79%)] Loss: 0.000237
Train Epoch: 8 [19456/24098 (81%)] Loss: 0.000224
Train Epoch: 8 [19968/24098 (83%)] Loss: 0.000304
Train Epoch: 8 [20480/24098 (85%)] Loss: 0.000264
Train Epoch: 8 [20992/24098 (87%)] Loss: 0.000184
Train Epoch: 8 [21504/24098 (89%)] Loss: 0.000216
Train Epoch: 8 [22016/24098 (91%)] Loss: 0.000481
Train Epoch: 8 [22528/24098 (93%)] Loss: 0.000341
Train Epoch: 8 [23040/24098 (96%)] Loss: 0.000200
Train Epoch: 8 [23552/24098 (98%)] Loss: 0.000260
Train Epoch: 8 [24064/24098 (100%)] Loss: 0.000405
[t2v_metrics]MovieClips epoch 8, R@1: 7.4, R@5: 20.1, R@10 28.2, R@50 51.6MedR: 46, MeanR: 207.0
[v2t_metrics]MovieClips epoch 8, R@1: 8.3, R@5: 20.7, R@10 29.2, R@50 52.3MedR: 42, MeanR: 204.7
    epoch          : 8
    loss           : 0.00025658158787534837
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022525060921907425
    val_t2v_metrics_R1: 7.410714285714286
    val_t2v_metrics_R5: 20.089285714285715
    val_t2v_metrics_R10: 28.24404761904762
    val_t2v_metrics_R50: 51.63690476190476
    val_t2v_metrics_MedR: 46.0
    val_t2v_metrics_MeanR: 207.0125
    val_t2v_metrics_geometric_mean_R1-R5-R10: 16.140506785203034
    val_v2t_metrics_R1: 8.333333333333334
    val_v2t_metrics_R5: 20.68452380952381
    val_v2t_metrics_R10: 29.166666666666668
    val_v2t_metrics_R50: 52.291666666666664
    val_v2t_metrics_MedR: 42.0
    val_v2t_metrics_MeanR: 204.7485119047619
    val_v2t_metrics_geometric_mean_R1-R5-R10: 17.131038580461436
Saving checkpoint: saved/models/MoEE/0318_083020/checkpoint-epoch8.pth ...
Train Epoch: 9 [0/24098 (0%)] Loss: 0.000044
Train Epoch: 9 [512/24098 (2%)] Loss: 0.000208
Train Epoch: 9 [1024/24098 (4%)] Loss: 0.000270
Train Epoch: 9 [1536/24098 (6%)] Loss: 0.000206
Train Epoch: 9 [2048/24098 (8%)] Loss: 0.000172
Train Epoch: 9 [2560/24098 (11%)] Loss: 0.000164
Train Epoch: 9 [3072/24098 (13%)] Loss: 0.000226
Train Epoch: 9 [3584/24098 (15%)] Loss: 0.000189
Train Epoch: 9 [4096/24098 (17%)] Loss: 0.000273
Train Epoch: 9 [4608/24098 (19%)] Loss: 0.000264
Train Epoch: 9 [5120/24098 (21%)] Loss: 0.000134
Train Epoch: 9 [5632/24098 (23%)] Loss: 0.000328
Train Epoch: 9 [6144/24098 (25%)] Loss: 0.000229
Train Epoch: 9 [6656/24098 (28%)] Loss: 0.000123
Train Epoch: 9 [7168/24098 (30%)] Loss: 0.000380
Train Epoch: 9 [7680/24098 (32%)] Loss: 0.000104
Train Epoch: 9 [8192/24098 (34%)] Loss: 0.000140
Train Epoch: 9 [8704/24098 (36%)] Loss: 0.000117
Train Epoch: 9 [9216/24098 (38%)] Loss: 0.000171
Train Epoch: 9 [9728/24098 (40%)] Loss: 0.000172
Train Epoch: 9 [10240/24098 (42%)] Loss: 0.000157
Train Epoch: 9 [10752/24098 (45%)] Loss: 0.000157
Train Epoch: 9 [11264/24098 (47%)] Loss: 0.000089
Train Epoch: 9 [11776/24098 (49%)] Loss: 0.000168
Train Epoch: 9 [12288/24098 (51%)] Loss: 0.000184
Train Epoch: 9 [12800/24098 (53%)] Loss: 0.000136
Train Epoch: 9 [13312/24098 (55%)] Loss: 0.000085
Train Epoch: 9 [13824/24098 (57%)] Loss: 0.000284
Train Epoch: 9 [14336/24098 (59%)] Loss: 0.000374
Train Epoch: 9 [14848/24098 (62%)] Loss: 0.000290
Train Epoch: 9 [15360/24098 (64%)] Loss: 0.000310
Train Epoch: 9 [15872/24098 (66%)] Loss: 0.000191
Train Epoch: 9 [16384/24098 (68%)] Loss: 0.000304
Train Epoch: 9 [16896/24098 (70%)] Loss: 0.000164
Train Epoch: 9 [17408/24098 (72%)] Loss: 0.000180
Train Epoch: 9 [17920/24098 (74%)] Loss: 0.000273
Train Epoch: 9 [18432/24098 (76%)] Loss: 0.000189
Train Epoch: 9 [18944/24098 (79%)] Loss: 0.000121
Train Epoch: 9 [19456/24098 (81%)] Loss: 0.000270
Train Epoch: 9 [19968/24098 (83%)] Loss: 0.000177
Train Epoch: 9 [20480/24098 (85%)] Loss: 0.000218
Train Epoch: 9 [20992/24098 (87%)] Loss: 0.000172
Train Epoch: 9 [21504/24098 (89%)] Loss: 0.000261
Train Epoch: 9 [22016/24098 (91%)] Loss: 0.000165
Train Epoch: 9 [22528/24098 (93%)] Loss: 0.000092
Train Epoch: 9 [23040/24098 (96%)] Loss: 0.000193
Train Epoch: 9 [23552/24098 (98%)] Loss: 0.000172
Train Epoch: 9 [24064/24098 (100%)] Loss: 0.000220
[t2v_metrics]MovieClips epoch 9, R@1: 7.1, R@5: 20.5, R@10 28.1, R@50 51.0MedR: 47, MeanR: 209.5
[v2t_metrics]MovieClips epoch 9, R@1: 8.0, R@5: 20.5, R@10 29.4, R@50 51.5MedR: 46, MeanR: 206.6
    epoch          : 9
    loss           : 0.0001893387702705934
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022937428206205368
    val_t2v_metrics_R1: 7.113095238095238
    val_t2v_metrics_R5: 20.50595238095238
    val_t2v_metrics_R10: 28.095238095238095
    val_t2v_metrics_R50: 51.041666666666664
    val_t2v_metrics_MedR: 47.0
    val_t2v_metrics_MeanR: 209.49166666666667
    val_t2v_metrics_geometric_mean_R1-R5-R10: 16.00259552497454
    val_v2t_metrics_R1: 8.035714285714286
    val_v2t_metrics_R5: 20.535714285714285
    val_v2t_metrics_R10: 29.404761904761905
    val_v2t_metrics_R50: 51.517857142857146
    val_v2t_metrics_MedR: 46.0
    val_v2t_metrics_MeanR: 206.56785714285715
    val_v2t_metrics_geometric_mean_R1-R5-R10: 16.929754319237407
Validation performance didn't improve for 4 epochs. Training stops.