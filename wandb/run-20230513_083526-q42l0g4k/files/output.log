loading features >>> [Total: 1.2s] (gnode080:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.8% of system memory 2.6 GB/131.3 GB
loading features >>> [Total: 35.3s] (gnode080:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.9% of system memory 6.9 GB/127.1 GB
loading features >>> [Total: 0.6s] (gnode080:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 5.9% of system memory 6.9 GB/127.1 GB
loading features >>> [Total: 1.2s] (gnode080:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.0% of system memory 7.1 GB/126.9 GB
loading features >>> [Total: 0.2s] (gnode080:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.1% of system memory 7.2 GB/126.8 GB
loading features >>> [Total: 28.4s] (gnode080:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
loading features >>> [Total: 0.7s] (gnode080:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
loading features >>> [Total: 0.7s] (gnode080:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.7% of system memory 9.2 GB/124.7 GB
train size: 24098 clips
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (scene): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=21, bias=True)
)
Trainable parameters: 50541651
Train Epoch: 1 [0/24098 (0%)] Loss: 0.120970
Train Epoch: 1 [1408/24098 (6%)] Loss: 0.121170
Train Epoch: 1 [2816/24098 (12%)] Loss: 0.120986
Train Epoch: 1 [4224/24098 (18%)] Loss: 0.120966
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.121154
Train Epoch: 1 [7040/24098 (29%)] Loss: 0.121096
Train Epoch: 1 [8448/24098 (35%)] Loss: 0.121088
Train Epoch: 1 [9856/24098 (41%)] Loss: 0.121098
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.121053
Train Epoch: 1 [12672/24098 (53%)] Loss: 0.121217
Train Epoch: 1 [14080/24098 (58%)] Loss: 0.121238
Train Epoch: 1 [15488/24098 (64%)] Loss: 0.121074
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.121204
Train Epoch: 1 [18304/24098 (76%)] Loss: 0.121281
Train Epoch: 1 [19712/24098 (82%)] Loss: 0.121061
Train Epoch: 1 [21120/24098 (88%)] Loss: 0.121206
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.121146
Train Epoch: 1 [23936/24098 (99%)] Loss: 0.121404
[t2v_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.1, R@10 0.2, R@50 1.7MedR: 1629, MeanR: 1649.0
[v2t_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.0, R@10 0.0, R@50 1.6MedR: 1655, MeanR: 1656.8
    epoch          : 1
    loss           : 0.12117205339449423
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.12118688225746155
    val_t2v_metrics_R1: 0.02976190476190476
    val_t2v_metrics_R5: 0.1488095238095238
    val_t2v_metrics_R10: 0.23809523809523808
    val_t2v_metrics_R50: 1.6964285714285714
    val_t2v_metrics_MedR: 1629.0
    val_t2v_metrics_MeanR: 1648.9683035714286
    val_t2v_metrics_geometric_mean_R1-R5-R10: 0.10178428254027956
    val_v2t_metrics_R1: 0.0
    val_v2t_metrics_R5: 0.0
    val_v2t_metrics_R10: 0.0
    val_v2t_metrics_R50: 1.6071428571428572
    val_v2t_metrics_MedR: 1655.0
    val_v2t_metrics_MeanR: 1656.8197916666666
    val_v2t_metrics_geometric_mean_R1-R5-R10: 0.0
/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/scipy/stats/stats.py:275: RuntimeWarning: divide by zero encountered in log
  log_a = np.log(np.array(a, dtype=dtype))
Saving checkpoint: FRS___/models/MoEE/0513_083519/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.121040
Train Epoch: 2 [1408/24098 (6%)] Loss: 0.107257
Train Epoch: 2 [2816/24098 (12%)] Loss: 0.088106
Train Epoch: 2 [4224/24098 (18%)] Loss: 0.070233
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.056084
Train Epoch: 2 [7040/24098 (29%)] Loss: 0.052468
Train Epoch: 2 [8448/24098 (35%)] Loss: 0.047502
Train Epoch: 2 [9856/24098 (41%)] Loss: 0.042470
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.044372
Train Epoch: 2 [12672/24098 (53%)] Loss: 0.040643
Train Epoch: 2 [14080/24098 (58%)] Loss: 0.042397
Train Epoch: 2 [15488/24098 (64%)] Loss: 0.034816
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.031456
Train Epoch: 2 [18304/24098 (76%)] Loss: 0.028297
Train Epoch: 2 [19712/24098 (82%)] Loss: 0.027968
Train Epoch: 2 [21120/24098 (88%)] Loss: 0.026627
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.030979
Train Epoch: 2 [23936/24098 (99%)] Loss: 0.026862
[t2v_metrics]MovieClips epoch 2, R@1: 2.1, R@5: 7.1, R@10 11.3, R@50 29.7MedR: 143, MeanR: 308.1
[v2t_metrics]MovieClips epoch 2, R@1: 2.4, R@5: 7.9, R@10 13.4, R@50 34.3MedR: 108, MeanR: 263.2
    epoch          : 2
    loss           : 0.04954765386209286
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.03153005242347717
    val_t2v_metrics_R1: 2.0535714285714284
    val_t2v_metrics_R5: 7.142857142857143
    val_t2v_metrics_R10: 11.279761904761905
    val_t2v_metrics_R50: 29.672619047619047
    val_t2v_metrics_MedR: 143.0
    val_t2v_metrics_MeanR: 308.08511904761906
    val_t2v_metrics_geometric_mean_R1-R5-R10: 5.4898511599739335
    val_v2t_metrics_R1: 2.4404761904761907
    val_v2t_metrics_R5: 7.857142857142857
    val_v2t_metrics_R10: 13.392857142857142
    val_v2t_metrics_R50: 34.285714285714285
    val_v2t_metrics_MedR: 108.0
    val_v2t_metrics_MeanR: 263.2232142857143
    val_v2t_metrics_geometric_mean_R1-R5-R10: 6.356296591108786
Saving checkpoint: FRS___/models/MoEE/0513_083519/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.025454
Train Epoch: 3 [1408/24098 (6%)] Loss: 0.021508
Train Epoch: 3 [2816/24098 (12%)] Loss: 0.021592
Train Epoch: 3 [4224/24098 (18%)] Loss: 0.019887
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.019801
Train Epoch: 3 [7040/24098 (29%)] Loss: 0.015887
Train Epoch: 3 [8448/24098 (35%)] Loss: 0.018524
Train Epoch: 3 [9856/24098 (41%)] Loss: 0.017094
Train Epoch: 3 [11264/24098 (47%)] Loss: 0.022973
Train Epoch: 3 [12672/24098 (53%)] Loss: 0.019587
Train Epoch: 3 [14080/24098 (58%)] Loss: 0.018766
Train Epoch: 3 [15488/24098 (64%)] Loss: 0.019277
Train Epoch: 3 [16896/24098 (70%)] Loss: 0.016594
Train Epoch: 3 [18304/24098 (76%)] Loss: 0.017088
Train Epoch: 3 [19712/24098 (82%)] Loss: 0.018109
Train Epoch: 3 [21120/24098 (88%)] Loss: 0.015470
Train Epoch: 3 [22528/24098 (93%)] Loss: 0.015826
Train Epoch: 3 [23936/24098 (99%)] Loss: 0.016436
[t2v_metrics]MovieClips epoch 3, R@1: 2.7, R@5: 10.1, R@10 16.0, R@50 40.1MedR: 84, MeanR: 221.3
[v2t_metrics]MovieClips epoch 3, R@1: 3.9, R@5: 12.8, R@10 19.8, R@50 45.0MedR: 62, MeanR: 189.7
    epoch          : 3
    loss           : 0.018731867377128866
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.024979708716273308
    val_t2v_metrics_R1: 2.738095238095238
    val_t2v_metrics_R5: 10.148809523809524
    val_t2v_metrics_R10: 16.041666666666668
    val_t2v_metrics_R50: 40.089285714285715
    val_t2v_metrics_MedR: 84.0
    val_t2v_metrics_MeanR: 221.2860119047619
    val_t2v_metrics_geometric_mean_R1-R5-R10: 7.63902116173075
    val_v2t_metrics_R1: 3.9285714285714284
    val_v2t_metrics_R5: 12.767857142857142
    val_v2t_metrics_R10: 19.761904761904763
    val_v2t_metrics_R50: 45.0
    val_v2t_metrics_MedR: 62.0
    val_v2t_metrics_MeanR: 189.71904761904761
    val_v2t_metrics_geometric_mean_R1-R5-R10: 9.970734610554555
Saving checkpoint: FRS___/models/MoEE/0513_083519/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/24098 (0%)] Loss: 0.009725
Train Epoch: 4 [1408/24098 (6%)] Loss: 0.013972
Train Epoch: 4 [2816/24098 (12%)] Loss: 0.011909
Train Epoch: 4 [4224/24098 (18%)] Loss: 0.010776
Train Epoch: 4 [5632/24098 (23%)] Loss: 0.010832
Train Epoch: 4 [7040/24098 (29%)] Loss: 0.010210
Train Epoch: 4 [8448/24098 (35%)] Loss: 0.011344
Train Epoch: 4 [9856/24098 (41%)] Loss: 0.011327
Train Epoch: 4 [11264/24098 (47%)] Loss: 0.010872
Train Epoch: 4 [12672/24098 (53%)] Loss: 0.012592
Train Epoch: 4 [14080/24098 (58%)] Loss: 0.008962
Train Epoch: 4 [15488/24098 (64%)] Loss: 0.009327
Train Epoch: 4 [16896/24098 (70%)] Loss: 0.010849
Train Epoch: 4 [18304/24098 (76%)] Loss: 0.009061
Train Epoch: 4 [19712/24098 (82%)] Loss: 0.008546
Train Epoch: 4 [21120/24098 (88%)] Loss: 0.008565
Train Epoch: 4 [22528/24098 (93%)] Loss: 0.010045
Train Epoch: 4 [23936/24098 (99%)] Loss: 0.011295
[t2v_metrics]MovieClips epoch 4, R@1: 3.9, R@5: 13.1, R@10 20.1, R@50 46.7MedR: 60, MeanR: 183.3
[v2t_metrics]MovieClips epoch 4, R@1: 4.5, R@5: 16.0, R@10 24.1, R@50 51.2MedR: 48, MeanR: 156.6
    epoch          : 4
    loss           : 0.01063867193700933
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022945169359445572
    val_t2v_metrics_R1: 3.9285714285714284
    val_t2v_metrics_R5: 13.125
    val_t2v_metrics_R10: 20.05952380952381
    val_t2v_metrics_R50: 46.666666666666664
    val_t2v_metrics_MedR: 60.0
    val_t2v_metrics_MeanR: 183.26815476190475
    val_t2v_metrics_geometric_mean_R1-R5-R10: 10.113113041311738
    val_v2t_metrics_R1: 4.464285714285714
    val_v2t_metrics_R5: 16.041666666666668
    val_v2t_metrics_R10: 24.136904761904763
    val_v2t_metrics_R50: 51.220238095238095
    val_v2t_metrics_MedR: 48.0
    val_v2t_metrics_MeanR: 156.61369047619047
    val_v2t_metrics_geometric_mean_R1-R5-R10: 12.001283143994305
Saving checkpoint: FRS___/models/MoEE/0513_083519/checkpoint-epoch4.pth ...
Saving current best: model_best.pth ...
Train Epoch: 5 [0/24098 (0%)] Loss: 0.005848
Train Epoch: 5 [1408/24098 (6%)] Loss: 0.005861
Train Epoch: 5 [2816/24098 (12%)] Loss: 0.006652
Train Epoch: 5 [4224/24098 (18%)] Loss: 0.006748
Train Epoch: 5 [5632/24098 (23%)] Loss: 0.007294
Train Epoch: 5 [7040/24098 (29%)] Loss: 0.005237
Train Epoch: 5 [8448/24098 (35%)] Loss: 0.007657
Train Epoch: 5 [9856/24098 (41%)] Loss: 0.006421
Train Epoch: 5 [11264/24098 (47%)] Loss: 0.006571
Train Epoch: 5 [12672/24098 (53%)] Loss: 0.006711
Train Epoch: 5 [14080/24098 (58%)] Loss: 0.006002
Train Epoch: 5 [15488/24098 (64%)] Loss: 0.006328
Train Epoch: 5 [16896/24098 (70%)] Loss: 0.005850
Train Epoch: 5 [18304/24098 (76%)] Loss: 0.006754
Train Epoch: 5 [19712/24098 (82%)] Loss: 0.005935
Train Epoch: 5 [21120/24098 (88%)] Loss: 0.005106
Train Epoch: 5 [22528/24098 (93%)] Loss: 0.005837
Train Epoch: 5 [23936/24098 (99%)] Loss: 0.005473
[t2v_metrics]MovieClips epoch 5, R@1: 4.8, R@5: 15.0, R@10 22.9, R@50 50.1MedR: 50, MeanR: 166.9
[v2t_metrics]MovieClips epoch 5, R@1: 5.9, R@5: 18.9, R@10 27.7, R@50 55.3MedR: 38, MeanR: 139.6
    epoch          : 5
    loss           : 0.006312333308554516
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.022197213023900986
    val_t2v_metrics_R1: 4.821428571428571
    val_t2v_metrics_R5: 15.029761904761905
    val_t2v_metrics_R10: 22.946428571428573
    val_t2v_metrics_R50: 50.089285714285715
    val_t2v_metrics_MedR: 50.0
    val_t2v_metrics_MeanR: 166.9202380952381
    val_t2v_metrics_geometric_mean_R1-R5-R10: 11.847161610948694
    val_v2t_metrics_R1: 5.892857142857143
    val_v2t_metrics_R5: 18.898809523809526
    val_v2t_metrics_R10: 27.738095238095237
    val_v2t_metrics_R50: 55.267857142857146
    val_v2t_metrics_MedR: 38.0
    val_v2t_metrics_MeanR: 139.62470238095239
    val_v2t_metrics_geometric_mean_R1-R5-R10: 14.563943940484256
Saving checkpoint: FRS___/models/MoEE/0513_083519/checkpoint-epoch5.pth ...
Saving current best: model_best.pth ...
Train Epoch: 6 [0/24098 (0%)] Loss: 0.004245
Train Epoch: 6 [1408/24098 (6%)] Loss: 0.003942