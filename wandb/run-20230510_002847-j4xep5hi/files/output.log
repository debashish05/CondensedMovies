loading features >>> [Total: 1.2s] (gnode086:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.9% of system memory 2.8 GB/131.2 GB
loading features >>> [Total: 35.5s] (gnode086:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 6.0% of system memory 7.1 GB/126.9 GB
loading features >>> [Total: 0.6s] (gnode086:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 6.0% of system memory 7.1 GB/126.9 GB
loading features >>> [Total: 1.2s] (gnode086:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.1% of system memory 7.2 GB/126.8 GB
loading features >>> [Total: 1.3s] (gnode086:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.3% of system memory 7.4 GB/126.6 GB
loading features >>> [Total: 16.9s] (gnode086:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 7.7% of system memory 9.3 GB/124.7 GB
loading features >>> [Total: 1.1s] (gnode086:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.7% of system memory 9.4 GB/124.6 GB
loading features >>> [Total: 0.6s] (gnode086:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.8% of system memory 9.4 GB/124.6 GB
train size: 24098 clips
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
>>> Currently using 7.8% of system memory 9.5 GB/124.5 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (scene): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=21, bias=True)
)
Trainable parameters: 50541651
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121227
Train Epoch: 1 [160/24098 (1%)] Loss: 0.121297
Train Epoch: 1 [320/24098 (1%)] Loss: 0.121458
Train Epoch: 1 [480/24098 (2%)] Loss: 0.121212
Train Epoch: 1 [640/24098 (3%)] Loss: 0.121311
Train Epoch: 1 [800/24098 (3%)] Loss: 0.121151
Train Epoch: 1 [960/24098 (4%)] Loss: 0.120772
Train Epoch: 1 [1120/24098 (5%)] Loss: 0.121107
Train Epoch: 1 [1280/24098 (5%)] Loss: 0.121140
Train Epoch: 1 [1440/24098 (6%)] Loss: 0.121051
Train Epoch: 1 [1600/24098 (7%)] Loss: 0.121053
Train Epoch: 1 [1760/24098 (7%)] Loss: 0.121210
Train Epoch: 1 [1920/24098 (8%)] Loss: 0.121207
Train Epoch: 1 [2080/24098 (9%)] Loss: 0.121335
Train Epoch: 1 [2240/24098 (9%)] Loss: 0.121416
Train Epoch: 1 [2400/24098 (10%)] Loss: 0.121508
Train Epoch: 1 [2560/24098 (11%)] Loss: 0.121282
Train Epoch: 1 [2720/24098 (11%)] Loss: 0.121295
Train Epoch: 1 [2880/24098 (12%)] Loss: 0.121056
Train Epoch: 1 [3040/24098 (13%)] Loss: 0.121110
Train Epoch: 1 [3200/24098 (13%)] Loss: 0.121105
Train Epoch: 1 [3360/24098 (14%)] Loss: 0.121049
Train Epoch: 1 [3520/24098 (15%)] Loss: 0.120837
Train Epoch: 1 [3680/24098 (15%)] Loss: 0.121336
Train Epoch: 1 [3840/24098 (16%)] Loss: 0.121463
Train Epoch: 1 [4000/24098 (17%)] Loss: 0.121611
Train Epoch: 1 [4160/24098 (17%)] Loss: 0.121172
Train Epoch: 1 [4320/24098 (18%)] Loss: 0.121025
Train Epoch: 1 [4480/24098 (19%)] Loss: 0.121323
Train Epoch: 1 [4640/24098 (19%)] Loss: 0.121635
Train Epoch: 1 [4800/24098 (20%)] Loss: 0.121202
Train Epoch: 1 [4960/24098 (21%)] Loss: 0.121006
Train Epoch: 1 [5120/24098 (21%)] Loss: 0.121480
Train Epoch: 1 [5280/24098 (22%)] Loss: 0.121868
Train Epoch: 1 [5440/24098 (23%)] Loss: 0.121299
Train Epoch: 1 [5600/24098 (23%)] Loss: 0.121032
Train Epoch: 1 [5760/24098 (24%)] Loss: 0.121418
Train Epoch: 1 [5920/24098 (25%)] Loss: 0.121769
Train Epoch: 1 [6080/24098 (25%)] Loss: 0.121563
Train Epoch: 1 [6240/24098 (26%)] Loss: 0.121215
Train Epoch: 1 [6400/24098 (27%)] Loss: 0.121115
Train Epoch: 1 [6560/24098 (27%)] Loss: 0.121082
Train Epoch: 1 [6720/24098 (28%)] Loss: 0.121267
Train Epoch: 1 [6880/24098 (29%)] Loss: 0.121025
Train Epoch: 1 [7040/24098 (29%)] Loss: 0.121521
Train Epoch: 1 [7200/24098 (30%)] Loss: 0.121165
Train Epoch: 1 [7360/24098 (31%)] Loss: 0.121512
Train Epoch: 1 [7520/24098 (31%)] Loss: 0.121218
Train Epoch: 1 [7680/24098 (32%)] Loss: 0.121360
Train Epoch: 1 [7840/24098 (33%)] Loss: 0.121201
Train Epoch: 1 [8000/24098 (33%)] Loss: 0.121656
Train Epoch: 1 [8160/24098 (34%)] Loss: 0.121738
Train Epoch: 1 [8320/24098 (35%)] Loss: 0.121130
Train Epoch: 1 [8480/24098 (35%)] Loss: 0.121015
Train Epoch: 1 [8640/24098 (36%)] Loss: 0.120769
Train Epoch: 1 [8800/24098 (37%)] Loss: 0.121077
Train Epoch: 1 [8960/24098 (37%)] Loss: 0.121169
Train Epoch: 1 [9120/24098 (38%)] Loss: 0.121479
Train Epoch: 1 [9280/24098 (39%)] Loss: 0.121164
Train Epoch: 1 [9440/24098 (39%)] Loss: 0.121128
Train Epoch: 1 [9600/24098 (40%)] Loss: 0.121342
Train Epoch: 1 [9760/24098 (41%)] Loss: 0.120618
Train Epoch: 1 [9920/24098 (41%)] Loss: 0.121083
Train Epoch: 1 [10080/24098 (42%)] Loss: 0.121771
Train Epoch: 1 [10240/24098 (42%)] Loss: 0.121514
Train Epoch: 1 [10400/24098 (43%)] Loss: 0.121316
Train Epoch: 1 [10560/24098 (44%)] Loss: 0.121105
Train Epoch: 1 [10720/24098 (44%)] Loss: 0.121595
Train Epoch: 1 [10880/24098 (45%)] Loss: 0.121232
Train Epoch: 1 [11040/24098 (46%)] Loss: 0.121089
Train Epoch: 1 [11200/24098 (46%)] Loss: 0.121278
Train Epoch: 1 [11360/24098 (47%)] Loss: 0.121258
Train Epoch: 1 [11520/24098 (48%)] Loss: 0.121092
Train Epoch: 1 [11680/24098 (48%)] Loss: 0.121297
Train Epoch: 1 [11840/24098 (49%)] Loss: 0.120851
Train Epoch: 1 [12000/24098 (50%)] Loss: 0.121352
Train Epoch: 1 [12160/24098 (50%)] Loss: 0.121376
Train Epoch: 1 [12320/24098 (51%)] Loss: 0.121311
Train Epoch: 1 [12480/24098 (52%)] Loss: 0.121154
Train Epoch: 1 [12640/24098 (52%)] Loss: 0.121240
Train Epoch: 1 [12800/24098 (53%)] Loss: 0.121032
Train Epoch: 1 [12960/24098 (54%)] Loss: 0.121758
Train Epoch: 1 [13120/24098 (54%)] Loss: 0.121240
Train Epoch: 1 [13280/24098 (55%)] Loss: 0.121294
Train Epoch: 1 [13440/24098 (56%)] Loss: 0.121153
Train Epoch: 1 [13600/24098 (56%)] Loss: 0.121519
Train Epoch: 1 [13760/24098 (57%)] Loss: 0.121381
Train Epoch: 1 [13920/24098 (58%)] Loss: 0.121292
Train Epoch: 1 [14080/24098 (58%)] Loss: 0.121149
Train Epoch: 1 [14240/24098 (59%)] Loss: 0.121152
Train Epoch: 1 [14400/24098 (60%)] Loss: 0.121431
Train Epoch: 1 [14560/24098 (60%)] Loss: 0.121535
Train Epoch: 1 [14720/24098 (61%)] Loss: 0.121122
Train Epoch: 1 [14880/24098 (62%)] Loss: 0.121368
Train Epoch: 1 [15040/24098 (62%)] Loss: 0.120815
Train Epoch: 1 [15200/24098 (63%)] Loss: 0.121089
Train Epoch: 1 [15360/24098 (64%)] Loss: 0.121113
Train Epoch: 1 [15520/24098 (64%)] Loss: 0.121002
Train Epoch: 1 [15680/24098 (65%)] Loss: 0.121144
Train Epoch: 1 [15840/24098 (66%)] Loss: 0.121193
Train Epoch: 1 [16000/24098 (66%)] Loss: 0.121352
Train Epoch: 1 [16160/24098 (67%)] Loss: 0.121328
Train Epoch: 1 [16320/24098 (68%)] Loss: 0.121245
Train Epoch: 1 [16480/24098 (68%)] Loss: 0.121793
Train Epoch: 1 [16640/24098 (69%)] Loss: 0.121798
Train Epoch: 1 [16800/24098 (70%)] Loss: 0.120992
Train Epoch: 1 [16960/24098 (70%)] Loss: 0.120994
Train Epoch: 1 [17120/24098 (71%)] Loss: 0.121150
Train Epoch: 1 [17280/24098 (72%)] Loss: 0.121528
Train Epoch: 1 [17440/24098 (72%)] Loss: 0.121366
Train Epoch: 1 [17600/24098 (73%)] Loss: 0.121144
Train Epoch: 1 [17760/24098 (74%)] Loss: 0.121208
Train Epoch: 1 [17920/24098 (74%)] Loss: 0.121074
Train Epoch: 1 [18080/24098 (75%)] Loss: 0.120917
Train Epoch: 1 [18240/24098 (76%)] Loss: 0.121470
Train Epoch: 1 [18400/24098 (76%)] Loss: 0.121374
Train Epoch: 1 [18560/24098 (77%)] Loss: 0.120870
Train Epoch: 1 [18720/24098 (78%)] Loss: 0.121263
Train Epoch: 1 [18880/24098 (78%)] Loss: 0.121514
Train Epoch: 1 [19040/24098 (79%)] Loss: 0.120923
Train Epoch: 1 [19200/24098 (80%)] Loss: 0.121344
Train Epoch: 1 [19360/24098 (80%)] Loss: 0.120577
Train Epoch: 1 [19520/24098 (81%)] Loss: 0.121508
Train Epoch: 1 [19680/24098 (82%)] Loss: 0.121383
Train Epoch: 1 [19840/24098 (82%)] Loss: 0.121178
Train Epoch: 1 [20000/24098 (83%)] Loss: 0.121025
Train Epoch: 1 [20160/24098 (84%)] Loss: 0.121157
Train Epoch: 1 [20320/24098 (84%)] Loss: 0.121343
Train Epoch: 1 [20480/24098 (85%)] Loss: 0.121147
Train Epoch: 1 [20640/24098 (86%)] Loss: 0.121174
Train Epoch: 1 [20800/24098 (86%)] Loss: 0.121098
Train Epoch: 1 [20960/24098 (87%)] Loss: 0.121246
Train Epoch: 1 [21120/24098 (88%)] Loss: 0.121147
Train Epoch: 1 [21280/24098 (88%)] Loss: 0.121923
Train Epoch: 1 [21440/24098 (89%)] Loss: 0.121778
Train Epoch: 1 [21600/24098 (90%)] Loss: 0.120996
Train Epoch: 1 [21760/24098 (90%)] Loss: 0.121364
Train Epoch: 1 [21920/24098 (91%)] Loss: 0.121284
Train Epoch: 1 [22080/24098 (92%)] Loss: 0.121331
Train Epoch: 1 [22240/24098 (92%)] Loss: 0.121509
Train Epoch: 1 [22400/24098 (93%)] Loss: 0.121438
Train Epoch: 1 [22560/24098 (94%)] Loss: 0.120870
Train Epoch: 1 [22720/24098 (94%)] Loss: 0.121058
Train Epoch: 1 [22880/24098 (95%)] Loss: 0.121085
Train Epoch: 1 [23040/24098 (96%)] Loss: 0.121449
Train Epoch: 1 [23200/24098 (96%)] Loss: 0.121108
Train Epoch: 1 [23360/24098 (97%)] Loss: 0.121619
Train Epoch: 1 [23520/24098 (98%)] Loss: 0.121484
Train Epoch: 1 [23680/24098 (98%)] Loss: 0.121137
Train Epoch: 1 [23840/24098 (99%)] Loss: 0.121086
Train Epoch: 1 [24000/24098 (100%)] Loss: 0.121422
Traceback (most recent call last):
  File "train.py", line 86, in <module>
    main(config)
  File "train.py", line 57, in main
    trainer.train()
  File "/home2/debashish.roy/CondensedMovies/base/base_trainer.py", line 68, in train
    result = self._train_epoch(epoch)
  File "/home2/debashish.roy/CondensedMovies/trainer/trainer.py", line 101, in _train_epoch
    val_log = self._valid_epoch(epoch)
  File "/home2/debashish.roy/CondensedMovies/trainer/trainer.py", line 134, in _valid_epoch
    for batch_idx, (minibatch, id) in enumerate(self.valid_data_loader):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1282, in _get_data
    success, data = self._try_get_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1120, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt