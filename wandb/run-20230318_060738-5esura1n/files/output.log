loading features >>> [Total: 0.4s] (gnode030:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.0% of system memory 1.6 GB/132.4 GB
loading features >>> [Total: 7.9s] (gnode030:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.2% of system memory 6.0 GB/128.0 GB
loading features >>> [Total: 0.2s] (gnode030:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 5.3% of system memory 6.0 GB/128.0 GB
loading features >>> [Total: 0.3s] (gnode030:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.3% of system memory 6.0 GB/128.0 GB
loading features >>> [Total: 0.9s] (gnode030:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.4% of system memory 6.2 GB/127.8 GB
loading features >>> [Total: 5.0s] (gnode030:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 6.8% of system memory 8.1 GB/125.9 GB
loading features >>> [Total: 0.3s] (gnode030:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 6.8% of system memory 8.1 GB/125.8 GB
loading features >>> [Total: 0.3s] (gnode030:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 6.9% of system memory 8.2 GB/125.8 GB
train size: 24098 clips
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
>>> Currently using 6.9% of system memory 8.2 GB/125.7 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=7, bias=True)
)
Trainable parameters: 50398249
/ssd_scratch/cvit/debashish/CondensedMovies/trainer/trainer.py:68: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly():
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121656
Train Epoch: 1 [512/24098 (2%)] Loss: 0.072781
Train Epoch: 1 [1024/24098 (4%)] Loss: 0.051286
Train Epoch: 1 [1536/24098 (6%)] Loss: 0.045916
Train Epoch: 1 [2048/24098 (8%)] Loss: 0.049835
Train Epoch: 1 [2560/24098 (11%)] Loss: 0.036000
Train Epoch: 1 [3072/24098 (13%)] Loss: 0.033513
Train Epoch: 1 [3584/24098 (15%)] Loss: 0.033088
Train Epoch: 1 [4096/24098 (17%)] Loss: 0.036531
Train Epoch: 1 [4608/24098 (19%)] Loss: 0.024499
Train Epoch: 1 [5120/24098 (21%)] Loss: 0.021268
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.021014
Train Epoch: 1 [6144/24098 (25%)] Loss: 0.026902
Train Epoch: 1 [6656/24098 (28%)] Loss: 0.020474
Train Epoch: 1 [7168/24098 (30%)] Loss: 0.016431
Train Epoch: 1 [7680/24098 (32%)] Loss: 0.016434
Train Epoch: 1 [8192/24098 (34%)] Loss: 0.023340
Train Epoch: 1 [8704/24098 (36%)] Loss: 0.028959
Train Epoch: 1 [9216/24098 (38%)] Loss: 0.018062
Train Epoch: 1 [9728/24098 (40%)] Loss: 0.018505
Train Epoch: 1 [10240/24098 (42%)] Loss: 0.015275
Train Epoch: 1 [10752/24098 (45%)] Loss: 0.012583
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.017478
Train Epoch: 1 [11776/24098 (49%)] Loss: 0.017016
Train Epoch: 1 [12288/24098 (51%)] Loss: 0.014675
Train Epoch: 1 [12800/24098 (53%)] Loss: 0.019176
Train Epoch: 1 [13312/24098 (55%)] Loss: 0.023141
Train Epoch: 1 [13824/24098 (57%)] Loss: 0.016470
Train Epoch: 1 [14336/24098 (59%)] Loss: 0.015855
Train Epoch: 1 [14848/24098 (62%)] Loss: 0.012493
Train Epoch: 1 [15360/24098 (64%)] Loss: 0.018428
Train Epoch: 1 [15872/24098 (66%)] Loss: 0.022434
Train Epoch: 1 [16384/24098 (68%)] Loss: 0.015196
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.016700
Train Epoch: 1 [17408/24098 (72%)] Loss: 0.013822
Train Epoch: 1 [17920/24098 (74%)] Loss: 0.011391
Train Epoch: 1 [18432/24098 (76%)] Loss: 0.016208
Train Epoch: 1 [18944/24098 (79%)] Loss: 0.015728
Train Epoch: 1 [19456/24098 (81%)] Loss: 0.016643
Train Epoch: 1 [19968/24098 (83%)] Loss: 0.012749
Train Epoch: 1 [20480/24098 (85%)] Loss: 0.015444
Train Epoch: 1 [20992/24098 (87%)] Loss: 0.018064
Train Epoch: 1 [21504/24098 (89%)] Loss: 0.011829
Train Epoch: 1 [22016/24098 (91%)] Loss: 0.016552
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.013992
Train Epoch: 1 [23040/24098 (96%)] Loss: 0.012391
Train Epoch: 1 [23552/24098 (98%)] Loss: 0.010716
Train Epoch: 1 [24064/24098 (100%)] Loss: 0.015363
[t2v_metrics]MovieClips epoch 1, R@1: 3.7, R@5: 14.2, R@10 22.3, R@50 48.2MedR: 55, MeanR: 173.8
[v2t_metrics]MovieClips epoch 1, R@1: 6.9, R@5: 18.9, R@10 27.4, R@50 52.4MedR: 46, MeanR: 150.8
    epoch          : 1
    loss           : 0.022394658743208694
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.0160981398075819
    val_t2v_metrics_R1: 3.6607142857142856
    val_t2v_metrics_R5: 14.226190476190476
    val_t2v_metrics_R10: 22.291666666666668
    val_t2v_metrics_R50: 48.214285714285715
    val_t2v_metrics_MedR: 55.0
    val_t2v_metrics_MeanR: 173.75684523809525
    val_t2v_metrics_geometric_mean_R1-R5-R10: 10.509910020095834
    val_v2t_metrics_R1: 6.904761904761905
    val_v2t_metrics_R5: 18.898809523809526
    val_v2t_metrics_R10: 27.351190476190474
    val_v2t_metrics_R50: 52.38095238095238
    val_v2t_metrics_MedR: 46.0
    val_v2t_metrics_MeanR: 150.78035714285716
    val_v2t_metrics_geometric_mean_R1-R5-R10: 15.282220553102077
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.007374
Train Epoch: 2 [512/24098 (2%)] Loss: 0.010774
Train Epoch: 2 [1024/24098 (4%)] Loss: 0.007244
Train Epoch: 2 [1536/24098 (6%)] Loss: 0.005083
Train Epoch: 2 [2048/24098 (8%)] Loss: 0.004467
Train Epoch: 2 [2560/24098 (11%)] Loss: 0.004982
Train Epoch: 2 [3072/24098 (13%)] Loss: 0.004626
Train Epoch: 2 [3584/24098 (15%)] Loss: 0.004556
Train Epoch: 2 [4096/24098 (17%)] Loss: 0.006437
Train Epoch: 2 [4608/24098 (19%)] Loss: 0.004215
Train Epoch: 2 [5120/24098 (21%)] Loss: 0.006324
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.004671
Train Epoch: 2 [6144/24098 (25%)] Loss: 0.005492
Train Epoch: 2 [6656/24098 (28%)] Loss: 0.004903
Train Epoch: 2 [7168/24098 (30%)] Loss: 0.005715
Train Epoch: 2 [7680/24098 (32%)] Loss: 0.004311
Train Epoch: 2 [8192/24098 (34%)] Loss: 0.003872
Train Epoch: 2 [8704/24098 (36%)] Loss: 0.005062
Train Epoch: 2 [9216/24098 (38%)] Loss: 0.006438
Train Epoch: 2 [9728/24098 (40%)] Loss: 0.004817
Train Epoch: 2 [10240/24098 (42%)] Loss: 0.005099
Train Epoch: 2 [10752/24098 (45%)] Loss: 0.004328
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.004210
Train Epoch: 2 [11776/24098 (49%)] Loss: 0.005429
Train Epoch: 2 [12288/24098 (51%)] Loss: 0.004761
Train Epoch: 2 [12800/24098 (53%)] Loss: 0.005657
Train Epoch: 2 [13312/24098 (55%)] Loss: 0.004187
Train Epoch: 2 [13824/24098 (57%)] Loss: 0.006278
Train Epoch: 2 [14336/24098 (59%)] Loss: 0.004504
Train Epoch: 2 [14848/24098 (62%)] Loss: 0.004893
Train Epoch: 2 [15360/24098 (64%)] Loss: 0.005558
Train Epoch: 2 [15872/24098 (66%)] Loss: 0.006917
Train Epoch: 2 [16384/24098 (68%)] Loss: 0.005491
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.004310
Train Epoch: 2 [17408/24098 (72%)] Loss: 0.006446
Train Epoch: 2 [17920/24098 (74%)] Loss: 0.003519
Train Epoch: 2 [18432/24098 (76%)] Loss: 0.003334
Train Epoch: 2 [18944/24098 (79%)] Loss: 0.004151
Train Epoch: 2 [19456/24098 (81%)] Loss: 0.003839
Train Epoch: 2 [19968/24098 (83%)] Loss: 0.004626
Train Epoch: 2 [20480/24098 (85%)] Loss: 0.004494
Train Epoch: 2 [20992/24098 (87%)] Loss: 0.004241
Train Epoch: 2 [21504/24098 (89%)] Loss: 0.004111
Train Epoch: 2 [22016/24098 (91%)] Loss: 0.007239
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.004513
Train Epoch: 2 [23040/24098 (96%)] Loss: 0.005554
Train Epoch: 2 [23552/24098 (98%)] Loss: 0.004152
Train Epoch: 2 [24064/24098 (100%)] Loss: 0.005154
[t2v_metrics]MovieClips epoch 2, R@1: 7.1, R@5: 21.2, R@10 30.4, R@50 56.4MedR: 36, MeanR: 137.4
[v2t_metrics]MovieClips epoch 2, R@1: 9.6, R@5: 24.9, R@10 34.4, R@50 59.8MedR: 29, MeanR: 124.5
    epoch          : 2
    loss           : 0.005013092420377648
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.013390995562076569
    val_t2v_metrics_R1: 7.083333333333333
    val_t2v_metrics_R5: 21.19047619047619
    val_t2v_metrics_R10: 30.416666666666668
    val_t2v_metrics_R50: 56.42857142857143
    val_t2v_metrics_MedR: 36.0
    val_t2v_metrics_MeanR: 137.39285714285714
    val_t2v_metrics_geometric_mean_R1-R5-R10: 16.589374249900562
    val_v2t_metrics_R1: 9.583333333333334
    val_v2t_metrics_R5: 24.910714285714285
    val_v2t_metrics_R10: 34.375
    val_v2t_metrics_R50: 59.791666666666664
    val_v2t_metrics_MedR: 29.0
    val_v2t_metrics_MeanR: 124.54345238095237
    val_v2t_metrics_geometric_mean_R1-R5-R10: 20.170430178137302
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.001285
Train Epoch: 3 [512/24098 (2%)] Loss: 0.001291
Train Epoch: 3 [1024/24098 (4%)] Loss: 0.002019
Train Epoch: 3 [1536/24098 (6%)] Loss: 0.000983
Train Epoch: 3 [2048/24098 (8%)] Loss: 0.001317
Train Epoch: 3 [2560/24098 (11%)] Loss: 0.001245
Train Epoch: 3 [3072/24098 (13%)] Loss: 0.001418
Train Epoch: 3 [3584/24098 (15%)] Loss: 0.001118
Train Epoch: 3 [4096/24098 (17%)] Loss: 0.001761
Train Epoch: 3 [4608/24098 (19%)] Loss: 0.001349
Train Epoch: 3 [5120/24098 (21%)] Loss: 0.000929
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.001179
Train Epoch: 3 [6144/24098 (25%)] Loss: 0.001008
Train Epoch: 3 [6656/24098 (28%)] Loss: 0.001796
Train Epoch: 3 [7168/24098 (30%)] Loss: 0.002096
Train Epoch: 3 [7680/24098 (32%)] Loss: 0.001388
Train Epoch: 3 [8192/24098 (34%)] Loss: 0.001134
Train Epoch: 3 [8704/24098 (36%)] Loss: 0.001498
Train Epoch: 3 [9216/24098 (38%)] Loss: 0.001904
Train Epoch: 3 [9728/24098 (40%)] Loss: 0.000901
Train Epoch: 3 [10240/24098 (42%)] Loss: 0.001407
Train Epoch: 3 [10752/24098 (45%)] Loss: 0.001335
Train Epoch: 3 [11264/24098 (47%)] Loss: 0.001165
Train Epoch: 3 [11776/24098 (49%)] Loss: 0.001509
Train Epoch: 3 [12288/24098 (51%)] Loss: 0.001841
Train Epoch: 3 [12800/24098 (53%)] Loss: 0.001336
Train Epoch: 3 [13312/24098 (55%)] Loss: 0.001265
Train Epoch: 3 [13824/24098 (57%)] Loss: 0.000994
Train Epoch: 3 [14336/24098 (59%)] Loss: 0.001517
Train Epoch: 3 [14848/24098 (62%)] Loss: 0.001654
Train Epoch: 3 [15360/24098 (64%)] Loss: 0.000964
Train Epoch: 3 [15872/24098 (66%)] Loss: 0.001177
Train Epoch: 3 [16384/24098 (68%)] Loss: 0.001102
Train Epoch: 3 [16896/24098 (70%)] Loss: 0.000965
Train Epoch: 3 [17408/24098 (72%)] Loss: 0.001157
Train Epoch: 3 [17920/24098 (74%)] Loss: 0.001228
Train Epoch: 3 [18432/24098 (76%)] Loss: 0.001372
Train Epoch: 3 [18944/24098 (79%)] Loss: 0.001413
Train Epoch: 3 [19456/24098 (81%)] Loss: 0.001114
Train Epoch: 3 [19968/24098 (83%)] Loss: 0.001013
Train Epoch: 3 [20480/24098 (85%)] Loss: 0.001233
Train Epoch: 3 [20992/24098 (87%)] Loss: 0.001440
Train Epoch: 3 [21504/24098 (89%)] Loss: 0.001319
Train Epoch: 3 [22016/24098 (91%)] Loss: 0.001279
Train Epoch: 3 [22528/24098 (93%)] Loss: 0.001366
Train Epoch: 3 [23040/24098 (96%)] Loss: 0.001307
Train Epoch: 3 [23552/24098 (98%)] Loss: 0.001498
Train Epoch: 3 [24064/24098 (100%)] Loss: 0.000736
[t2v_metrics]MovieClips epoch 3, R@1: 8.8, R@5: 25.2, R@10 34.7, R@50 61.1MedR: 26, MeanR: 121.9
[v2t_metrics]MovieClips epoch 3, R@1: 12.3, R@5: 29.8, R@10 38.9, R@50 63.5MedR: 22, MeanR: 111.9
    epoch          : 3
    loss           : 0.0014034923445803932
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.012371588498353958
    val_t2v_metrics_R1: 8.75
    val_t2v_metrics_R5: 25.178571428571427
    val_t2v_metrics_R10: 34.732142857142854
    val_t2v_metrics_R50: 61.101190476190474
    val_t2v_metrics_MedR: 26.0
    val_t2v_metrics_MeanR: 121.93809523809524
    val_t2v_metrics_geometric_mean_R1-R5-R10: 19.705626145407532
    val_v2t_metrics_R1: 12.261904761904763
    val_v2t_metrics_R5: 29.761904761904763
    val_v2t_metrics_R10: 38.86904761904762
    val_v2t_metrics_R50: 63.51190476190476
    val_v2t_metrics_MedR: 22.0
    val_v2t_metrics_MeanR: 111.94583333333334
    val_v2t_metrics_geometric_mean_R1-R5-R10: 24.206993501689226
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/24098 (0%)] Loss: 0.000395
Train Epoch: 4 [512/24098 (2%)] Loss: 0.000923
Train Epoch: 4 [1024/24098 (4%)] Loss: 0.000448
Train Epoch: 4 [1536/24098 (6%)] Loss: 0.000391
Train Epoch: 4 [2048/24098 (8%)] Loss: 0.000425
Train Epoch: 4 [2560/24098 (11%)] Loss: 0.000585
Train Epoch: 4 [3072/24098 (13%)] Loss: 0.000486
Train Epoch: 4 [3584/24098 (15%)] Loss: 0.000601
Train Epoch: 4 [4096/24098 (17%)] Loss: 0.000537
Train Epoch: 4 [4608/24098 (19%)] Loss: 0.000365
Train Epoch: 4 [5120/24098 (21%)] Loss: 0.000685
Train Epoch: 4 [5632/24098 (23%)] Loss: 0.000495
Train Epoch: 4 [6144/24098 (25%)] Loss: 0.000531
Train Epoch: 4 [6656/24098 (28%)] Loss: 0.000478
Train Epoch: 4 [7168/24098 (30%)] Loss: 0.000526
Train Epoch: 4 [7680/24098 (32%)] Loss: 0.000340
Train Epoch: 4 [8192/24098 (34%)] Loss: 0.000536
Train Epoch: 4 [8704/24098 (36%)] Loss: 0.000686
Train Epoch: 4 [9216/24098 (38%)] Loss: 0.000414
Train Epoch: 4 [9728/24098 (40%)] Loss: 0.000439
Train Epoch: 4 [10240/24098 (42%)] Loss: 0.000453
Train Epoch: 4 [10752/24098 (45%)] Loss: 0.000543
Train Epoch: 4 [11264/24098 (47%)] Loss: 0.000409
Train Epoch: 4 [11776/24098 (49%)] Loss: 0.000405
Train Epoch: 4 [12288/24098 (51%)] Loss: 0.000764
Train Epoch: 4 [12800/24098 (53%)] Loss: 0.000722
Train Epoch: 4 [13312/24098 (55%)] Loss: 0.000638
Train Epoch: 4 [13824/24098 (57%)] Loss: 0.000675
Train Epoch: 4 [14336/24098 (59%)] Loss: 0.000321
Train Epoch: 4 [14848/24098 (62%)] Loss: 0.000656
Train Epoch: 4 [15360/24098 (64%)] Loss: 0.000799
Train Epoch: 4 [15872/24098 (66%)] Loss: 0.000452
Train Epoch: 4 [16384/24098 (68%)] Loss: 0.000416
Train Epoch: 4 [16896/24098 (70%)] Loss: 0.000529
Train Epoch: 4 [17408/24098 (72%)] Loss: 0.000564
Train Epoch: 4 [17920/24098 (74%)] Loss: 0.000356
Train Epoch: 4 [18432/24098 (76%)] Loss: 0.000630
Train Epoch: 4 [18944/24098 (79%)] Loss: 0.000838
Train Epoch: 4 [19456/24098 (81%)] Loss: 0.000401
Train Epoch: 4 [19968/24098 (83%)] Loss: 0.000570
Train Epoch: 4 [20480/24098 (85%)] Loss: 0.000694
Train Epoch: 4 [20992/24098 (87%)] Loss: 0.000495
Train Epoch: 4 [21504/24098 (89%)] Loss: 0.000515
Train Epoch: 4 [22016/24098 (91%)] Loss: 0.000747
Train Epoch: 4 [22528/24098 (93%)] Loss: 0.000587
Train Epoch: 4 [23040/24098 (96%)] Loss: 0.000673
Train Epoch: 4 [23552/24098 (98%)] Loss: 0.000425
Train Epoch: 4 [24064/24098 (100%)] Loss: 0.000762
[t2v_metrics]MovieClips epoch 4, R@1: 10.0, R@5: 26.9, R@10 37.0, R@50 63.2MedR: 24, MeanR: 121.7
[v2t_metrics]MovieClips epoch 4, R@1: 12.6, R@5: 30.5, R@10 39.6, R@50 65.2MedR: 21, MeanR: 111.8
    epoch          : 4
    loss           : 0.0005774777820327663
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.012675229460000992
    val_t2v_metrics_R1: 9.970238095238095
    val_t2v_metrics_R5: 26.875
    val_t2v_metrics_R10: 36.99404761904762
    val_t2v_metrics_R50: 63.18452380952381
    val_t2v_metrics_MedR: 24.0
    val_t2v_metrics_MeanR: 121.70892857142857
    val_t2v_metrics_geometric_mean_R1-R5-R10: 21.48136879878184
    val_v2t_metrics_R1: 12.619047619047619
    val_v2t_metrics_R5: 30.50595238095238
    val_v2t_metrics_R10: 39.642857142857146
    val_v2t_metrics_R50: 65.20833333333333
    val_v2t_metrics_MedR: 21.0
    val_v2t_metrics_MeanR: 111.78779761904762
    val_v2t_metrics_geometric_mean_R1-R5-R10: 24.80420840023414
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch4.pth ...
Train Epoch: 5 [0/24098 (0%)] Loss: 0.000203
Train Epoch: 5 [512/24098 (2%)] Loss: 0.000232
Train Epoch: 5 [1024/24098 (4%)] Loss: 0.000239
Train Epoch: 5 [1536/24098 (6%)] Loss: 0.000281
Train Epoch: 5 [2048/24098 (8%)] Loss: 0.000343
Train Epoch: 5 [2560/24098 (11%)] Loss: 0.000409
Train Epoch: 5 [3072/24098 (13%)] Loss: 0.000371
Train Epoch: 5 [3584/24098 (15%)] Loss: 0.000283
Train Epoch: 5 [4096/24098 (17%)] Loss: 0.000590
Train Epoch: 5 [4608/24098 (19%)] Loss: 0.000381
Train Epoch: 5 [5120/24098 (21%)] Loss: 0.000362
Train Epoch: 5 [5632/24098 (23%)] Loss: 0.000563
Train Epoch: 5 [6144/24098 (25%)] Loss: 0.000425
Train Epoch: 5 [6656/24098 (28%)] Loss: 0.000500
Train Epoch: 5 [7168/24098 (30%)] Loss: 0.000147
Train Epoch: 5 [7680/24098 (32%)] Loss: 0.000311
Train Epoch: 5 [8192/24098 (34%)] Loss: 0.000415
Train Epoch: 5 [8704/24098 (36%)] Loss: 0.000323
Train Epoch: 5 [9216/24098 (38%)] Loss: 0.000103
Train Epoch: 5 [9728/24098 (40%)] Loss: 0.000325
Train Epoch: 5 [10240/24098 (42%)] Loss: 0.000300
Train Epoch: 5 [10752/24098 (45%)] Loss: 0.000282
Train Epoch: 5 [11264/24098 (47%)] Loss: 0.000337
Train Epoch: 5 [11776/24098 (49%)] Loss: 0.000256
Train Epoch: 5 [12288/24098 (51%)] Loss: 0.000255
Train Epoch: 5 [12800/24098 (53%)] Loss: 0.000460
Train Epoch: 5 [13312/24098 (55%)] Loss: 0.000220
Train Epoch: 5 [13824/24098 (57%)] Loss: 0.000278
Train Epoch: 5 [14336/24098 (59%)] Loss: 0.000152
Train Epoch: 5 [14848/24098 (62%)] Loss: 0.000211
Train Epoch: 5 [15360/24098 (64%)] Loss: 0.000198
Train Epoch: 5 [15872/24098 (66%)] Loss: 0.000445
Train Epoch: 5 [16384/24098 (68%)] Loss: 0.000104
Train Epoch: 5 [16896/24098 (70%)] Loss: 0.000213
Train Epoch: 5 [17408/24098 (72%)] Loss: 0.000538
Train Epoch: 5 [17920/24098 (74%)] Loss: 0.000214
Train Epoch: 5 [18432/24098 (76%)] Loss: 0.000314
Train Epoch: 5 [18944/24098 (79%)] Loss: 0.000182
Train Epoch: 5 [19456/24098 (81%)] Loss: 0.000221
Train Epoch: 5 [19968/24098 (83%)] Loss: 0.000447
Train Epoch: 5 [20480/24098 (85%)] Loss: 0.000332
Train Epoch: 5 [20992/24098 (87%)] Loss: 0.000323
Train Epoch: 5 [21504/24098 (89%)] Loss: 0.000405
Train Epoch: 5 [22016/24098 (91%)] Loss: 0.000320
Train Epoch: 5 [22528/24098 (93%)] Loss: 0.000294
Train Epoch: 5 [23040/24098 (96%)] Loss: 0.000117
Train Epoch: 5 [23552/24098 (98%)] Loss: 0.000190
Train Epoch: 5 [24064/24098 (100%)] Loss: 0.000398
[t2v_metrics]MovieClips epoch 5, R@1: 9.9, R@5: 28.5, R@10 38.8, R@50 65.0MedR: 21, MeanR: 119.8
[v2t_metrics]MovieClips epoch 5, R@1: 13.9, R@5: 32.0, R@10 41.7, R@50 67.1MedR: 18, MeanR: 110.5
    epoch          : 5
    loss           : 0.0003176526009708529
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.012921357527375221
    val_t2v_metrics_R1: 9.910714285714286
    val_t2v_metrics_R5: 28.452380952380953
    val_t2v_metrics_R10: 38.75
    val_t2v_metrics_R50: 65.0
    val_t2v_metrics_MedR: 21.0
    val_t2v_metrics_MeanR: 119.82380952380953
    val_t2v_metrics_geometric_mean_R1-R5-R10: 22.190398048229273
    val_v2t_metrics_R1: 13.928571428571429
    val_v2t_metrics_R5: 32.023809523809526
    val_v2t_metrics_R10: 41.69642857142857
    val_v2t_metrics_R50: 67.11309523809524
    val_v2t_metrics_MedR: 18.0
    val_v2t_metrics_MeanR: 110.46517857142857
    val_v2t_metrics_geometric_mean_R1-R5-R10: 26.494728641672687
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch5.pth ...
Train Epoch: 6 [0/24098 (0%)] Loss: 0.000092
Train Epoch: 6 [512/24098 (2%)] Loss: 0.000250
Train Epoch: 6 [1024/24098 (4%)] Loss: 0.000278
Train Epoch: 6 [1536/24098 (6%)] Loss: 0.000270
Train Epoch: 6 [2048/24098 (8%)] Loss: 0.000220
Train Epoch: 6 [2560/24098 (11%)] Loss: 0.000161
Train Epoch: 6 [3072/24098 (13%)] Loss: 0.000321
Train Epoch: 6 [3584/24098 (15%)] Loss: 0.000186
Train Epoch: 6 [4096/24098 (17%)] Loss: 0.000169
Train Epoch: 6 [4608/24098 (19%)] Loss: 0.000207
Train Epoch: 6 [5120/24098 (21%)] Loss: 0.000133
Train Epoch: 6 [5632/24098 (23%)] Loss: 0.000193
Train Epoch: 6 [6144/24098 (25%)] Loss: 0.000314
Train Epoch: 6 [6656/24098 (28%)] Loss: 0.000385
Train Epoch: 6 [7168/24098 (30%)] Loss: 0.000139
Train Epoch: 6 [7680/24098 (32%)] Loss: 0.000198
Train Epoch: 6 [8192/24098 (34%)] Loss: 0.000147
Train Epoch: 6 [8704/24098 (36%)] Loss: 0.001038
Train Epoch: 6 [9216/24098 (38%)] Loss: 0.000112
Train Epoch: 6 [9728/24098 (40%)] Loss: 0.000205
Train Epoch: 6 [10240/24098 (42%)] Loss: 0.000212
Train Epoch: 6 [10752/24098 (45%)] Loss: 0.000223
Train Epoch: 6 [11264/24098 (47%)] Loss: 0.000491
Train Epoch: 6 [11776/24098 (49%)] Loss: 0.000170
Train Epoch: 6 [12288/24098 (51%)] Loss: 0.000276
Train Epoch: 6 [12800/24098 (53%)] Loss: 0.000184
Train Epoch: 6 [13312/24098 (55%)] Loss: 0.000227
Train Epoch: 6 [13824/24098 (57%)] Loss: 0.000138
Train Epoch: 6 [14336/24098 (59%)] Loss: 0.000186
Train Epoch: 6 [14848/24098 (62%)] Loss: 0.000196
Train Epoch: 6 [15360/24098 (64%)] Loss: 0.000157
Train Epoch: 6 [15872/24098 (66%)] Loss: 0.000215
Train Epoch: 6 [16384/24098 (68%)] Loss: 0.000214
Train Epoch: 6 [16896/24098 (70%)] Loss: 0.000359
Train Epoch: 6 [17408/24098 (72%)] Loss: 0.000230
Train Epoch: 6 [17920/24098 (74%)] Loss: 0.000243
Train Epoch: 6 [18432/24098 (76%)] Loss: 0.000238
Train Epoch: 6 [18944/24098 (79%)] Loss: 0.000144
Train Epoch: 6 [19456/24098 (81%)] Loss: 0.000289
Train Epoch: 6 [19968/24098 (83%)] Loss: 0.000309
Train Epoch: 6 [20480/24098 (85%)] Loss: 0.000154
Train Epoch: 6 [20992/24098 (87%)] Loss: 0.000193
Train Epoch: 6 [21504/24098 (89%)] Loss: 0.000319
Train Epoch: 6 [22016/24098 (91%)] Loss: 0.000305
Train Epoch: 6 [22528/24098 (93%)] Loss: 0.000218
Train Epoch: 6 [23040/24098 (96%)] Loss: 0.000281
Train Epoch: 6 [23552/24098 (98%)] Loss: 0.000214
Train Epoch: 6 [24064/24098 (100%)] Loss: 0.000084
[t2v_metrics]MovieClips epoch 6, R@1: 11.5, R@5: 29.0, R@10 39.3, R@50 65.0MedR: 20, MeanR: 121.0
[v2t_metrics]MovieClips epoch 6, R@1: 13.9, R@5: 31.5, R@10 41.1, R@50 65.8MedR: 19, MeanR: 113.5
    epoch          : 6
    loss           : 0.00021344986627848302
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.013309947215020657
    val_t2v_metrics_R1: 11.458333333333334
    val_t2v_metrics_R5: 28.988095238095237
    val_t2v_metrics_R10: 39.345238095238095
    val_t2v_metrics_R50: 65.0297619047619
    val_t2v_metrics_MedR: 20.0
    val_t2v_metrics_MeanR: 120.98779761904763
    val_t2v_metrics_geometric_mean_R1-R5-R10: 23.55471043999568
    val_v2t_metrics_R1: 13.898809523809524
    val_v2t_metrics_R5: 31.517857142857142
    val_v2t_metrics_R10: 41.13095238095238
    val_v2t_metrics_R50: 65.80357142857143
    val_v2t_metrics_MedR: 19.0
    val_v2t_metrics_MeanR: 113.51517857142858
    val_v2t_metrics_geometric_mean_R1-R5-R10: 26.216075786204097
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch6.pth ...
Train Epoch: 7 [0/24098 (0%)] Loss: 0.000134
Train Epoch: 7 [512/24098 (2%)] Loss: 0.000138
Train Epoch: 7 [1024/24098 (4%)] Loss: 0.000212
Train Epoch: 7 [1536/24098 (6%)] Loss: 0.000313
Train Epoch: 7 [2048/24098 (8%)] Loss: 0.000098
Train Epoch: 7 [2560/24098 (11%)] Loss: 0.000221
Train Epoch: 7 [3072/24098 (13%)] Loss: 0.000142
Train Epoch: 7 [3584/24098 (15%)] Loss: 0.000050
Train Epoch: 7 [4096/24098 (17%)] Loss: 0.000138
Train Epoch: 7 [4608/24098 (19%)] Loss: 0.000114
Train Epoch: 7 [5120/24098 (21%)] Loss: 0.000283
Train Epoch: 7 [5632/24098 (23%)] Loss: 0.000188
Train Epoch: 7 [6144/24098 (25%)] Loss: 0.000167
Train Epoch: 7 [6656/24098 (28%)] Loss: 0.000172
Train Epoch: 7 [7168/24098 (30%)] Loss: 0.000177
Train Epoch: 7 [7680/24098 (32%)] Loss: 0.000281
Train Epoch: 7 [8192/24098 (34%)] Loss: 0.000113
Train Epoch: 7 [8704/24098 (36%)] Loss: 0.000091
Train Epoch: 7 [9216/24098 (38%)] Loss: 0.000059
Train Epoch: 7 [9728/24098 (40%)] Loss: 0.000081
Train Epoch: 7 [10240/24098 (42%)] Loss: 0.000248
Train Epoch: 7 [10752/24098 (45%)] Loss: 0.000219
Train Epoch: 7 [11264/24098 (47%)] Loss: 0.000069
Train Epoch: 7 [11776/24098 (49%)] Loss: 0.000126
Train Epoch: 7 [12288/24098 (51%)] Loss: 0.000191
Train Epoch: 7 [12800/24098 (53%)] Loss: 0.000310
Train Epoch: 7 [13312/24098 (55%)] Loss: 0.000205
Train Epoch: 7 [13824/24098 (57%)] Loss: 0.000216
Train Epoch: 7 [14336/24098 (59%)] Loss: 0.000155
Train Epoch: 7 [14848/24098 (62%)] Loss: 0.000153
Train Epoch: 7 [15360/24098 (64%)] Loss: 0.000622
Train Epoch: 7 [15872/24098 (66%)] Loss: 0.000073
Train Epoch: 7 [16384/24098 (68%)] Loss: 0.000043
Train Epoch: 7 [16896/24098 (70%)] Loss: 0.000118
Train Epoch: 7 [17408/24098 (72%)] Loss: 0.000135
Train Epoch: 7 [17920/24098 (74%)] Loss: 0.000079
Train Epoch: 7 [18432/24098 (76%)] Loss: 0.000091
Train Epoch: 7 [18944/24098 (79%)] Loss: 0.000201
Train Epoch: 7 [19456/24098 (81%)] Loss: 0.000128
Train Epoch: 7 [19968/24098 (83%)] Loss: 0.000097
Train Epoch: 7 [20480/24098 (85%)] Loss: 0.000103
Train Epoch: 7 [20992/24098 (87%)] Loss: 0.000184
Train Epoch: 7 [21504/24098 (89%)] Loss: 0.000132
Train Epoch: 7 [22016/24098 (91%)] Loss: 0.000142
Train Epoch: 7 [22528/24098 (93%)] Loss: 0.000215
Train Epoch: 7 [23040/24098 (96%)] Loss: 0.000119
Train Epoch: 7 [23552/24098 (98%)] Loss: 0.000106
Train Epoch: 7 [24064/24098 (100%)] Loss: 0.000844
[t2v_metrics]MovieClips epoch 7, R@1: 10.8, R@5: 29.1, R@10 40.2, R@50 65.2MedR: 19, MeanR: 121.0
[v2t_metrics]MovieClips epoch 7, R@1: 14.3, R@5: 32.3, R@10 41.2, R@50 67.0MedR: 18, MeanR: 112.0
    epoch          : 7
    loss           : 0.00015943627497846748
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.0134419621899724
    val_t2v_metrics_R1: 10.773809523809524
    val_t2v_metrics_R5: 29.107142857142858
    val_t2v_metrics_R10: 40.23809523809524
    val_t2v_metrics_R50: 65.20833333333333
    val_t2v_metrics_MedR: 19.0
    val_t2v_metrics_MeanR: 121.05
    val_t2v_metrics_geometric_mean_R1-R5-R10: 23.281024877737494
    val_v2t_metrics_R1: 14.255952380952381
    val_v2t_metrics_R5: 32.32142857142857
    val_v2t_metrics_R10: 41.19047619047619
    val_v2t_metrics_R50: 66.96428571428571
    val_v2t_metrics_MedR: 18.0
    val_v2t_metrics_MeanR: 111.97083333333333
    val_v2t_metrics_geometric_mean_R1-R5-R10: 26.674392186920326
Saving checkpoint: saved/models/MoEE/0318_060745/checkpoint-epoch7.pth ...
Train Epoch: 8 [0/24098 (0%)] Loss: 0.000154
Train Epoch: 8 [512/24098 (2%)] Loss: 0.000127
Train Epoch: 8 [1024/24098 (4%)] Loss: 0.000082
Train Epoch: 8 [1536/24098 (6%)] Loss: 0.000070
Train Epoch: 8 [2048/24098 (8%)] Loss: 0.000119
Train Epoch: 8 [2560/24098 (11%)] Loss: 0.000156
Train Epoch: 8 [3072/24098 (13%)] Loss: 0.000089
Train Epoch: 8 [3584/24098 (15%)] Loss: 0.000049
Train Epoch: 8 [4096/24098 (17%)] Loss: 0.000064
Train Epoch: 8 [4608/24098 (19%)] Loss: 0.000063
Train Epoch: 8 [5120/24098 (21%)] Loss: 0.000116
Train Epoch: 8 [5632/24098 (23%)] Loss: 0.000114
Train Epoch: 8 [6144/24098 (25%)] Loss: 0.000142
Train Epoch: 8 [6656/24098 (28%)] Loss: 0.000264
Train Epoch: 8 [7168/24098 (30%)] Loss: 0.000097
Train Epoch: 8 [7680/24098 (32%)] Loss: 0.000056
Train Epoch: 8 [8192/24098 (34%)] Loss: 0.000071
Train Epoch: 8 [8704/24098 (36%)] Loss: 0.000072
Train Epoch: 8 [9216/24098 (38%)] Loss: 0.000103
Train Epoch: 8 [9728/24098 (40%)] Loss: 0.000149
Train Epoch: 8 [10240/24098 (42%)] Loss: 0.000072
Train Epoch: 8 [10752/24098 (45%)] Loss: 0.000160
Train Epoch: 8 [11264/24098 (47%)] Loss: 0.000106
Train Epoch: 8 [11776/24098 (49%)] Loss: 0.000082
Train Epoch: 8 [12288/24098 (51%)] Loss: 0.000088
Train Epoch: 8 [12800/24098 (53%)] Loss: 0.000066
Train Epoch: 8 [13312/24098 (55%)] Loss: 0.000075
Train Epoch: 8 [13824/24098 (57%)] Loss: 0.000146
Train Epoch: 8 [14336/24098 (59%)] Loss: 0.000165
Train Epoch: 8 [14848/24098 (62%)] Loss: 0.000090
Train Epoch: 8 [15360/24098 (64%)] Loss: 0.000301
Train Epoch: 8 [15872/24098 (66%)] Loss: 0.000110
Train Epoch: 8 [16384/24098 (68%)] Loss: 0.000122
Train Epoch: 8 [16896/24098 (70%)] Loss: 0.000085
Train Epoch: 8 [17408/24098 (72%)] Loss: 0.000085
Train Epoch: 8 [17920/24098 (74%)] Loss: 0.000149
Train Epoch: 8 [18432/24098 (76%)] Loss: 0.000145
Train Epoch: 8 [18944/24098 (79%)] Loss: 0.000162
Train Epoch: 8 [19456/24098 (81%)] Loss: 0.000104
Train Epoch: 8 [19968/24098 (83%)] Loss: 0.000188
Train Epoch: 8 [20480/24098 (85%)] Loss: 0.000129
Train Epoch: 8 [20992/24098 (87%)] Loss: 0.000070
Train Epoch: 8 [21504/24098 (89%)] Loss: 0.000212
Train Epoch: 8 [22016/24098 (91%)] Loss: 0.000191
Train Epoch: 8 [22528/24098 (93%)] Loss: 0.000161
Train Epoch: 8 [23040/24098 (96%)] Loss: 0.000185
Train Epoch: 8 [23552/24098 (98%)] Loss: 0.000073
Train Epoch: 8 [24064/24098 (100%)] Loss: 0.000076
[t2v_metrics]MovieClips epoch 8, R@1: 12.0, R@5: 29.5, R@10 39.5, R@50 64.3MedR: 20, MeanR: 126.3
[v2t_metrics]MovieClips epoch 8, R@1: 14.6, R@5: 32.6, R@10 42.0, R@50 65.7MedR: 18, MeanR: 118.7
    epoch          : 8
    loss           : 0.00013032465163821048
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.01424600649625063
    val_t2v_metrics_R1: 11.964285714285714
    val_t2v_metrics_R5: 29.523809523809526
    val_t2v_metrics_R10: 39.49404761904762
    val_t2v_metrics_R50: 64.28571428571429
    val_t2v_metrics_MedR: 20.0
    val_t2v_metrics_MeanR: 126.31964285714285
    val_t2v_metrics_geometric_mean_R1-R5-R10: 24.073003111935353
    val_v2t_metrics_R1: 14.613095238095237
    val_v2t_metrics_R5: 32.589285714285715
    val_v2t_metrics_R10: 42.023809523809526
    val_v2t_metrics_R50: 65.68452380952381
    val_v2t_metrics_MedR: 18.0
    val_v2t_metrics_MeanR: 118.70386904761905
    val_v2t_metrics_geometric_mean_R1-R5-R10: 27.150061974932278
Validation performance didn't improve for 4 epochs. Training stops.