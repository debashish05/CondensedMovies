loading features >>> [Total: 0.3s] (gnode012:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 2.7% of system memory 2.5 GB/131.4 GB
loading features >>> [Total: 3.5s] (gnode012:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.8% of system memory 6.8 GB/127.2 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/SE-ResNet-50/256D_vgg_face2/agg/agg_feats_mean.npy)
>>> Currently using 5.9% of system memory 6.8 GB/127.1 GB
loading features >>> [Total: 0.2s] (gnode012:data/features/SE-ResNet-154/pred_imagenet_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.0% of system memory 6.9 GB/127.0 GB
loading features >>> [Total: 0.2s] (gnode012:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 6.1% of system memory 7.1 GB/126.9 GB
loading features >>> [Total: 1.6s] (gnode012:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 7.5% of system memory 9.0 GB/125.0 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.5% of system memory 9.1 GB/124.9 GB
loading features >>> [Total: 0.1s] (gnode012:data/features/S3DG/pred_s3dg_10fps_256px_stride16_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 7.6% of system memory 9.1 GB/124.8 GB
train size: 24098 clips
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
>>> Currently using 7.6% of system memory 9.2 GB/124.8 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (face): MeanToken()
    (scene): MeanToken()
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=256, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=2048, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (face): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (rgb): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (s3d): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
    (1): Identity()
    (2): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=21, bias=True)
)
Trainable parameters: 50541651
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121401
Train Epoch: 1 [1408/24098 (6%)] Loss: 0.121345
Train Epoch: 1 [2816/24098 (12%)] Loss: 0.121365
Train Epoch: 1 [4224/24098 (18%)] Loss: 0.121206
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.121328
Train Epoch: 1 [7040/24098 (29%)] Loss: 0.121282
Train Epoch: 1 [8448/24098 (35%)] Loss: 0.121338
Train Epoch: 1 [9856/24098 (41%)] Loss: 0.121347
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.121266
Train Epoch: 1 [12672/24098 (53%)] Loss: 0.121365
Train Epoch: 1 [14080/24098 (58%)] Loss: 0.121242
Train Epoch: 1 [15488/24098 (64%)] Loss: 0.121254
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.121272
Train Epoch: 1 [18304/24098 (76%)] Loss: 0.121215
Train Epoch: 1 [19712/24098 (82%)] Loss: 0.121109
Train Epoch: 1 [21120/24098 (88%)] Loss: 0.121574
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.121333
Train Epoch: 1 [23936/24098 (99%)] Loss: 0.121261
[t2v_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.1, R@10 0.2, R@50 1.5MedR: 1662.5, MeanR: 1663.1
[v2t_metrics]MovieClips epoch 1, R@1: 0.1, R@5: 0.1, R@10 0.3, R@50 1.7MedR: 1651.5, MeanR: 1649.5
    epoch          : 1
    loss           : 0.12128657997442932
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.12116561084985733
    val_t2v_metrics_R1: 0.02976190476190476
    val_t2v_metrics_R5: 0.1488095238095238
    val_t2v_metrics_R10: 0.23809523809523808
    val_t2v_metrics_R50: 1.5476190476190477
    val_t2v_metrics_MedR: 1662.5
    val_t2v_metrics_MeanR: 1663.0565476190477
    val_t2v_metrics_geometric_mean_R1-R5-R10: 0.10178428254027956
    val_v2t_metrics_R1: 0.08928571428571429
    val_v2t_metrics_R5: 0.1488095238095238
    val_v2t_metrics_R10: 0.26785714285714285
    val_v2t_metrics_R50: 1.6666666666666667
    val_v2t_metrics_MedR: 1651.5
    val_v2t_metrics_MeanR: 1649.523511904762
    val_v2t_metrics_geometric_mean_R1-R5-R10: 0.15267642381041938
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_162853/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.121357
Train Epoch: 2 [1408/24098 (6%)] Loss: 0.107104
Train Epoch: 2 [2816/24098 (12%)] Loss: 0.089741
Train Epoch: 2 [4224/24098 (18%)] Loss: 0.068483
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.054168
Train Epoch: 2 [7040/24098 (29%)] Loss: 0.047195
Train Epoch: 2 [8448/24098 (35%)] Loss: 0.050812
Train Epoch: 2 [9856/24098 (41%)] Loss: 0.048349
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.036718
Train Epoch: 2 [12672/24098 (53%)] Loss: 0.034702
Train Epoch: 2 [14080/24098 (58%)] Loss: 0.034231
Train Epoch: 2 [15488/24098 (64%)] Loss: 0.037908
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.032929
Train Epoch: 2 [18304/24098 (76%)] Loss: 0.032563
Train Epoch: 2 [19712/24098 (82%)] Loss: 0.032322
Train Epoch: 2 [21120/24098 (88%)] Loss: 0.032541
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.031116
Train Epoch: 2 [23936/24098 (99%)] Loss: 0.025266
[t2v_metrics]MovieClips epoch 2, R@1: 1.8, R@5: 6.9, R@10 11.3, R@50 29.5MedR: 143, MeanR: 314.6
[v2t_metrics]MovieClips epoch 2, R@1: 2.2, R@5: 7.8, R@10 13.7, R@50 33.4MedR: 110, MeanR: 272.0
    epoch          : 2
    loss           : 0.04976986986264665
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.031867776066064835
    val_t2v_metrics_R1: 1.8452380952380953
    val_t2v_metrics_R5: 6.904761904761905
    val_t2v_metrics_R10: 11.279761904761905
    val_t2v_metrics_R50: 29.464285714285715
    val_t2v_metrics_MedR: 143.0
    val_t2v_metrics_MeanR: 314.57157738095236
    val_t2v_metrics_geometric_mean_R1-R5-R10: 5.238018372543839
    val_v2t_metrics_R1: 2.1726190476190474
    val_v2t_metrics_R5: 7.8273809523809526
    val_v2t_metrics_R10: 13.660714285714286
    val_v2t_metrics_R50: 33.36309523809524
    val_v2t_metrics_MedR: 110.0
    val_v2t_metrics_MeanR: 271.99613095238095
    val_v2t_metrics_geometric_mean_R1-R5-R10: 6.147395487557696
Saving checkpoint: FRSSVS_lr=3e-5_valLoss/models/MoEE/0513_162853/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.023583
Train Epoch: 3 [1408/24098 (6%)] Loss: 0.022512
Train Epoch: 3 [2816/24098 (12%)] Loss: 0.020763
Train Epoch: 3 [4224/24098 (18%)] Loss: 0.022758
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.019123
Train Epoch: 3 [7040/24098 (29%)] Loss: 0.022035
Train Epoch: 3 [8448/24098 (35%)] Loss: 0.017870
Train Epoch: 3 [9856/24098 (41%)] Loss: 0.019421
Traceback (most recent call last):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py", line 39, in <module>
    cli.main()
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 430, in main
    run()
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 284, in run_file
    runpy.run_path(target, run_name="__main__")
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 322, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 136, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "/home2/debashish.roy/.vscode-server/extensions/ms-python.python-2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
    exec(code, run_globals)
  File "/home2/debashish.roy/CondensedMovies/train.py", line 77, in <module>
    main(config)
  File "/home2/debashish.roy/CondensedMovies/train.py", line 48, in main
    trainer.train()
  File "/home2/debashish.roy/CondensedMovies/base/base_trainer.py", line 68, in train
    result = self._train_epoch(epoch)
  File "/home2/debashish.roy/CondensedMovies/trainer/trainer.py", line 66, in _train_epoch
    for batch_idx, (minibatch, id) in enumerate(self.data_loader):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1316, in _next_data
    idx, data = self._get_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1282, in _get_data
    success, data = self._try_get_data()
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 1120, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/multiprocessing/connection.py", line 921, in wait
    ready = selector.select(timeout)
  File "/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt