<parse_config.ConfigParser object at 0x14548f7a7c10>
loading features >>> [Total: 0.3s] (gnode030:data/features/BERT/bert-large-cased/clip_name/agg/agg.npy)
>>> Currently using 1.9% of system memory 1.5 GB/132.5 GB
loading features >>> [Total: 8.8s] (gnode030:data/features/BERT/bert-large-cased/description/agg/agg_word.npy)
>>> Currently using 5.2% of system memory 5.9 GB/128.1 GB
loading features >>> [Total: 0.4s] (gnode030:data/features/DenseNet-161/pred_scene_25fps_256px_stride1_offset0/agg/agg_feats_mean.npy)
>>> Currently using 5.2% of system memory 5.9 GB/128.1 GB
loading features >>> [Total: 5.0s] (gnode030:data/features/BERT/bert-large-cased/speech/agg/agg.npy)
>>> Currently using 6.5% of system memory 7.7 GB/126.2 GB
loading features >>> [Total: 0.3s] (gnode030:data/features/I3D/pred_i3d_25fps_256px_stride25_offset0_inner_stride1/agg/agg_feats_mean.npy)
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
train size: 24098 clips
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
>>> Currently using 6.6% of system memory 7.8 GB/126.2 GB
val size: 3360 clips
MoEE(
  (aggregation): ModuleDict(
    (label): NetVLAD(
      (batch_norm): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (speech): MeanToken()
  )
  (video_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=2208, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=1024, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (clip_GU): ModuleList(
    (0): Identity()
  )
  (text_GU): ModuleDict(
    (clip_name): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (description): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (scene): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (speech): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (video): Gated_Embedding_Unit(
      (fc): Linear(in_features=10240, out_features=512, bias=True)
      (cg): Context_Gating(
        (fc): Linear(in_features=512, out_features=512, bias=True)
        (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (text_clip): ModuleList(
    (0): Identity()
  )
  (moe_fc): Linear(in_features=10240, out_features=4, bias=True)
)
Trainable parameters: 31352864
Train Epoch: 1 [0/24098 (0%)] Loss: 0.121192
Train Epoch: 1 [512/24098 (2%)] Loss: 0.120843
Train Epoch: 1 [1024/24098 (4%)] Loss: 0.121184
Train Epoch: 1 [1536/24098 (6%)] Loss: 0.120937
Train Epoch: 1 [2048/24098 (8%)] Loss: 0.121322
Train Epoch: 1 [2560/24098 (11%)] Loss: 0.120778
Train Epoch: 1 [3072/24098 (13%)] Loss: 0.121330
Train Epoch: 1 [3584/24098 (15%)] Loss: 0.121019
Train Epoch: 1 [4096/24098 (17%)] Loss: 0.121313
Train Epoch: 1 [4608/24098 (19%)] Loss: 0.121297
Train Epoch: 1 [5120/24098 (21%)] Loss: 0.120906
Train Epoch: 1 [5632/24098 (23%)] Loss: 0.120809
Train Epoch: 1 [6144/24098 (25%)] Loss: 0.120836
Train Epoch: 1 [6656/24098 (28%)] Loss: 0.121527
Train Epoch: 1 [7168/24098 (30%)] Loss: 0.121790
Train Epoch: 1 [7680/24098 (32%)] Loss: 0.121216
Train Epoch: 1 [8192/24098 (34%)] Loss: 0.121178
Train Epoch: 1 [8704/24098 (36%)] Loss: 0.121941
Train Epoch: 1 [9216/24098 (38%)] Loss: 0.120755
Train Epoch: 1 [9728/24098 (40%)] Loss: 0.121212
Train Epoch: 1 [10240/24098 (42%)] Loss: 0.121343
Train Epoch: 1 [10752/24098 (45%)] Loss: 0.121135
Train Epoch: 1 [11264/24098 (47%)] Loss: 0.121812
Train Epoch: 1 [11776/24098 (49%)] Loss: 0.121019
Train Epoch: 1 [12288/24098 (51%)] Loss: 0.121374
Train Epoch: 1 [12800/24098 (53%)] Loss: 0.121049
Train Epoch: 1 [13312/24098 (55%)] Loss: 0.120994
Train Epoch: 1 [13824/24098 (57%)] Loss: 0.121649
Train Epoch: 1 [14336/24098 (59%)] Loss: 0.121405
Train Epoch: 1 [14848/24098 (62%)] Loss: 0.121335
Train Epoch: 1 [15360/24098 (64%)] Loss: 0.121044
Train Epoch: 1 [15872/24098 (66%)] Loss: 0.121843
Train Epoch: 1 [16384/24098 (68%)] Loss: 0.121207
Train Epoch: 1 [16896/24098 (70%)] Loss: 0.121349
Train Epoch: 1 [17408/24098 (72%)] Loss: 0.120745
Train Epoch: 1 [17920/24098 (74%)] Loss: 0.121230
Train Epoch: 1 [18432/24098 (76%)] Loss: 0.120832
Train Epoch: 1 [18944/24098 (79%)] Loss: 0.121459
Train Epoch: 1 [19456/24098 (81%)] Loss: 0.121149
Train Epoch: 1 [19968/24098 (83%)] Loss: 0.121235
Train Epoch: 1 [20480/24098 (85%)] Loss: 0.121606
Train Epoch: 1 [20992/24098 (87%)] Loss: 0.121036
Train Epoch: 1 [21504/24098 (89%)] Loss: 0.121196
Train Epoch: 1 [22016/24098 (91%)] Loss: 0.121342
Train Epoch: 1 [22528/24098 (93%)] Loss: 0.120961
Train Epoch: 1 [23040/24098 (96%)] Loss: 0.121210
Train Epoch: 1 [23552/24098 (98%)] Loss: 0.120859
Train Epoch: 1 [24064/24098 (100%)] Loss: 0.121408
[t2v_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.2, R@10 0.4, R@50 1.4MedR: 1652, MeanR: 1663.8
/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/scipy/stats/stats.py:275: RuntimeWarning: divide by zero encountered in log
  log_a = np.log(np.array(a, dtype=dtype))
/home2/debashish.roy/miniconda3/envs/IS/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
[v2t_metrics]MovieClips epoch 1, R@1: 0.0, R@5: 0.1, R@10 0.3, R@50 1.7MedR: 1630, MeanR: 1651.9
    epoch          : 1
    loss           : 0.12119986626766721
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.12110908329486847
    val_t2v_metrics_R1: 0.0
    val_t2v_metrics_R5: 0.23809523809523808
    val_t2v_metrics_R10: 0.3869047619047619
    val_t2v_metrics_R50: 1.4285714285714286
    val_t2v_metrics_MedR: 1652.0
    val_t2v_metrics_MeanR: 1663.842261904762
    val_t2v_metrics_geometric_mean_R1-R5-R10: 0.0
    val_v2t_metrics_R1: 0.0
    val_v2t_metrics_R5: 0.11904761904761904
    val_v2t_metrics_R10: 0.26785714285714285
    val_v2t_metrics_R50: 1.6964285714285714
    val_v2t_metrics_MedR: 1630.0
    val_v2t_metrics_MeanR: 1651.9235119047619
    val_v2t_metrics_geometric_mean_R1-R5-R10: 0.0
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch1.pth ...
Saving current best: model_best.pth ...
Train Epoch: 2 [0/24098 (0%)] Loss: 0.120779
Train Epoch: 2 [512/24098 (2%)] Loss: 0.067697
/ssd_scratch/cvit/debashish/CondensedMovies/trainer/trainer.py:136: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.
  with autograd.detect_anomaly():
Train Epoch: 2 [1024/24098 (4%)] Loss: 0.058441
Train Epoch: 2 [1536/24098 (6%)] Loss: 0.053026
Train Epoch: 2 [2048/24098 (8%)] Loss: 0.039690
Train Epoch: 2 [2560/24098 (11%)] Loss: 0.038633
Train Epoch: 2 [3072/24098 (13%)] Loss: 0.043718
Train Epoch: 2 [3584/24098 (15%)] Loss: 0.029384
Train Epoch: 2 [4096/24098 (17%)] Loss: 0.035173
Train Epoch: 2 [4608/24098 (19%)] Loss: 0.032652
Train Epoch: 2 [5120/24098 (21%)] Loss: 0.032201
Train Epoch: 2 [5632/24098 (23%)] Loss: 0.025770
Train Epoch: 2 [6144/24098 (25%)] Loss: 0.024575
Train Epoch: 2 [6656/24098 (28%)] Loss: 0.025780
Train Epoch: 2 [7168/24098 (30%)] Loss: 0.028346
Train Epoch: 2 [7680/24098 (32%)] Loss: 0.025382
Train Epoch: 2 [8192/24098 (34%)] Loss: 0.032446
Train Epoch: 2 [8704/24098 (36%)] Loss: 0.019281
Train Epoch: 2 [9216/24098 (38%)] Loss: 0.025910
Train Epoch: 2 [9728/24098 (40%)] Loss: 0.026978
Train Epoch: 2 [10240/24098 (42%)] Loss: 0.036637
Train Epoch: 2 [10752/24098 (45%)] Loss: 0.021724
Train Epoch: 2 [11264/24098 (47%)] Loss: 0.025038
Train Epoch: 2 [11776/24098 (49%)] Loss: 0.021334
Train Epoch: 2 [12288/24098 (51%)] Loss: 0.025492
Train Epoch: 2 [12800/24098 (53%)] Loss: 0.015494
Train Epoch: 2 [13312/24098 (55%)] Loss: 0.019774
Train Epoch: 2 [13824/24098 (57%)] Loss: 0.022390
Train Epoch: 2 [14336/24098 (59%)] Loss: 0.022714
Train Epoch: 2 [14848/24098 (62%)] Loss: 0.024965
Train Epoch: 2 [15360/24098 (64%)] Loss: 0.019142
Train Epoch: 2 [15872/24098 (66%)] Loss: 0.022058
Train Epoch: 2 [16384/24098 (68%)] Loss: 0.021658
Train Epoch: 2 [16896/24098 (70%)] Loss: 0.020683
Train Epoch: 2 [17408/24098 (72%)] Loss: 0.025755
Train Epoch: 2 [17920/24098 (74%)] Loss: 0.016156
Train Epoch: 2 [18432/24098 (76%)] Loss: 0.014402
Train Epoch: 2 [18944/24098 (79%)] Loss: 0.022009
Train Epoch: 2 [19456/24098 (81%)] Loss: 0.016524
Train Epoch: 2 [19968/24098 (83%)] Loss: 0.021192
Train Epoch: 2 [20480/24098 (85%)] Loss: 0.015417
Train Epoch: 2 [20992/24098 (87%)] Loss: 0.012237
Train Epoch: 2 [21504/24098 (89%)] Loss: 0.018269
Train Epoch: 2 [22016/24098 (91%)] Loss: 0.018370
Train Epoch: 2 [22528/24098 (93%)] Loss: 0.011136
Train Epoch: 2 [23040/24098 (96%)] Loss: 0.025867
Train Epoch: 2 [23552/24098 (98%)] Loss: 0.020454
Train Epoch: 2 [24064/24098 (100%)] Loss: 0.038883
[t2v_metrics]MovieClips epoch 2, R@1: 3.8, R@5: 12.2, R@10 19.5, R@50 41.9MedR: 77, MeanR: 216.6
[v2t_metrics]MovieClips epoch 2, R@1: 5.0, R@5: 14.6, R@10 21.6, R@50 44.3MedR: 65, MeanR: 204.1
    epoch          : 2
    loss           : 0.027483646372525858
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.020318057388067245
    val_t2v_metrics_R1: 3.8095238095238093
    val_t2v_metrics_R5: 12.202380952380953
    val_t2v_metrics_R10: 19.464285714285715
    val_t2v_metrics_R50: 41.904761904761905
    val_t2v_metrics_MedR: 77.0
    val_t2v_metrics_MeanR: 216.57619047619048
    val_t2v_metrics_geometric_mean_R1-R5-R10: 9.672036219226042
    val_v2t_metrics_R1: 5.0
    val_v2t_metrics_R5: 14.613095238095237
    val_v2t_metrics_R10: 21.636904761904763
    val_v2t_metrics_R50: 44.31547619047619
    val_v2t_metrics_MedR: 65.0
    val_v2t_metrics_MeanR: 204.06205357142858
    val_v2t_metrics_geometric_mean_R1-R5-R10: 11.6493703103976
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch2.pth ...
Saving current best: model_best.pth ...
Train Epoch: 3 [0/24098 (0%)] Loss: 0.007964
Train Epoch: 3 [512/24098 (2%)] Loss: 0.010953
Train Epoch: 3 [1024/24098 (4%)] Loss: 0.007473
Train Epoch: 3 [1536/24098 (6%)] Loss: 0.007352
Train Epoch: 3 [2048/24098 (8%)] Loss: 0.009251
Train Epoch: 3 [2560/24098 (11%)] Loss: 0.008261
Train Epoch: 3 [3072/24098 (13%)] Loss: 0.008807
Train Epoch: 3 [3584/24098 (15%)] Loss: 0.007609
Train Epoch: 3 [4096/24098 (17%)] Loss: 0.009902
Train Epoch: 3 [4608/24098 (19%)] Loss: 0.007032
Train Epoch: 3 [5120/24098 (21%)] Loss: 0.007698
Train Epoch: 3 [5632/24098 (23%)] Loss: 0.010645
Train Epoch: 3 [6144/24098 (25%)] Loss: 0.008961
Train Epoch: 3 [6656/24098 (28%)] Loss: 0.006026
Train Epoch: 3 [7168/24098 (30%)] Loss: 0.005654
Train Epoch: 3 [7680/24098 (32%)] Loss: 0.007790
Train Epoch: 3 [8192/24098 (34%)] Loss: 0.011142
Train Epoch: 3 [8704/24098 (36%)] Loss: 0.005793
Train Epoch: 3 [9216/24098 (38%)] Loss: 0.008021
Train Epoch: 3 [9728/24098 (40%)] Loss: 0.009146
Train Epoch: 3 [10240/24098 (42%)] Loss: 0.007739
Train Epoch: 3 [10752/24098 (45%)] Loss: 0.007568
Train Epoch: 3 [11264/24098 (47%)] Loss: 0.008750
Train Epoch: 3 [11776/24098 (49%)] Loss: 0.006010
Train Epoch: 3 [12288/24098 (51%)] Loss: 0.005227
Train Epoch: 3 [12800/24098 (53%)] Loss: 0.006452
Train Epoch: 3 [13312/24098 (55%)] Loss: 0.006812
Train Epoch: 3 [13824/24098 (57%)] Loss: 0.008837
Train Epoch: 3 [14336/24098 (59%)] Loss: 0.007837
Train Epoch: 3 [14848/24098 (62%)] Loss: 0.007125
Train Epoch: 3 [15360/24098 (64%)] Loss: 0.006385
Train Epoch: 3 [15872/24098 (66%)] Loss: 0.006731
Train Epoch: 3 [16384/24098 (68%)] Loss: 0.006984
Train Epoch: 3 [16896/24098 (70%)] Loss: 0.006440
Train Epoch: 3 [17408/24098 (72%)] Loss: 0.009555
Train Epoch: 3 [17920/24098 (74%)] Loss: 0.005060
Train Epoch: 3 [18432/24098 (76%)] Loss: 0.007487
Train Epoch: 3 [18944/24098 (79%)] Loss: 0.008871
Train Epoch: 3 [19456/24098 (81%)] Loss: 0.009628
Train Epoch: 3 [19968/24098 (83%)] Loss: 0.008919
Train Epoch: 3 [20480/24098 (85%)] Loss: 0.007715
Train Epoch: 3 [20992/24098 (87%)] Loss: 0.008395
Train Epoch: 3 [21504/24098 (89%)] Loss: 0.006495
Train Epoch: 3 [22016/24098 (91%)] Loss: 0.009019
Train Epoch: 3 [22528/24098 (93%)] Loss: 0.006886
Train Epoch: 3 [23040/24098 (96%)] Loss: 0.006836
Train Epoch: 3 [23552/24098 (98%)] Loss: 0.007203
Train Epoch: 3 [24064/24098 (100%)] Loss: 0.014188
[t2v_metrics]MovieClips epoch 3, R@1: 5.8, R@5: 16.6, R@10 23.8, R@50 46.0MedR: 62, MeanR: 206.0
[v2t_metrics]MovieClips epoch 3, R@1: 6.1, R@5: 18.4, R@10 25.5, R@50 49.6MedR: 51, MeanR: 186.9
    epoch          : 3
    loss           : 0.00790456614879501
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.01955283433198929
    val_t2v_metrics_R1: 5.833333333333333
    val_t2v_metrics_R5: 16.607142857142858
    val_t2v_metrics_R10: 23.839285714285715
    val_t2v_metrics_R50: 45.982142857142854
    val_t2v_metrics_MedR: 62.0
    val_t2v_metrics_MeanR: 206.02083333333334
    val_t2v_metrics_geometric_mean_R1-R5-R10: 13.218078235934184
    val_v2t_metrics_R1: 6.101190476190476
    val_v2t_metrics_R5: 18.422619047619047
    val_v2t_metrics_R10: 25.476190476190474
    val_v2t_metrics_R50: 49.642857142857146
    val_v2t_metrics_MedR: 51.0
    val_v2t_metrics_MeanR: 186.88511904761904
    val_v2t_metrics_geometric_mean_R1-R5-R10: 14.200385929226279
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch3.pth ...
Saving current best: model_best.pth ...
Train Epoch: 4 [0/24098 (0%)] Loss: 0.003379
Train Epoch: 4 [512/24098 (2%)] Loss: 0.004183
Train Epoch: 4 [1024/24098 (4%)] Loss: 0.003014
Train Epoch: 4 [1536/24098 (6%)] Loss: 0.005167
Train Epoch: 4 [2048/24098 (8%)] Loss: 0.003809
Train Epoch: 4 [2560/24098 (11%)] Loss: 0.002547
Train Epoch: 4 [3072/24098 (13%)] Loss: 0.002873
Train Epoch: 4 [3584/24098 (15%)] Loss: 0.004020
Train Epoch: 4 [4096/24098 (17%)] Loss: 0.003637
Train Epoch: 4 [4608/24098 (19%)] Loss: 0.003359
Train Epoch: 4 [5120/24098 (21%)] Loss: 0.002767
Train Epoch: 4 [5632/24098 (23%)] Loss: 0.002076
Train Epoch: 4 [6144/24098 (25%)] Loss: 0.002330
Train Epoch: 4 [6656/24098 (28%)] Loss: 0.002354
Train Epoch: 4 [7168/24098 (30%)] Loss: 0.002210
Train Epoch: 4 [7680/24098 (32%)] Loss: 0.003106
Train Epoch: 4 [8192/24098 (34%)] Loss: 0.002170
Train Epoch: 4 [8704/24098 (36%)] Loss: 0.002210
Train Epoch: 4 [9216/24098 (38%)] Loss: 0.002909
Train Epoch: 4 [9728/24098 (40%)] Loss: 0.002562
Train Epoch: 4 [10240/24098 (42%)] Loss: 0.002886
Train Epoch: 4 [10752/24098 (45%)] Loss: 0.002893
Train Epoch: 4 [11264/24098 (47%)] Loss: 0.003403
Train Epoch: 4 [11776/24098 (49%)] Loss: 0.001884
Train Epoch: 4 [12288/24098 (51%)] Loss: 0.002448
Train Epoch: 4 [12800/24098 (53%)] Loss: 0.002799
Train Epoch: 4 [13312/24098 (55%)] Loss: 0.002509
Train Epoch: 4 [13824/24098 (57%)] Loss: 0.002810
Train Epoch: 4 [14336/24098 (59%)] Loss: 0.002188
Train Epoch: 4 [14848/24098 (62%)] Loss: 0.002637
Train Epoch: 4 [15360/24098 (64%)] Loss: 0.003360
Train Epoch: 4 [15872/24098 (66%)] Loss: 0.002998
Train Epoch: 4 [16384/24098 (68%)] Loss: 0.002980
Train Epoch: 4 [16896/24098 (70%)] Loss: 0.002714
Train Epoch: 4 [17408/24098 (72%)] Loss: 0.003066
Train Epoch: 4 [17920/24098 (74%)] Loss: 0.003262
Train Epoch: 4 [18432/24098 (76%)] Loss: 0.002416
Train Epoch: 4 [18944/24098 (79%)] Loss: 0.002324
Train Epoch: 4 [19456/24098 (81%)] Loss: 0.002117
Train Epoch: 4 [19968/24098 (83%)] Loss: 0.002121
Train Epoch: 4 [20480/24098 (85%)] Loss: 0.001981
Train Epoch: 4 [20992/24098 (87%)] Loss: 0.002957
Train Epoch: 4 [21504/24098 (89%)] Loss: 0.002959
Train Epoch: 4 [22016/24098 (91%)] Loss: 0.001879
Train Epoch: 4 [22528/24098 (93%)] Loss: 0.002914
Train Epoch: 4 [23040/24098 (96%)] Loss: 0.003597
Train Epoch: 4 [23552/24098 (98%)] Loss: 0.003310
Train Epoch: 4 [24064/24098 (100%)] Loss: 0.002253
[t2v_metrics]MovieClips epoch 4, R@1: 6.6, R@5: 19.7, R@10 27.3, R@50 51.6MedR: 46, MeanR: 183.0
[v2t_metrics]MovieClips epoch 4, R@1: 7.7, R@5: 20.6, R@10 29.1, R@50 53.0MedR: 42, MeanR: 172.2
    epoch          : 4
    loss           : 0.0027764318943201546
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.018177008256316185
    val_t2v_metrics_R1: 6.636904761904762
    val_t2v_metrics_R5: 19.672619047619047
    val_t2v_metrics_R10: 27.291666666666668
    val_t2v_metrics_R50: 51.63690476190476
    val_t2v_metrics_MedR: 46.0
    val_t2v_metrics_MeanR: 183.04315476190476
    val_t2v_metrics_geometric_mean_R1-R5-R10: 15.273993754270313
    val_v2t_metrics_R1: 7.738095238095238
    val_v2t_metrics_R5: 20.595238095238095
    val_v2t_metrics_R10: 29.077380952380953
    val_v2t_metrics_R50: 53.00595238095238
    val_v2t_metrics_MedR: 42.0
    val_v2t_metrics_MeanR: 172.22291666666666
    val_v2t_metrics_geometric_mean_R1-R5-R10: 16.67191131106241
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch4.pth ...
Saving current best: model_best.pth ...
Train Epoch: 5 [0/24098 (0%)] Loss: 0.001268
Train Epoch: 5 [512/24098 (2%)] Loss: 0.001423
Train Epoch: 5 [1024/24098 (4%)] Loss: 0.001318
Train Epoch: 5 [1536/24098 (6%)] Loss: 0.001131
Train Epoch: 5 [2048/24098 (8%)] Loss: 0.001156
Train Epoch: 5 [2560/24098 (11%)] Loss: 0.001508
Train Epoch: 5 [3072/24098 (13%)] Loss: 0.001194
Train Epoch: 5 [3584/24098 (15%)] Loss: 0.002085
Train Epoch: 5 [4096/24098 (17%)] Loss: 0.000889
Train Epoch: 5 [4608/24098 (19%)] Loss: 0.001213
Train Epoch: 5 [5120/24098 (21%)] Loss: 0.001085
Train Epoch: 5 [5632/24098 (23%)] Loss: 0.000773
Train Epoch: 5 [6144/24098 (25%)] Loss: 0.001538
Train Epoch: 5 [6656/24098 (28%)] Loss: 0.000853
Train Epoch: 5 [7168/24098 (30%)] Loss: 0.001024
Train Epoch: 5 [7680/24098 (32%)] Loss: 0.001116
Train Epoch: 5 [8192/24098 (34%)] Loss: 0.001473
Train Epoch: 5 [8704/24098 (36%)] Loss: 0.000821
Train Epoch: 5 [9216/24098 (38%)] Loss: 0.001094
Train Epoch: 5 [9728/24098 (40%)] Loss: 0.001729
Train Epoch: 5 [10240/24098 (42%)] Loss: 0.000762
Train Epoch: 5 [10752/24098 (45%)] Loss: 0.001461
Train Epoch: 5 [11264/24098 (47%)] Loss: 0.000987
Train Epoch: 5 [11776/24098 (49%)] Loss: 0.001391
Train Epoch: 5 [12288/24098 (51%)] Loss: 0.000824
Train Epoch: 5 [12800/24098 (53%)] Loss: 0.001010
Train Epoch: 5 [13312/24098 (55%)] Loss: 0.000774
Train Epoch: 5 [13824/24098 (57%)] Loss: 0.001075
Train Epoch: 5 [14336/24098 (59%)] Loss: 0.000784
Train Epoch: 5 [14848/24098 (62%)] Loss: 0.001062
Train Epoch: 5 [15360/24098 (64%)] Loss: 0.000784
Train Epoch: 5 [15872/24098 (66%)] Loss: 0.000920
Train Epoch: 5 [16384/24098 (68%)] Loss: 0.001056
Train Epoch: 5 [16896/24098 (70%)] Loss: 0.001458
Train Epoch: 5 [17408/24098 (72%)] Loss: 0.000828
Train Epoch: 5 [17920/24098 (74%)] Loss: 0.001279
Train Epoch: 5 [18432/24098 (76%)] Loss: 0.000989
Train Epoch: 5 [18944/24098 (79%)] Loss: 0.000991
Train Epoch: 5 [19456/24098 (81%)] Loss: 0.001749
Train Epoch: 5 [19968/24098 (83%)] Loss: 0.001367
Train Epoch: 5 [20480/24098 (85%)] Loss: 0.000958
Train Epoch: 5 [20992/24098 (87%)] Loss: 0.000904
Train Epoch: 5 [21504/24098 (89%)] Loss: 0.001122
Train Epoch: 5 [22016/24098 (91%)] Loss: 0.000987
Train Epoch: 5 [22528/24098 (93%)] Loss: 0.001143
Train Epoch: 5 [23040/24098 (96%)] Loss: 0.000943
Train Epoch: 5 [23552/24098 (98%)] Loss: 0.001314
Train Epoch: 5 [24064/24098 (100%)] Loss: 0.001186
[t2v_metrics]MovieClips epoch 5, R@1: 7.8, R@5: 21.3, R@10 29.0, R@50 53.7MedR: 41, MeanR: 170.8
[v2t_metrics]MovieClips epoch 5, R@1: 8.5, R@5: 22.6, R@10 31.2, R@50 55.2MedR: 37, MeanR: 162.8
    epoch          : 5
    loss           : 0.001084540317833068
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.017750674858689308
    val_t2v_metrics_R1: 7.8273809523809526
    val_t2v_metrics_R5: 21.339285714285715
    val_t2v_metrics_R10: 29.017857142857142
    val_t2v_metrics_R50: 53.720238095238095
    val_t2v_metrics_MedR: 41.0
    val_t2v_metrics_MeanR: 170.80416666666667
    val_t2v_metrics_geometric_mean_R1-R5-R10: 16.92338479159427
    val_v2t_metrics_R1: 8.511904761904763
    val_v2t_metrics_R5: 22.648809523809526
    val_v2t_metrics_R10: 31.19047619047619
    val_v2t_metrics_R50: 55.208333333333336
    val_v2t_metrics_MedR: 37.0
    val_v2t_metrics_MeanR: 162.77931547619048
    val_v2t_metrics_geometric_mean_R1-R5-R10: 18.184361095422133
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch5.pth ...
Saving current best: model_best.pth ...
Train Epoch: 6 [0/24098 (0%)] Loss: 0.000577
Train Epoch: 6 [512/24098 (2%)] Loss: 0.000638
Train Epoch: 6 [1024/24098 (4%)] Loss: 0.000571
Train Epoch: 6 [1536/24098 (6%)] Loss: 0.000942
Train Epoch: 6 [2048/24098 (8%)] Loss: 0.000472
Train Epoch: 6 [2560/24098 (11%)] Loss: 0.000643
Train Epoch: 6 [3072/24098 (13%)] Loss: 0.000482
Train Epoch: 6 [3584/24098 (15%)] Loss: 0.000485
Train Epoch: 6 [4096/24098 (17%)] Loss: 0.000630
Train Epoch: 6 [4608/24098 (19%)] Loss: 0.000422
Train Epoch: 6 [5120/24098 (21%)] Loss: 0.000736
Train Epoch: 6 [5632/24098 (23%)] Loss: 0.000623
Train Epoch: 6 [6144/24098 (25%)] Loss: 0.000372
Train Epoch: 6 [6656/24098 (28%)] Loss: 0.000574
Train Epoch: 6 [7168/24098 (30%)] Loss: 0.000620
Train Epoch: 6 [7680/24098 (32%)] Loss: 0.000480
Train Epoch: 6 [8192/24098 (34%)] Loss: 0.000437
Train Epoch: 6 [8704/24098 (36%)] Loss: 0.000546
Train Epoch: 6 [9216/24098 (38%)] Loss: 0.000378
Train Epoch: 6 [9728/24098 (40%)] Loss: 0.000555
Train Epoch: 6 [10240/24098 (42%)] Loss: 0.000586
Train Epoch: 6 [10752/24098 (45%)] Loss: 0.000332
Train Epoch: 6 [11264/24098 (47%)] Loss: 0.000649
Train Epoch: 6 [11776/24098 (49%)] Loss: 0.000479
Train Epoch: 6 [12288/24098 (51%)] Loss: 0.000608
Train Epoch: 6 [12800/24098 (53%)] Loss: 0.000556
Train Epoch: 6 [13312/24098 (55%)] Loss: 0.000678
Train Epoch: 6 [13824/24098 (57%)] Loss: 0.000522
Train Epoch: 6 [14336/24098 (59%)] Loss: 0.000435
Train Epoch: 6 [14848/24098 (62%)] Loss: 0.000559
Train Epoch: 6 [15360/24098 (64%)] Loss: 0.000515
Train Epoch: 6 [15872/24098 (66%)] Loss: 0.000473
Train Epoch: 6 [16384/24098 (68%)] Loss: 0.001024
Train Epoch: 6 [16896/24098 (70%)] Loss: 0.000599
Train Epoch: 6 [17408/24098 (72%)] Loss: 0.000653
Train Epoch: 6 [17920/24098 (74%)] Loss: 0.000612
Train Epoch: 6 [18432/24098 (76%)] Loss: 0.000336
Train Epoch: 6 [18944/24098 (79%)] Loss: 0.000459
Train Epoch: 6 [19456/24098 (81%)] Loss: 0.000513
Train Epoch: 6 [19968/24098 (83%)] Loss: 0.000816
Train Epoch: 6 [20480/24098 (85%)] Loss: 0.000545
Train Epoch: 6 [20992/24098 (87%)] Loss: 0.000500
Train Epoch: 6 [21504/24098 (89%)] Loss: 0.000458
Train Epoch: 6 [22016/24098 (91%)] Loss: 0.000392
Train Epoch: 6 [22528/24098 (93%)] Loss: 0.000594
Train Epoch: 6 [23040/24098 (96%)] Loss: 0.000734
Train Epoch: 6 [23552/24098 (98%)] Loss: 0.000404
Train Epoch: 6 [24064/24098 (100%)] Loss: 0.000390
[t2v_metrics]MovieClips epoch 6, R@1: 8.0, R@5: 21.4, R@10 30.3, R@50 54.0MedR: 40, MeanR: 174.1
[v2t_metrics]MovieClips epoch 6, R@1: 9.4, R@5: 23.1, R@10 31.3, R@50 55.7MedR: 35, MeanR: 166.9
    epoch          : 6
    loss           : 0.0005496852416409284
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.018696678802371025
    val_t2v_metrics_R1: 8.005952380952381
    val_t2v_metrics_R5: 21.36904761904762
    val_t2v_metrics_R10: 30.297619047619047
    val_t2v_metrics_R50: 54.017857142857146
    val_t2v_metrics_MedR: 40.0
    val_t2v_metrics_MeanR: 174.125
    val_t2v_metrics_geometric_mean_R1-R5-R10: 17.306220123909817
    val_v2t_metrics_R1: 9.404761904761905
    val_v2t_metrics_R5: 23.125
    val_v2t_metrics_R10: 31.339285714285715
    val_v2t_metrics_R50: 55.74404761904762
    val_v2t_metrics_MedR: 35.0
    val_v2t_metrics_MeanR: 166.9360119047619
    val_v2t_metrics_geometric_mean_R1-R5-R10: 18.96005299138079
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch6.pth ...
Train Epoch: 7 [0/24098 (0%)] Loss: 0.000350
Train Epoch: 7 [512/24098 (2%)] Loss: 0.000339
Train Epoch: 7 [1024/24098 (4%)] Loss: 0.000332
Train Epoch: 7 [1536/24098 (6%)] Loss: 0.000360
Train Epoch: 7 [2048/24098 (8%)] Loss: 0.000250
Train Epoch: 7 [2560/24098 (11%)] Loss: 0.000630
Train Epoch: 7 [3072/24098 (13%)] Loss: 0.000211
Train Epoch: 7 [3584/24098 (15%)] Loss: 0.000276
Train Epoch: 7 [4096/24098 (17%)] Loss: 0.000283
Train Epoch: 7 [4608/24098 (19%)] Loss: 0.000281
Train Epoch: 7 [5120/24098 (21%)] Loss: 0.000304
Train Epoch: 7 [5632/24098 (23%)] Loss: 0.000377
Train Epoch: 7 [6144/24098 (25%)] Loss: 0.000351
Train Epoch: 7 [6656/24098 (28%)] Loss: 0.000331
Train Epoch: 7 [7168/24098 (30%)] Loss: 0.000352
Train Epoch: 7 [7680/24098 (32%)] Loss: 0.000381
Train Epoch: 7 [8192/24098 (34%)] Loss: 0.000223
Train Epoch: 7 [8704/24098 (36%)] Loss: 0.000398
Train Epoch: 7 [9216/24098 (38%)] Loss: 0.000554
Train Epoch: 7 [9728/24098 (40%)] Loss: 0.000360
Train Epoch: 7 [10240/24098 (42%)] Loss: 0.000349
Train Epoch: 7 [10752/24098 (45%)] Loss: 0.000333
Train Epoch: 7 [11264/24098 (47%)] Loss: 0.000274
Train Epoch: 7 [11776/24098 (49%)] Loss: 0.000253
Train Epoch: 7 [12288/24098 (51%)] Loss: 0.000483
Train Epoch: 7 [12800/24098 (53%)] Loss: 0.000360
Train Epoch: 7 [13312/24098 (55%)] Loss: 0.000403
Train Epoch: 7 [13824/24098 (57%)] Loss: 0.000443
Train Epoch: 7 [14336/24098 (59%)] Loss: 0.000218
Train Epoch: 7 [14848/24098 (62%)] Loss: 0.000255
Train Epoch: 7 [15360/24098 (64%)] Loss: 0.000269
Train Epoch: 7 [15872/24098 (66%)] Loss: 0.000291
Train Epoch: 7 [16384/24098 (68%)] Loss: 0.000382
Train Epoch: 7 [16896/24098 (70%)] Loss: 0.000364
Train Epoch: 7 [17408/24098 (72%)] Loss: 0.000302
Train Epoch: 7 [17920/24098 (74%)] Loss: 0.000337
Train Epoch: 7 [18432/24098 (76%)] Loss: 0.000259
Train Epoch: 7 [18944/24098 (79%)] Loss: 0.000398
Train Epoch: 7 [19456/24098 (81%)] Loss: 0.000239
Train Epoch: 7 [19968/24098 (83%)] Loss: 0.000434
Train Epoch: 7 [20480/24098 (85%)] Loss: 0.000379
Train Epoch: 7 [20992/24098 (87%)] Loss: 0.000516
Train Epoch: 7 [21504/24098 (89%)] Loss: 0.000346
Train Epoch: 7 [22016/24098 (91%)] Loss: 0.000318
Train Epoch: 7 [22528/24098 (93%)] Loss: 0.000326
Train Epoch: 7 [23040/24098 (96%)] Loss: 0.000249
Train Epoch: 7 [23552/24098 (98%)] Loss: 0.000631
Train Epoch: 7 [24064/24098 (100%)] Loss: 0.000446
[t2v_metrics]MovieClips epoch 7, R@1: 8.1, R@5: 22.2, R@10 30.7, R@50 54.0MedR: 39, MeanR: 176.4
[v2t_metrics]MovieClips epoch 7, R@1: 9.6, R@5: 23.3, R@10 31.6, R@50 54.9MedR: 35, MeanR: 171.6
    epoch          : 7
    loss           : 0.0003485025709327582
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.019257619976997375
    val_t2v_metrics_R1: 8.06547619047619
    val_t2v_metrics_R5: 22.172619047619047
    val_t2v_metrics_R10: 30.68452380952381
    val_t2v_metrics_R50: 54.017857142857146
    val_t2v_metrics_MedR: 39.0
    val_t2v_metrics_MeanR: 176.39613095238096
    val_t2v_metrics_geometric_mean_R1-R5-R10: 17.63824885024632
    val_v2t_metrics_R1: 9.553571428571429
    val_v2t_metrics_R5: 23.333333333333332
    val_v2t_metrics_R10: 31.636904761904763
    val_v2t_metrics_R50: 54.851190476190474
    val_v2t_metrics_MedR: 35.0
    val_v2t_metrics_MeanR: 171.59910714285715
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.17691938032202
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch7.pth ...
Train Epoch: 8 [0/24098 (0%)] Loss: 0.000205
Train Epoch: 8 [512/24098 (2%)] Loss: 0.000250
Train Epoch: 8 [1024/24098 (4%)] Loss: 0.000184
Train Epoch: 8 [1536/24098 (6%)] Loss: 0.000253
Train Epoch: 8 [2048/24098 (8%)] Loss: 0.000245
Train Epoch: 8 [2560/24098 (11%)] Loss: 0.000188
Train Epoch: 8 [3072/24098 (13%)] Loss: 0.000213
Train Epoch: 8 [3584/24098 (15%)] Loss: 0.000239
Train Epoch: 8 [4096/24098 (17%)] Loss: 0.000200
Train Epoch: 8 [4608/24098 (19%)] Loss: 0.000177
Train Epoch: 8 [5120/24098 (21%)] Loss: 0.000408
Train Epoch: 8 [5632/24098 (23%)] Loss: 0.000181
Train Epoch: 8 [6144/24098 (25%)] Loss: 0.000157
Train Epoch: 8 [6656/24098 (28%)] Loss: 0.000335
Train Epoch: 8 [7168/24098 (30%)] Loss: 0.000219
Train Epoch: 8 [7680/24098 (32%)] Loss: 0.000230
Train Epoch: 8 [8192/24098 (34%)] Loss: 0.000164
Train Epoch: 8 [8704/24098 (36%)] Loss: 0.000190
Train Epoch: 8 [9216/24098 (38%)] Loss: 0.000207
Train Epoch: 8 [9728/24098 (40%)] Loss: 0.000330
Train Epoch: 8 [10240/24098 (42%)] Loss: 0.000228
Train Epoch: 8 [10752/24098 (45%)] Loss: 0.000159
Train Epoch: 8 [11264/24098 (47%)] Loss: 0.000183
Train Epoch: 8 [11776/24098 (49%)] Loss: 0.000262
Train Epoch: 8 [12288/24098 (51%)] Loss: 0.000138
Train Epoch: 8 [12800/24098 (53%)] Loss: 0.000222
Train Epoch: 8 [13312/24098 (55%)] Loss: 0.000231
Train Epoch: 8 [13824/24098 (57%)] Loss: 0.000239
Train Epoch: 8 [14336/24098 (59%)] Loss: 0.000396
Train Epoch: 8 [14848/24098 (62%)] Loss: 0.000181
Train Epoch: 8 [15360/24098 (64%)] Loss: 0.000161
Train Epoch: 8 [15872/24098 (66%)] Loss: 0.000073
Train Epoch: 8 [16384/24098 (68%)] Loss: 0.000433
Train Epoch: 8 [16896/24098 (70%)] Loss: 0.000148
Train Epoch: 8 [17408/24098 (72%)] Loss: 0.000245
Train Epoch: 8 [17920/24098 (74%)] Loss: 0.000149
Train Epoch: 8 [18432/24098 (76%)] Loss: 0.000187
Train Epoch: 8 [18944/24098 (79%)] Loss: 0.000149
Train Epoch: 8 [19456/24098 (81%)] Loss: 0.000294
Train Epoch: 8 [19968/24098 (83%)] Loss: 0.000275
Train Epoch: 8 [20480/24098 (85%)] Loss: 0.000260
Train Epoch: 8 [20992/24098 (87%)] Loss: 0.000203
Train Epoch: 8 [21504/24098 (89%)] Loss: 0.000341
Train Epoch: 8 [22016/24098 (91%)] Loss: 0.000154
Train Epoch: 8 [22528/24098 (93%)] Loss: 0.000160
Train Epoch: 8 [23040/24098 (96%)] Loss: 0.000270
Train Epoch: 8 [23552/24098 (98%)] Loss: 0.000232
Train Epoch: 8 [24064/24098 (100%)] Loss: 0.000576
[t2v_metrics]MovieClips epoch 8, R@1: 9.0, R@5: 22.6, R@10 30.9, R@50 54.8MedR: 37, MeanR: 174.2
[v2t_metrics]MovieClips epoch 8, R@1: 9.5, R@5: 23.9, R@10 32.6, R@50 55.9MedR: 35, MeanR: 169.2
    epoch          : 8
    loss           : 0.00024271415345743176
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.019555924460291862
    val_t2v_metrics_R1: 8.988095238095237
    val_t2v_metrics_R5: 22.589285714285715
    val_t2v_metrics_R10: 30.892857142857142
    val_t2v_metrics_R50: 54.82142857142857
    val_t2v_metrics_MedR: 37.0
    val_t2v_metrics_MeanR: 174.19300595238096
    val_t2v_metrics_geometric_mean_R1-R5-R10: 18.442059267999024
    val_v2t_metrics_R1: 9.494047619047619
    val_v2t_metrics_R5: 23.898809523809526
    val_v2t_metrics_R10: 32.61904761904762
    val_v2t_metrics_R50: 55.92261904761905
    val_v2t_metrics_MedR: 35.0
    val_v2t_metrics_MeanR: 169.17708333333334
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.487957183284642
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch8.pth ...
Train Epoch: 9 [0/24098 (0%)] Loss: 0.000128
Train Epoch: 9 [512/24098 (2%)] Loss: 0.000289
Train Epoch: 9 [1024/24098 (4%)] Loss: 0.000174
Train Epoch: 9 [1536/24098 (6%)] Loss: 0.000114
Train Epoch: 9 [2048/24098 (8%)] Loss: 0.000388
Train Epoch: 9 [2560/24098 (11%)] Loss: 0.000073
Train Epoch: 9 [3072/24098 (13%)] Loss: 0.000135
Train Epoch: 9 [3584/24098 (15%)] Loss: 0.000180
Train Epoch: 9 [4096/24098 (17%)] Loss: 0.000171
Train Epoch: 9 [4608/24098 (19%)] Loss: 0.000114
Train Epoch: 9 [5120/24098 (21%)] Loss: 0.000146
Train Epoch: 9 [5632/24098 (23%)] Loss: 0.000123
Train Epoch: 9 [6144/24098 (25%)] Loss: 0.000144
Train Epoch: 9 [6656/24098 (28%)] Loss: 0.000103
Train Epoch: 9 [7168/24098 (30%)] Loss: 0.000185
Train Epoch: 9 [7680/24098 (32%)] Loss: 0.000294
Train Epoch: 9 [8192/24098 (34%)] Loss: 0.000203
Train Epoch: 9 [8704/24098 (36%)] Loss: 0.000095
Train Epoch: 9 [9216/24098 (38%)] Loss: 0.000105
Train Epoch: 9 [9728/24098 (40%)] Loss: 0.000179
Train Epoch: 9 [10240/24098 (42%)] Loss: 0.000207
Train Epoch: 9 [10752/24098 (45%)] Loss: 0.000172
Train Epoch: 9 [11264/24098 (47%)] Loss: 0.000142
Train Epoch: 9 [11776/24098 (49%)] Loss: 0.000150
Train Epoch: 9 [12288/24098 (51%)] Loss: 0.000178
Train Epoch: 9 [12800/24098 (53%)] Loss: 0.000183
Train Epoch: 9 [13312/24098 (55%)] Loss: 0.000127
Train Epoch: 9 [13824/24098 (57%)] Loss: 0.000254
Train Epoch: 9 [14336/24098 (59%)] Loss: 0.000143
Train Epoch: 9 [14848/24098 (62%)] Loss: 0.000203
Train Epoch: 9 [15360/24098 (64%)] Loss: 0.000151
Train Epoch: 9 [15872/24098 (66%)] Loss: 0.000255
Train Epoch: 9 [16384/24098 (68%)] Loss: 0.000174
Train Epoch: 9 [16896/24098 (70%)] Loss: 0.000166
Train Epoch: 9 [17408/24098 (72%)] Loss: 0.000105
Train Epoch: 9 [17920/24098 (74%)] Loss: 0.000145
Train Epoch: 9 [18432/24098 (76%)] Loss: 0.000174
Train Epoch: 9 [18944/24098 (79%)] Loss: 0.000096
Train Epoch: 9 [19456/24098 (81%)] Loss: 0.000268
Train Epoch: 9 [19968/24098 (83%)] Loss: 0.000210
Train Epoch: 9 [20480/24098 (85%)] Loss: 0.000288
Train Epoch: 9 [20992/24098 (87%)] Loss: 0.000212
Train Epoch: 9 [21504/24098 (89%)] Loss: 0.000202
Train Epoch: 9 [22016/24098 (91%)] Loss: 0.000106
Train Epoch: 9 [22528/24098 (93%)] Loss: 0.000232
Train Epoch: 9 [23040/24098 (96%)] Loss: 0.000249
Train Epoch: 9 [23552/24098 (98%)] Loss: 0.000221
Train Epoch: 9 [24064/24098 (100%)] Loss: 0.000140
[t2v_metrics]MovieClips epoch 9, R@1: 8.4, R@5: 23.1, R@10 31.4, R@50 55.1MedR: 36, MeanR: 177.2
[v2t_metrics]MovieClips epoch 9, R@1: 9.6, R@5: 24.3, R@10 33.1, R@50 56.4MedR: 33, MeanR: 172.0
    epoch          : 9
    loss           : 0.00019046911929328914
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.020164811983704567
    val_t2v_metrics_R1: 8.422619047619047
    val_t2v_metrics_R5: 23.125
    val_t2v_metrics_R10: 31.36904761904762
    val_t2v_metrics_R50: 55.148809523809526
    val_t2v_metrics_MedR: 36.0
    val_t2v_metrics_MeanR: 177.16726190476192
    val_t2v_metrics_geometric_mean_R1-R5-R10: 18.2814263716984
    val_v2t_metrics_R1: 9.583333333333334
    val_v2t_metrics_R5: 24.31547619047619
    val_v2t_metrics_R10: 33.06547619047619
    val_v2t_metrics_R50: 56.398809523809526
    val_v2t_metrics_MedR: 33.0
    val_v2t_metrics_MeanR: 171.99642857142857
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.751104418588234
Saving checkpoint: saved/models/MoEE/0318_090306/checkpoint-epoch9.pth ...
Train Epoch: 10 [0/24098 (0%)] Loss: 0.000104
Train Epoch: 10 [512/24098 (2%)] Loss: 0.000056
Train Epoch: 10 [1024/24098 (4%)] Loss: 0.000272
Train Epoch: 10 [1536/24098 (6%)] Loss: 0.000238
Train Epoch: 10 [2048/24098 (8%)] Loss: 0.000113
Train Epoch: 10 [2560/24098 (11%)] Loss: 0.000129
Train Epoch: 10 [3072/24098 (13%)] Loss: 0.000152
Train Epoch: 10 [3584/24098 (15%)] Loss: 0.000346
Train Epoch: 10 [4096/24098 (17%)] Loss: 0.000110
Train Epoch: 10 [4608/24098 (19%)] Loss: 0.000142
Train Epoch: 10 [5120/24098 (21%)] Loss: 0.000102
Train Epoch: 10 [5632/24098 (23%)] Loss: 0.000093
Train Epoch: 10 [6144/24098 (25%)] Loss: 0.000171
Train Epoch: 10 [6656/24098 (28%)] Loss: 0.000114
Train Epoch: 10 [7168/24098 (30%)] Loss: 0.000115
Train Epoch: 10 [7680/24098 (32%)] Loss: 0.000393
Train Epoch: 10 [8192/24098 (34%)] Loss: 0.000130
Train Epoch: 10 [8704/24098 (36%)] Loss: 0.000203
Train Epoch: 10 [9216/24098 (38%)] Loss: 0.000120
Train Epoch: 10 [9728/24098 (40%)] Loss: 0.000098
Train Epoch: 10 [10240/24098 (42%)] Loss: 0.000136
Train Epoch: 10 [10752/24098 (45%)] Loss: 0.000095
Train Epoch: 10 [11264/24098 (47%)] Loss: 0.000113
Train Epoch: 10 [11776/24098 (49%)] Loss: 0.000254
Train Epoch: 10 [12288/24098 (51%)] Loss: 0.000116
Train Epoch: 10 [12800/24098 (53%)] Loss: 0.000157
Train Epoch: 10 [13312/24098 (55%)] Loss: 0.000202
Train Epoch: 10 [13824/24098 (57%)] Loss: 0.000117
Train Epoch: 10 [14336/24098 (59%)] Loss: 0.000255
Train Epoch: 10 [14848/24098 (62%)] Loss: 0.000154
Train Epoch: 10 [15360/24098 (64%)] Loss: 0.000113
Train Epoch: 10 [15872/24098 (66%)] Loss: 0.000075
Train Epoch: 10 [16384/24098 (68%)] Loss: 0.000246
Train Epoch: 10 [16896/24098 (70%)] Loss: 0.000166
Train Epoch: 10 [17408/24098 (72%)] Loss: 0.000098
Train Epoch: 10 [17920/24098 (74%)] Loss: 0.000352
Train Epoch: 10 [18432/24098 (76%)] Loss: 0.000104
Train Epoch: 10 [18944/24098 (79%)] Loss: 0.000069
Train Epoch: 10 [19456/24098 (81%)] Loss: 0.000102
Train Epoch: 10 [19968/24098 (83%)] Loss: 0.000161
Train Epoch: 10 [20480/24098 (85%)] Loss: 0.000134
Train Epoch: 10 [20992/24098 (87%)] Loss: 0.000109
Train Epoch: 10 [21504/24098 (89%)] Loss: 0.000212
Train Epoch: 10 [22016/24098 (91%)] Loss: 0.000236
Train Epoch: 10 [22528/24098 (93%)] Loss: 0.000217
Train Epoch: 10 [23040/24098 (96%)] Loss: 0.000133
Train Epoch: 10 [23552/24098 (98%)] Loss: 0.000090
Train Epoch: 10 [24064/24098 (100%)] Loss: 0.000255
[t2v_metrics]MovieClips epoch 10, R@1: 8.8, R@5: 23.0, R@10 31.2, R@50 54.7MedR: 38, MeanR: 183.0
[v2t_metrics]MovieClips epoch 10, R@1: 9.5, R@5: 24.0, R@10 32.9, R@50 56.1MedR: 33, MeanR: 179.3
    epoch          : 10
    loss           : 0.00014898053181221967
    t2v_metrics    : 0.0
    v2t_metrics    : 0.0
    val_loss       : 0.021006781607866287
    val_t2v_metrics_R1: 8.75
    val_t2v_metrics_R5: 23.035714285714285
    val_t2v_metrics_R10: 31.25
    val_t2v_metrics_R50: 54.67261904761905
    val_t2v_metrics_MedR: 38.0
    val_t2v_metrics_MeanR: 182.97544642857142
    val_t2v_metrics_geometric_mean_R1-R5-R10: 18.468002273030958
    val_v2t_metrics_R1: 9.464285714285714
    val_v2t_metrics_R5: 24.017857142857142
    val_v2t_metrics_R10: 32.88690476190476
    val_v2t_metrics_R50: 56.07142857142857
    val_v2t_metrics_MedR: 33.0
    val_v2t_metrics_MeanR: 179.30178571428573
    val_v2t_metrics_geometric_mean_R1-R5-R10: 19.55307353285828
Validation performance didn't improve for 4 epochs. Training stops.